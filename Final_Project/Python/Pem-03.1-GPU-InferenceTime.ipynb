{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CPU inference time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nSpyder Editor\\n\\nThis is a temporary script file.\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Destination Folder: /home/pengmiao/Project/MEMSYS/Pem/data/output/notebooks/03_1/\n",
      "['swaptions_1_1M.out', 'swaptions_2_1M.out', 'swaptions_1_repeat_1M.out']\n",
      "{}\n",
      "Skipping EDA report generation\n",
      "USE_GPU: False\n",
      "Executing Scenario LSTM_FPGA_Pretrained_rerun_1_Swaptions_1_1m\n",
      "Running for 400000\n",
      "Tokenizing ...\n",
      "Raw Vocabulary Size: 89114\n",
      "Quantile based Minimum Frequency for 1 is 0\n",
      "0 399999 0 199999 0 200000\n",
      "Max Accuracy: 1.0\n",
      "Total Removals: 0\n",
      "Pruned Vocabulary Size: 58630\n",
      "Final Vocabulary Size: 58630\n",
      "Total Sequences: 399996\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 3, 10)             586300    \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 16)                1728      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 16)                272       \n",
      "=================================================================\n",
      "Total params: 588,300\n",
      "Trainable params: 588,300\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/2\n",
      "199998/199998 [==============================] - 8s 41us/step - loss: 0.3672 - accuracy: 0.8365\n",
      "Epoch 2/2\n",
      "199998/199998 [==============================] - 8s 41us/step - loss: 0.2831 - accuracy: 0.8609\n",
      "time: 21.97560954093933\n",
      "2X_test: [[    1     1     1]\n",
      " [    1     1     1]\n",
      " [    1     1     1]\n",
      " ...\n",
      " [58628 58629   124]\n",
      " [58629   124     2]\n",
      " [  124     2     2]]\n",
      "Final Training accuracy: 0.86085296\n",
      "Test score: 0\n",
      "Test accuracy: 0.24164741647416474\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 486,
       "width": 514
      }
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy 0.860853, Test Accuracy 0.241647\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<DictProxy object, typeid 'dict' at 0x7fe546d80b70>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing Scenario LSTM_FPGA_Pretrained_new_1_Swaptions_1_1m\n",
      "Running for 400000\n",
      "Tokenizing ...\n",
      "Raw Vocabulary Size: 89115\n",
      "Quantile based Minimum Frequency for 1 is 0\n",
      "0 399999 0 199999 0 200000\n",
      "Max Accuracy: 1.0\n",
      "Total Removals: 0\n",
      "Pruned Vocabulary Size: 58631\n",
      "Final Vocabulary Size: 58631\n",
      "Total Sequences: 399996\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 3, 10)             586310    \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 16)                1728      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 16)                272       \n",
      "=================================================================\n",
      "Total params: 588,310\n",
      "Trainable params: 588,310\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/2\n",
      "199998/199998 [==============================] - 9s 43us/step - loss: 0.3731 - accuracy: 0.8273\n",
      "Epoch 2/2\n",
      "199998/199998 [==============================] - 8s 42us/step - loss: 0.2891 - accuracy: 0.8541\n",
      "time: 22.90497374534607\n",
      "2X_test: [[    1     1     1]\n",
      " [    1     1     1]\n",
      " [    1     1     1]\n",
      " ...\n",
      " [    8 58628 58629]\n",
      " [58628 58629 58630]\n",
      " [58629 58630   124]]\n",
      "Final Training accuracy: 0.85413384\n",
      "Test score: 0\n",
      "Test accuracy: 0.2153421534215342\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 486,
       "width": 514
      }
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy 0.854134, Test Accuracy 0.215342\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<DictProxy object, typeid 'dict' at 0x7fe546d80b70>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Spyder Editor\n",
    "\n",
    "This is a temporary script file.\n",
    "\"\"\"\n",
    "%matplotlib inline\n",
    "import sys\n",
    "from utils import *\n",
    "X=[]\n",
    "\n",
    "if platform.system() == \"Linux\":\n",
    "    PROJECT_ROOT_DIRECTORY = \"/home/pengmiao/Project/MEMSYS/Pem/\"#\"/home/aggelos/projects/SDH/\"\n",
    "    sys.path.append(PROJECT_ROOT_DIRECTORY)\n",
    "    os.environ[\"TMP\"] = \"/tmp\"\n",
    "    USE_GPU = False#True\n",
    "else:\n",
    "    PROJECT_ROOT_DIRECTORY = \"E:/Lab/PyCharm/Pem_MEMSYS_try3/Anglos/\"\n",
    "    sys.path.append(PROJECT_ROOT_DIRECTORY)\n",
    "    USE_GPU = False\n",
    "\n",
    "DELETE_OLD_RESULTS = False\n",
    "\n",
    "NUMBER_OF_PROCESSES = 2\n",
    "\n",
    "PERFORM_EDA = False\n",
    "\n",
    "NOTEBOOK_ID = \"03_1\"\n",
    "\n",
    "README_TXT = \"\"\"# README\n",
    "## Ensemble modeling of memory access timeseries (using shapelets, LSTMs and more)\n",
    "\"\"\"\n",
    "###\n",
    "\n",
    "# Inputs:\n",
    "# TRACE_DIRECTORY = PROJECT_ROOT_DIRECTORY + \"data/input/\"\n",
    "#TRACE_DIRECTORY = \"E:/Lab/PyCharm/Pem_MEMSYS_try3/Anglos/data/\"\n",
    "TRACE_DIRECTORY =\"/home/pengmiao/Project/MEMSYS/data/\"\n",
    "TRACE_FILE_NAMES = [\n",
    "    'swaptions_1_1M.out'\n",
    "]  # more to be added here\n",
    "\n",
    "# Size of files in number of rows. This should be implemented as a single dict for both\n",
    "TRACE_FILE_NAME_SIZES = {\n",
    "    # \"swaptions_mem.out\": 66999281,\n",
    "    # \"blackscholes_mem.out\": 63141878,\n",
    "    # \"fluidanimate_mem.out\": 838028424\n",
    "\n",
    "    #'blackscholes_1.out': 63141878,\n",
    "    'swaptions_1_1M.out': 1000000\n",
    "\n",
    "}\n",
    "###\n",
    "\n",
    "# Outputs:\n",
    "NOTEBOOK_ROOT_DIRECTORY = PROJECT_ROOT_DIRECTORY + \"data/output/notebooks/%s/\" % NOTEBOOK_ID\n",
    "\n",
    "NOTEBOOK_PLOTS_DIRECTORY = NOTEBOOK_ROOT_DIRECTORY + \"figs/\"\n",
    "\n",
    "NOTEBOOK_DATA_DIRECTORY = NOTEBOOK_ROOT_DIRECTORY + \"data/\"\n",
    "\n",
    "NOTEBOOK_PICKLES_DIRECTORY = NOTEBOOK_ROOT_DIRECTORY + \"pickles/\"\n",
    "\n",
    "NOTEBOOK_REPORT_DIRECTORY = NOTEBOOK_ROOT_DIRECTORY + \"reports/\"\n",
    "\n",
    "###\n",
    "\n",
    "CURRENT_TIMESTAMP = get_current_timestamp()\n",
    "setup_report(data_dir=NOTEBOOK_ROOT_DIRECTORY, readme_text=README_TXT, delete_old_results=DELETE_OLD_RESULTS)\n",
    "setup_report(data_dir=NOTEBOOK_PLOTS_DIRECTORY, delete_old_results=DELETE_OLD_RESULTS)\n",
    "setup_report(data_dir=NOTEBOOK_DATA_DIRECTORY, delete_old_results=DELETE_OLD_RESULTS)\n",
    "setup_report(data_dir=NOTEBOOK_PICKLES_DIRECTORY, delete_old_results=DELETE_OLD_RESULTS)\n",
    "setup_report(data_dir=NOTEBOOK_REPORT_DIRECTORY, delete_old_results=DELETE_OLD_RESULTS)\n",
    "set_plot_style_for_paper()\n",
    "\n",
    "print(\"Destination Folder: %s\" % NOTEBOOK_ROOT_DIRECTORY)\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "# InteractiveShell.ast_node_interactivity = \"last_expr\"\n",
    "\n",
    "# this code adds also the variations of each primary trace, namely the ones with _2 and 1_rerun prefix.\n",
    "TRACE_FILE_NAMES_AND_VARIATIONS = []\n",
    "for trace in TRACE_FILE_NAMES:\n",
    "    if \"old\" not in trace:\n",
    "        TRACE_FILE_NAMES_AND_VARIATIONS.append(trace)\n",
    "        TRACE_FILE_NAMES_AND_VARIATIONS.append(trace.replace(\"1_1M\", \"2_1M\"))\n",
    "        TRACE_FILE_NAMES_AND_VARIATIONS.append(trace.replace(\"1_1M.out\", \"1_repeat_1M.out\"))\n",
    "    else:\n",
    "        TRACE_FILE_NAMES_AND_VARIATIONS.append(trace)\n",
    "print(TRACE_FILE_NAMES_AND_VARIATIONS)\n",
    "\n",
    "# In[]\n",
    "from sklearn.model_selection import train_test_split\n",
    "from numpy import array\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import to_categorical, Sequence\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.layers import LSTM, CuDNNLSTM\n",
    "from keras.layers import Embedding\n",
    "from keras.utils import plot_model\n",
    "from keras.models import load_model, save_model\n",
    "from IPython.display import SVG, display\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "import keras.backend as K\n",
    "from sys import getsizeof\n",
    "import statsmodels.api as sm\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "from multiprocessing import Manager\n",
    "from collections import Counter\n",
    "from numpy import argmax\n",
    "from sklearn.metrics import accuracy_score\n",
    "matplotlib.rcParams['text.usetex'] = False #True\n",
    "import time\n",
    "#from tensorflow.contrib.rnn import *\n",
    "\n",
    "if USE_GPU:\n",
    "    import tensorflow as tf\n",
    "    from keras.backend.tensorflow_backend import set_session\n",
    "    config = tf.compat.v1.ConfigProto( device_count = {'GPU': 0 , 'CPU': 8} )\n",
    "    config = tf.compat.v1.ConfigProto()\n",
    "    config.gpu_options.allow_growth = True  # dynamically grow the memory used on the GPU\n",
    "    config.log_device_placement = True  # to log device placement (on which device the operation ran)\n",
    "\n",
    "    sess = tf.compat.v1.Session(config=config)\n",
    "    #set_session(sess)\n",
    "    tf.compat.v1.keras.backend.set_session(sess)\n",
    "    print(tf.test.gpu_device_name())\n",
    "\n",
    "# In[] Data Preprocessing Functions\n",
    "def convert_to_binary(data=None, bit_size=16):\n",
    "    \"\"\"\n",
    "    Input: an array of integers\n",
    "    Returns a numpy array of arrays where each number is represented with a list of its binary digits\n",
    "    IMPORTANT: Currently 16 bit conversion is implemented below. For difference sizes, change 16 to something else.\n",
    "    \"\"\"\n",
    "    if bit_size == 16:\n",
    "        dataset = np.array([[int(d) for d in str('{0:016b}'.format(x))] for x in list(data)])\n",
    "    elif bit_size == 32 or bit_size not in [16, 32]:\n",
    "        if bit_size != 32:\n",
    "            print\n",
    "            \"Using 32bits delta representation\"\n",
    "        dataset = np.array([[int(d) for d in str('{0:032b}'.format(x))] for x in list(data)])\n",
    "    # print \"A10\", dataset[:10]\n",
    "    return dataset\n",
    "\n",
    "\n",
    "def difference(dataset, interval=1):\n",
    "    \"\"\"\n",
    "    Calculates the difference between a time-series and a lagged version of it\n",
    "    \"\"\"\n",
    "    diff = list()\n",
    "    for i in range(interval, len(dataset)):\n",
    "        value = dataset[i] - dataset[i - interval]\n",
    "        diff.append(value)\n",
    "    return diff\n",
    "\n",
    "\n",
    "def difference16(data=None, lag=1, prune_lsb=False, prune_length=None):\n",
    "    \"\"\"\n",
    "    Calculates the difference between a time-series and a lagged version of it that are represented in HEX format.\n",
    "    This can be used to convert memory addresses to integers.\n",
    "    \"\"\"\n",
    "    diff = list()\n",
    "    for i in range(lag, len(data)):\n",
    "        if prune_lsb:\n",
    "            value = int(data[i][:-prune_length] + '0' * prune_length, 16) - int(\n",
    "                data[i - lag][:-prune_length] + '0' * prune_length, 16)\n",
    "        else:\n",
    "            value = int(data[i], 16) - int(data[i - lag], 16)\n",
    "        diff.append(value)\n",
    "    return diff\n",
    "\n",
    "\n",
    "def inverse_difference(last_ob, value):\n",
    "    \"\"\"\n",
    "    Reconstructs the next value of a differenced time series.\n",
    "    \"\"\"\n",
    "    return value + last_ob\n",
    "\n",
    "# In[] Plot Configuration\n",
    "params = {\n",
    "    'axes.labelsize': 28,\n",
    "    'font.size': 24,\n",
    "    'legend.fontsize': 24,\n",
    "    'xtick.labelsize': 24,\n",
    "    'ytick.labelsize': 24,\n",
    "    'text.usetex': False, #True,\n",
    "    #'figure.figsize': [4.5, 4.5],\n",
    "    'figure.facecolor': 'w',\n",
    "    'figure.edgecolor': 'w',\n",
    "    'axes.facecolor': 'w',\n",
    "    'axes.edgecolor': 'gray',\n",
    "    'savefig.facecolor': 'w',\n",
    "    'savefig.edgecolor': 'g',\n",
    "    'savefig.pad_inches': 0.1,\n",
    "    'savefig.transparent': True,\n",
    "    'axes.titlepad': 24,\n",
    "    'axes.titlesize': 32\n",
    "}\n",
    "rcParams.update(params)\n",
    "\n",
    "# In[] Perform EDA\n",
    "\n",
    "# PERFORM_EDA = False\n",
    "NROWS = 500000\n",
    "\n",
    "manager = Manager()\n",
    "\n",
    "\n",
    "def run_eda(dataset=None, app_name=None, manual_encoding=False, decompose_timeseries=False, file_suffix=None):\n",
    "    set_plot_size(8, 8)\n",
    "\n",
    "    file_name_suffix = (\"tok_seq\" if not manual_encoding else \"manual_enc_seq\") + (\n",
    "        \"_decomposed\" if decompose_timeseries else \"\") + (\n",
    "                                   \"_%s_%s.eps\" % (app_name.replace(\" \", \"_\"), file_suffix)).replace(\"-\", \"_\").replace(\n",
    "        \" \", \"_\").lower()\n",
    "    report_name_prefix = (\"Of Mem Deltas  \" if decompose_timeseries else \"\") + (\n",
    "        \"\" if not manual_encoding else \"Of Manually\")\n",
    "\n",
    "    #     if not manual_encoding:\n",
    "    #         tokenizer = Tokenizer()\n",
    "    #         tokenizer.fit_on_texts(list(dataset))\n",
    "    #         encoded_all = tokenizer.texts_to_sequences([' '.join(list(dataset))])[0]\n",
    "    #     else:\n",
    "    #         encoded_all = encode_mem_accesses(list(dataset)) # angelos version\n",
    "    # TODO: cleanup code here since we are now passing deltas\n",
    "    encoded_all = dataset  # its already delta\n",
    "    if decompose_timeseries:\n",
    "        # decomposition implements diff for now\n",
    "\n",
    "        # encoded_all = get_timeseries_decomposition(data=encoded_all, frequency=decomposition_freq, plot=True, file_name_suffix=file_name_suffix, app_name=app_name, report_name_prefix=report_name_prefix)[2]\n",
    "        # encoded_all = [x for x in encoded_all if str(x) != 'nan']\n",
    "        encoded_all = difference(encoded_all, 1)\n",
    "\n",
    "    set_plot_size(16, 5)\n",
    "    _ = plt.figure()\n",
    "    # _ = pd.DataFrame(encoded_all, columns=[\"address\"]).plot(linewidth=1, fontsize=22)\n",
    "    _ = plt.plot(encoded_all, marker='x', markersize=8, linestyle='None')\n",
    "    _ = plt.ylim([-50000, 50000])\n",
    "    _ = plt.title(\"Memory Delta Time-Series %s\\nFor Trace %s\" % (report_name_prefix, app_name))\n",
    "    _ = plt.xlabel(\"Time\")\n",
    "    _ = plt.ylabel(\"Memory Address Delta\")\n",
    "    _ = plt.grid(True)\n",
    "    _ = plt.savefig(NOTEBOOK_PLOTS_DIRECTORY + \"raw_ts_pruned_%s\" % (file_name_suffix.replace(\".eps\", \"png\")),\n",
    "                    bbox_inches='tight')\n",
    "    _ = plt.show(block=False)\n",
    "    set_plot_size(8, 8)\n",
    "\n",
    "\n",
    "def eda_worker(dataset, app_name, file_suffix):\n",
    "    \"\"\"\n",
    "    Implements the main call that generates data for Experimental Data Analysis (EDA)\n",
    "    \"\"\"\n",
    "    run_eda(dataset=dataset, app_name=app_name, decompose_timeseries=False, manual_encoding=False,\n",
    "            file_suffix=file_suffix)\n",
    "\n",
    "# In[] Perform Time Series Shapelet Analysis\n",
    "rcParams['agg.path.chunksize'] = 10000\n",
    "\n",
    "# PERFORM_EDA = False\n",
    "NROWS = 10000\n",
    "\n",
    "NCHUNKS = 2\n",
    "SKIP_ROWS = 1000\n",
    "\n",
    "manager = Manager()\n",
    "\n",
    "# shapelet_report = manager.dict()\n",
    "shapelet_report = {}  # This nested dictionary cannot be implemented with multiprocesses bc its not mutable. So we fall back to using signle processes\n",
    "\n",
    "\n",
    "def run_shape_analyzer(dataset=None, app_name=None, manual_encoding=False, decompose_timeseries=False, chunk_id=None):\n",
    "    global shapelet_report\n",
    "    set_plot_size(30, 6)\n",
    "\n",
    "    encoded_all = dataset\n",
    "    file_name_suffix = (\"tok_seq\" if not manual_encoding else \"manual_enc_seq\") + (\n",
    "        \"_decomposed\" if decompose_timeseries else \"\") + (\"%s_%s.png\" % (chunk_id, app_name.replace(\" \", \"_\"))).replace(\n",
    "        \"-\", \"_\").replace(\" \", \"_\").lower()\n",
    "    report_name_prefix = (\"Of Mem Deltas  \" if decompose_timeseries else \"\") + (\n",
    "        \"\" if not manual_encoding else \"Of Manually\")\n",
    "\n",
    "    report_id = \"%s_%s_%s\" % (app_name, manual_encoding, decompose_timeseries)\n",
    "    report_name = app_name.replace(\" \", \"\")\n",
    "    params = {\n",
    "        \"manual_enconding\": manual_encoding,\n",
    "        \"decompose_timeseries\": decompose_timeseries\n",
    "    }\n",
    "\n",
    "    if report_id not in shapelet_report.keys():\n",
    "        shapelet_report[report_id] = {\n",
    "            \"report_name\": report_name,\n",
    "            \"params\": params,\n",
    "            \"plots\": {\n",
    "                \"movavg\": {},\n",
    "                \"rawts\": {},\n",
    "                \"diffts\": {},\n",
    "                \"rollacf\": {},\n",
    "                \"acfts\": {}\n",
    "            }\n",
    "        }\n",
    "    filename = NOTEBOOK_PLOTS_DIRECTORY + \"mov_avg_%s\" % (file_name_suffix)\n",
    "    print(filename)\n",
    "    print(encoded_all[:100])\n",
    "\n",
    "    _ = plt.figure()\n",
    "    _ = pd.DataFrame(encoded_all, columns=[\"address\"]).rolling(1000).mean().plot(linewidth=1, fontsize=22)\n",
    "    _ = plt.title(\"Moving Average %s\\nTrace %s\" % (report_name_prefix, app_name))\n",
    "    _ = plt.xlabel(\"Time\")\n",
    "    _ = plt.ylabel(\"Average Memory Address\")\n",
    "    _ = plt.grid(True)\n",
    "    _ = plt.savefig(filename, bbox_inches='tight')\n",
    "    _ = plt.show(block=False)\n",
    "    shapelet_report[report_id][\"plots\"][\"movavg\"][chunk_id] = filename\n",
    "\n",
    "    filename = NOTEBOOK_PLOTS_DIRECTORY + \"raw_ts_%s\" % (file_name_suffix)\n",
    "    _ = plt.figure()\n",
    "    _ = pd.DataFrame(encoded_all, columns=[\"address\"]).plot(linewidth=1, fontsize=22)\n",
    "    _ = plt.title(\"Raw Time-Series %s\\nTrace %s\" % (report_name_prefix, app_name))\n",
    "    _ = plt.xlabel(\"Time\")\n",
    "    _ = plt.ylabel(\"Memory Address\")\n",
    "    _ = plt.grid(True)\n",
    "    _ = plt.savefig(filename, bbox_inches='tight')\n",
    "    _ = plt.show(block=False)\n",
    "    shapelet_report[report_id][\"plots\"][\"rawts\"][chunk_id] = filename\n",
    "\n",
    "    # TODO: make this diff to be done directly on the MEM addresses (HEX)\n",
    "    filename = NOTEBOOK_PLOTS_DIRECTORY + \"diff_ts_%s\" % (file_name_suffix)\n",
    "    # _ = pd.DataFrame(encoded_all, columns=[\"address\"]).diff().plot(linewidth=1, fontsize=22)\n",
    "    # _ = pd.DataFrame(pd.DataFrame(encoded_all, columns=[\"address\"]).diff(), columns=[\"address\"]).rolling(1000).mean().plot(linewidth=1, fontsize=22)\n",
    "    _ = plt.figure()\n",
    "    _ = pd.DataFrame(encoded_all, columns=[\"address\"]).diff().plot(linewidth=1, fontsize=22)\n",
    "    _ = plt.title(\"Delta Time-Series %s\\nTrace %s\" % (report_name_prefix, app_name))\n",
    "    _ = plt.xlabel(\"Time\")\n",
    "    _ = plt.ylabel(\"Memory Address Deltas\")\n",
    "    _ = plt.grid(True)\n",
    "    _ = plt.savefig(filename, bbox_inches='tight')\n",
    "    _ = plt.show(block=False)\n",
    "    shapelet_report[report_id][\"plots\"][\"diffts\"][chunk_id] = filename\n",
    "\n",
    "\n",
    "def trace_shape_analyzer_worker(dataset, app_name, chunk_id):\n",
    "    \"\"\"\n",
    "    Implements the main call that generates data for Experimental Data Analysis (EDA)\n",
    "    \"\"\"\n",
    "    run_shape_analyzer(dataset=dataset, app_name=app_name, decompose_timeseries=False, manual_encoding=False,\n",
    "                       chunk_id=chunk_id)\n",
    "    # run_shape_analyzer(dataset=dataset, app_name=app_name, decompose_timeseries=False, manual_encoding=True, chunk_id=chunk_id)\n",
    "    # run_shape_analyzer(dataset=dataset, app_name=app_name, decompose_timeseries=True, manual_encoding=False, chunk_id=chunk_id)\n",
    "    # run_shape_analyzer(dataset=dataset, app_name=app_name, decompose_timeseries=True, manual_encoding=True, chunk_id=chunk_id)\n",
    "\n",
    "\n",
    "chunk = 0\n",
    "word_index = 1\n",
    "encoding_dictionary = defaultdict(int)\n",
    "\n",
    "print(dict(shapelet_report))\n",
    "\n",
    "\n",
    "# In[] Process Report\n",
    "def create_html_report(config, report_name):\n",
    "    page = []\n",
    "    page.append(\"\"\"<html>\n",
    "    <head>\n",
    "    <title>SDH Report</title>\n",
    "    </head>\n",
    "    <body>\"\"\")\n",
    "\n",
    "    # page.append('<ul>\\n')\n",
    "\n",
    "    for report_id, val in config.iteritems():\n",
    "        print(report_id)\n",
    "        page.append(\"<h1>%s</h1>\" % report_id.replace(\"_False_False\", \"\"))\n",
    "        page.append(\"\"\"\n",
    "            <table style=\"width:100%\">\n",
    "              <tr>\n",
    "                <th width=\"10%\">Metric Name</th>\n",
    "                <th width=\"90%\">Plot</th>\n",
    "              </tr>\n",
    "        \"\"\")\n",
    "        for k, v in val[\"plots\"].iteritems():\n",
    "            print(k, v)\n",
    "            for kk, vv in v.iteritems():\n",
    "                page.append('<tr><td>Chunk # %s of %s </td>' % (kk, k))\n",
    "                page.append('<td><img src=\"%s\"></td></tr>' % vv)\n",
    "\n",
    "        page.append('</table>\\n')\n",
    "    page.append('</body></html>')\n",
    "\n",
    "    with open(NOTEBOOK_REPORT_DIRECTORY + report_name + \".html\", \"w\") as text_file:\n",
    "        text_file.write('\\n'.join(page))\n",
    "\n",
    "\n",
    "if len(shapelet_report) > 0:\n",
    "    create_html_report(dict(shapelet_report), \"shapelet\")\n",
    "else:\n",
    "    print(\"Skipping EDA report generation\")\n",
    "\n",
    "\n",
    "# In[] Modeling Functions\n",
    "def precision(y_true, y_pred):\n",
    "    \"\"\"Precision metric. Only computes a batch-wise average of precision.\n",
    "-    Computes the precision, a metric for multi-label classification of\n",
    "-    how many selected items are relevant.\n",
    "-    \"\"\"\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "\n",
    "def recall(y_true, y_pred):\n",
    "    \"\"\"Recall metric.\n",
    "-    Only computes a batch-wise average of recall.\n",
    "-    Computes the recall, a metric for multi-label classification of\n",
    "-    how many relevant items are selected.\n",
    "-    \"\"\"\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "\n",
    "def fbeta_score(y_true, y_pred, beta=1):\n",
    "    \"\"\"Computes the F score.\n",
    "-    The F score is the weighted harmonic mean of precision and recall.\n",
    "-    Here it is only computed as a batch-wise average, not globally.\n",
    "-    This is useful for multi-label classification, where input samples can be\n",
    "-    classified as sets of labels. By only using accuracy (precision) a model\n",
    "-    would achieve a perfect score by simply assigning every class to every\n",
    "-    input. In order to avoid this, a metric should penalize incorrect class\n",
    "-    assignments as well (recall). The F-beta score (ranged from 0.0 to 1.0)\n",
    "-    computes this, as a weighted mean of the proportion of correct class\n",
    "-    assignments vs. the proportion of incorrect class assignments.\n",
    "-    With beta = 1, this is equivalent to a F-measure. With beta < 1, assigning\n",
    "-    correct classes becomes more important, and with beta > 1 the metric is\n",
    "-    instead weighted towards penalizing incorrect class assignments.\n",
    "-    \"\"\"\n",
    "    if beta < 0:\n",
    "        raise ValueError('The lowest choosable beta is zero (only precision).')\n",
    "\n",
    "        # If there are no true positives, fix the F score at 0 like sklearn.\n",
    "    if K.sum(K.round(K.clip(y_true, 0, 1))) == 0:\n",
    "        return 0\n",
    "    p = precision(y_true, y_pred)\n",
    "    r = recall(y_true, y_pred)\n",
    "    bb = beta ** 2\n",
    "    fbeta_score = (1 + bb) * (p * r) / (bb * p + r + K.epsilon())\n",
    "    return fbeta_score\n",
    "\n",
    "\n",
    "def fmeasure(y_true, y_pred):\n",
    "    \"\"\"Computes the f-measure, the harmonic mean of precision and recall.\n",
    "    Here it is only computed as a batch-wise average, not globally.\n",
    "    \"\"\"\n",
    "    return fbeta_score(y_true, y_pred, beta=1)\n",
    "\n",
    "\n",
    "def encode_mem_accesses(data):\n",
    "    \"\"\"\n",
    "    It implements a mapping between a set of strings to integers.\n",
    "    It does not have a limit in the max_dictionary_size supported.\n",
    "\n",
    "    data: data input should be in Pandas DF format\n",
    "    \"\"\"\n",
    "    tmp = defaultdict(int)\n",
    "    i = 1\n",
    "    encoded = []\n",
    "    for el in list(data):\n",
    "        if not tmp[el]:\n",
    "            # if el not in tmp.keys():\n",
    "            tmp[el] = i\n",
    "            i += 1\n",
    "        encoded.append(tmp[el])\n",
    "    return encoded\n",
    "\n",
    "\n",
    "def create_windowed_dataset(data, look_back):\n",
    "    \"\"\"\n",
    "    Create the dataset by grouping windows of memory accesses together (using the look_back parameter)\n",
    "\n",
    "    data: it should be a list of integers\n",
    "    \"\"\"\n",
    "    sequences = list()\n",
    "    for i in range(look_back, len(data)):\n",
    "        sequence = data[i - look_back:i + 1]\n",
    "        sequences.append(sequence)\n",
    "    return sequences\n",
    "\n",
    "\n",
    "def get_timeseries_decomposition(data=None, frequency=None, plot=False, report_name_prefix=None, file_name_suffix=None,\n",
    "                                 app_name=None):\n",
    "    # TODO: reimplement this\n",
    "    \"\"\"\n",
    "    data is a list of integers which is converted to address - date dataframe\n",
    "    \"\"\"\n",
    "    dta = pd.DataFrame(data)\n",
    "    dta['date'] = dta.index\n",
    "    dta.columns = [\"address\", \"date\"]\n",
    "\n",
    "    dta['date'] = pd.DatetimeIndex(dta.date)  # ,  format=\"%Y-%m-%d %H:%M:%S\")\n",
    "    # df.index = pd.to_datetime(df.index, unit='s')\n",
    "    # dta.address.interpolate(inplace=True)\n",
    "    dta.set_index('date', inplace=True)\n",
    "\n",
    "    # dta = dta.groupby(pd.TimeGrouper('%ss' % 1), as_index=True)['total'].sum()\n",
    "    res = sm.tsa.seasonal_decompose(dta, freq=frequency, model='additive')\n",
    "    if plot:\n",
    "        _ = plt.figure()\n",
    "        _ = res.plot()\n",
    "        _ = plt.title(\n",
    "            \"Time Series Decomposition Of %s Tokenized Sequence For Trace %s\" % (report_name_prefix, app_name))\n",
    "        _ = plt.grid(True)\n",
    "        _ = plt.savefig(NOTEBOOK_PLOTS_DIRECTORY + \"hist_%s\" % (file_name_suffix), bbox_inches='tight')\n",
    "        _ = plt.show(block=False)\n",
    "\n",
    "    return list(res.trend['address']), list(res.seasonal['address']), list(res.resid['address'])\n",
    "\n",
    "\n",
    "def plot_generic_timeseries(train_data=None,test_data=None, rows=2000, app_name=\"\", scenario_name=None):\n",
    "    set_plot_size(30, 4)\n",
    "    scenario_name = scenario_name.replace(\"_\", \"-\").replace(\" \", \"-\")\n",
    "\n",
    "    _ = plt.figure()\n",
    "    _ = plt.plot(train_data[:rows])  # , linestyle='-', marker='.', markersize=6, linewidth=1)\n",
    "    _ = plt.xlabel(\"Time\")\n",
    "    _ = plt.ylabel(\"Memory Address\")\n",
    "    _ = plt.title(\"Memory Access Timeseries For Trace %s - Scenario %s - Training Phase\" % (app_name, scenario_name))\n",
    "    _ = plt.grid(True)\n",
    "    _ = plt.savefig(NOTEBOOK_PLOTS_DIRECTORY + \"memory_accesses_training_%s_%s.eps\" % (app_name, scenario_name),\n",
    "                    bbox_inches='tight')\n",
    "    _ = plt.show(block=False)\n",
    "\n",
    "    _ = plt.figure()\n",
    "    _ = plt.plot(test_data[:rows])  # , linestyle='-', marker='.', markersize=6, linewidth=1)\n",
    "    _ = plt.xlabel(\"Time\")\n",
    "    _ = plt.ylabel(\"Memory Address\")\n",
    "    _ = plt.title(\"Memory Access Timeseries For Trace %s - Scenario %s - Testing Phase\" % (app_name, scenario_name))\n",
    "    _ = plt.grid(True)\n",
    "    _ = plt.savefig(NOTEBOOK_PLOTS_DIRECTORY + \"memory_accesses_testing_%s_%s.eps\" % (app_name, scenario_name),\n",
    "                    bbox_inches='tight')\n",
    "    _ = plt.show(block=False)\n",
    "\n",
    "\n",
    "def plot_memory_trace(train_data=None, test_data=None, rows=2000, app_name=\"\", scenario_name=None):\n",
    "    set_plot_size(30, 4)\n",
    "    scenario_name = scenario_name.replace(\"_\", \"-\").replace(\" \", \"-\")\n",
    "\n",
    "    _ = plt.figure()\n",
    "    _ = plt.plot(train_data[:rows])  # , linestyle='-', marker='.', markersize=6, linewidth=1)\n",
    "    _ = plt.xlabel(\"Time\")\n",
    "    _ = plt.ylabel(\"Memory Address\")\n",
    "    _ = plt.title(\"Memory Access Timeseries For Trace %s - Scenario %s - Training Phase\" % (app_name, scenario_name))\n",
    "    _ = plt.grid(True)\n",
    "    _ = plt.savefig(NOTEBOOK_PLOTS_DIRECTORY + \"memory_accesses_training_%s_%s.eps\" % (app_name, scenario_name),\n",
    "                    bbox_inches='tight')\n",
    "    _ = plt.show(block=False)\n",
    "\n",
    "    _ = plt.figure()\n",
    "    _ = plt.plot(test_data[:rows])  # , linestyle='-', marker='.', markersize=6, linewidth=1)\n",
    "    _ = plt.xlabel(\"Time\")\n",
    "    _ = plt.ylabel(\"Memory Address\")\n",
    "    _ = plt.title(\"Memory Access Timeseries For Trace %s - Scenario %s - Testing Phase\" % (app_name, scenario_name))\n",
    "    _ = plt.grid(True)\n",
    "    _ = plt.savefig(NOTEBOOK_PLOTS_DIRECTORY + \"memory_accesses_testing_%s_%s.eps\" % (app_name, scenario_name),\n",
    "                    bbox_inches='tight')\n",
    "    _ = plt.show(block=False)\n",
    "\n",
    "\n",
    "def plot_on_the_fly_model_performance(history=None, app_name=\"\", scenario_name=None):\n",
    "    # TODO: optimize function and remove key accesses from the dictionaries (pass them as params)\n",
    "    # Plot training & validation accuracy values\n",
    "    scenario_name = scenario_name.replace(\"_\", \"-\").replace(\" \", \"-\")\n",
    "\n",
    "    set_plot_size(6, 6)\n",
    "    _ = plt.figure()\n",
    "    _ = plt.plot(range(1, len(history.history['acc']) + 1), history.history['acc'], linestyle='-', marker='^',\n",
    "                 markersize=8, linewidth=2)\n",
    "    _ = plt.plot(range(1, len(history.history['val_acc']) + 1), history.history['val_acc'], linestyle='-', marker='s',\n",
    "                 markersize=8, linewidth=2)\n",
    "    _ = plt.title('Model Accuracy For Trace %s\\nScenario %s' % (app_name, scenario_name))\n",
    "    _ = plt.ylabel('Accuracy')\n",
    "    _ = plt.xlabel('Epoch No.')\n",
    "    _ = plt.grid(True)\n",
    "    _ = plt.legend(['Train', 'Test'], loc='upper left')\n",
    "    _ = plt.savefig(NOTEBOOK_PLOTS_DIRECTORY + \"train_test_accuracy_for_%s_%s.eps\" % (app_name, scenario_name),\n",
    "                    bbox_inches='tight')\n",
    "    _ = plt.show(block=False)\n",
    "\n",
    "    # Plot training & validation loss values\n",
    "    _ = plt.figure()\n",
    "    _ = plt.plot(range(1, len(history.history['loss']) + 1), history.history['loss'], linestyle='-', marker='^',\n",
    "                 markersize=8, linewidth=2)\n",
    "    _ = plt.plot(range(1, len(history.history['val_loss']) + 1), history.history['val_loss'], linestyle='-', marker='s',\n",
    "                 markersize=8, linewidth=2)\n",
    "    _ = plt.title('Model Loss For Trace %s\\nScenario %s' % (app_name, scenario_name))\n",
    "    _ = plt.ylabel('Loss')\n",
    "    _ = plt.xlabel('Epoch No.')\n",
    "    _ = plt.grid(True)\n",
    "    _ = plt.legend(['Train', 'Test'], loc='upper left')\n",
    "    _ = plt.savefig(NOTEBOOK_PLOTS_DIRECTORY + \"train_test_loss_for_%s_%s.eps\" % (app_name, scenario_name),\n",
    "                    bbox_inches='tight')\n",
    "    _ = plt.show(block=False)\n",
    "\n",
    "\n",
    "def plot_train_test_model_performance(train_history=None, test_history=None, app_name=\"\", scenario_name=None):\n",
    "    # TODO: optimize function and remove key accesses from the dictionaries (pass them as params)\n",
    "    if train_history is not None:\n",
    "        print('Final Training accuracy: %s' % (train_history.history['accuracy'][-1]))\n",
    "        print('Test score: %s' % test_history[0])\n",
    "        print('Test accuracy: %s' % test_history[1])\n",
    "        scenario_name = scenario_name.replace(\"_\", \"-\").replace(\" \", \"-\")\n",
    "        data = train_history.history['accuracy']\n",
    "        set_plot_size(6, 6)\n",
    "        _ = plt.figure()\n",
    "        _ = plt.plot(range(1, len(data) + 1), data, linestyle='-', marker='^', markersize=8, linewidth=2)\n",
    "        _ = plt.xticks(range(1, len(data) + 1))\n",
    "        _ = plt.title('Training Accuracy Per Epoch\\nTrace %s' % (app_name))\n",
    "        _ = plt.ylabel('Accuracy')\n",
    "        _ = plt.xlabel('Epoch No.')\n",
    "        _ = plt.grid(True)\n",
    "        # _ = plt.legend(['Train'], loc='upper left')\n",
    "        _ = plt.savefig(NOTEBOOK_PLOTS_DIRECTORY + \"train_and_test_accuracy_for_%s_%s.eps\" % (app_name, scenario_name),\n",
    "                        bbox_inches='tight')\n",
    "        _ = plt.show(block=False)\n",
    "\n",
    "\n",
    "def approx_entropy(U, m, r):\n",
    "    try:\n",
    "        U = np.array(U)\n",
    "\n",
    "        def _maxdist(x_i, x_j):\n",
    "            return max([abs(ua - va) for ua, va in zip(x_i, x_j)])\n",
    "\n",
    "        def _phi(m):\n",
    "            x = [[U[j] for j in range(i, i + m - 1 + 1)] for i in range(N - m + 1)]\n",
    "            C = [len([1 for x_j in x if _maxdist(x_i, x_j) <= r]) / (N - m + 1.0) for x_i in x]\n",
    "            return (N - m + 1.0) ** (-1) * sum(np.log(C))\n",
    "\n",
    "        N = len(U)\n",
    "        return abs(_phi(m + 1) - _phi(m))\n",
    "    except:\n",
    "        print(U)\n",
    "        raise\n",
    "\n",
    "\n",
    "def sample_entropy(data):\n",
    "    p_data = pd.Series(data).value_counts() / len(data)  # calculates the probabilities\n",
    "    entropy = sc.stats.entropy(p_data)  # input probabilities to get the entropy\n",
    "    return entropy\n",
    "\n",
    "# In[] LSTM Model Implementation\n",
    "def dataset_creator(scenario):\n",
    "    use_manual_encoding = scenario['use_manual_encoding']\n",
    "    app_name = scenario['app_name']\n",
    "    decompose_timeseries = scenario['decompose_timeseries']\n",
    "    decomposition_frequency = scenario['decomposition_frequency']\n",
    "    test_ratio = scenario['test_ratio']\n",
    "    on_the_fly_testing = scenario['on_the_fly_testing']\n",
    "    plot_timeseries = scenario['plot_timeseries']\n",
    "    look_back = scenario['look_back_window']\n",
    "    scenario_name = scenario['scenario_name']\n",
    "    vocabulary_maximum_size = scenario['vocabulary_maximum_size']\n",
    "    vocabulary_mimimum_word_frequency_quantile = scenario['vocabulary_mimimum_word_frequency_quantile']\n",
    "    model_diffs = scenario['model_diffs']\n",
    "    lstm_batch_size = scenario['lstm_batch_size']\n",
    "    lstm_epochs = scenario['lstm_epochs']\n",
    "    verbosity = scenario['verbosity']\n",
    "    dropout_ratio = scenario['dropout_ratio']\n",
    "    lstm_size = scenario['lstm_size']\n",
    "    embedding_size = scenario['embedding_size']\n",
    "    prediction_batch_size = scenario['prediction_batch_size']\n",
    "    online_retraining = scenario['online_retraining']\n",
    "    online_learning_accuracy_threshold = scenario['online_learning_accuracy_threshold']\n",
    "    online_retraining_periods = scenario['online_retraining_periods']\n",
    "    online_retraining_period_size = scenario['online_retraining_period_size']\n",
    "    number_of_rows_to_model = scenario['number_of_rows_to_model']\n",
    "    number_of_rows_to_skip = scenario['number_of_rows_to_skip']\n",
    "    keep_read_access_only = scenario['keep_read_access_only']\n",
    "    prune_lsb = scenario['prune_lsb']\n",
    "    prune_length = scenario['prune_length']\n",
    "    pretrain_type = scenario[\"pretrain_type\"]\n",
    "    bit_size = scenario[\"bit_size\"]\n",
    "    convert_output_to_binary = scenario['convert_output_to_binary']  # this is used for FPGA implementation.\n",
    "\n",
    "    max_test_accuracy = 1\n",
    "    # used to reduce accuracy appropriatelly in case of rounding/approximations in the prediction address.\n",
    "\n",
    "    tokenizer = None\n",
    "    tokenizer2 = None\n",
    "\n",
    "    # This is used to represent rare words and not get encoded individually, which then will be\n",
    "    # flagged as false positives (or negatives) and use them to reduce the model accuracy\n",
    "    # All the rare words will be encoded with the following value.\n",
    "    dummy_word = \"0xffffffff\"\n",
    "    dummy_word_index = -1  # this is the index of the dummy word (to be set later)\n",
    "\n",
    "    # this is to be used to spoof the index of the dummy word and thus force false positive\n",
    "    # determination during testing (since these words cannot be predicted)\n",
    "    dummy_index = -1\n",
    "\n",
    "    # Set total rows to None to load all the rows for online learning. Else keep as many as we need.\n",
    "    total_rows = scenario['number_of_rows_to_model'] if not online_retraining else \\\n",
    "        scenario['number_of_rows_to_model'] + online_retraining_period_size * (online_retraining_periods + 2)\n",
    "    print(\"Running for %d\" % total_rows)\n",
    "\n",
    "    if pretrain_type is None:\n",
    "        dataset_verbose = pd.read_csv(TRACE_DIRECTORY + scenario['trace_file_name'], sep=\" \", nrows=total_rows,\n",
    "                                      skiprows=scenario['number_of_rows_to_skip'])\n",
    "    else:\n",
    "        ### This implements testing with a pretrained model\n",
    "        # TODO: put this info about the rerun files at the begining of the script as a dictionary.\n",
    "        comparison_file_name = scenario['trace_file_name']\n",
    "        if pretrain_type == \"rerun\":\n",
    "            comparison_file_name = comparison_file_name.replace(\"_1M.out\", \"\") + \"_repeat_1M.out\"\n",
    "        if pretrain_type == \"new\":\n",
    "            comparison_file_name = comparison_file_name.replace(\"1_\", \"2_\")\n",
    "        ###\n",
    "\n",
    "        #dataset_verbose1 = pd.read_csv(TRACE_DIRECTORY + comparison_file_name, sep=\" \",\n",
    "        #                               nrows=int(math.floor(total_rows / 2.0)),\n",
    "        #                               skiprows=scenario['number_of_rows_to_skip'])\n",
    "        dataset_verbose1 = pd.read_csv(TRACE_DIRECTORY + comparison_file_name,sep=\" \",\n",
    "                                       nrows=int(math.floor(total_rows / 2.0)),\n",
    "                                       skiprows=scenario['number_of_rows_to_skip'])\n",
    "        #dataset_verbose1.columns = [\"instruction\", \"address\"]\n",
    "        #print(dataset_verbose1)\n",
    "        dataset_verbose1.columns = [\"instruction\", \"type\", \"address\"]\n",
    "        #Pem\n",
    "       # dataset_verbose1.columns = [\"address\"]\n",
    "\n",
    "        #dataset_verbose2 = pd.read_csv(TRACE_DIRECTORY + comparison_file_name, sep=\" \",\n",
    "        #                               nrows=int(math.ceil(total_rows / 2.0)),\n",
    "        #                               skiprows=scenario['number_of_rows_to_skip'] + int(math.floor(total_rows / 2.0)))\n",
    "        dataset_verbose2 = pd.read_csv(TRACE_DIRECTORY + comparison_file_name,sep=\" \",\n",
    "                                       nrows=int(math.ceil(total_rows / 2.0)),\n",
    "                                       skiprows=scenario['number_of_rows_to_skip'] + int(math.floor(total_rows / 2.0)))\n",
    "        #dataset_verbose2.columns = [\"instruction\", \"address\"]\n",
    "        # Pem\n",
    "        dataset_verbose2.columns = [\"instruction\", \"type\", \"address\"]\n",
    "\n",
    "        dataset_verbose = dataset_verbose1.append(dataset_verbose2, ignore_index=True)\n",
    "\n",
    "\n",
    "    dataset_verbose.columns = [\"instruction\", \"type\", \"address\"]\n",
    "    if keep_read_access_only:\n",
    "        dataset_verbose = dataset_verbose[dataset_verbose[\"type\"] == \"R\"]\n",
    "    # print dataset_verbose.head()\n",
    "    # print dataset_verbose.describe()\n",
    "\n",
    "    dataset = dataset_verbose['address']\n",
    "    del dataset_verbose\n",
    "\n",
    "    if not use_manual_encoding:\n",
    "        if model_diffs:\n",
    "            print(\"Tokenizing ...\")\n",
    "            # Tokenize raw memory address to convert them to integers\n",
    "            tokenizer = Tokenizer()\n",
    "            tokenizer.fit_on_texts(list(dataset))\n",
    "            concat_dataset = [' '.join(list(dataset))]\n",
    "            # This is used only for plotting purposes\n",
    "            encoded_raw = tokenizer.texts_to_sequences(concat_dataset)[0]\n",
    "\n",
    "            vocab_size_raw = len(tokenizer.word_index) + 1\n",
    "            print('Raw Vocabulary Size: %d' % vocab_size_raw)\n",
    "\n",
    "            # calculate diffs of integer memory addresses\n",
    "            # print dataset\n",
    "\n",
    "            encoded_raw_diff = difference16(data=list(dataset), lag=1, prune_lsb=prune_lsb, prune_length=prune_length)\n",
    "\n",
    "            encoded_raw_diff_str = [\"%s%d\" % (\"1x\" if x < 0 else \"0x\", abs(x)) for x in encoded_raw_diff]\n",
    "            df = pd.DataFrame(encoded_raw_diff_str)\n",
    "            # print df\n",
    "\n",
    "            df.columns = ['delta']\n",
    "\n",
    "            df2 = pd.DataFrame(pd.Series(encoded_raw_diff_str).value_counts())\n",
    "            # print \"Length2 %s\" % len(df2.index)\n",
    "            df2.columns = ['total']\n",
    "            df2['delta'] = df2.index\n",
    "            # print \"xxxxx\", df2\n",
    "            df2 = df2.reset_index(drop=True)\n",
    "            df2.columns = ['total', 'delta']\n",
    "            # print \"V2\", df2\n",
    "            bit_size_offset = 3\n",
    "\n",
    "            df2_2 = df2[['total']].copy()\n",
    "            df2_2['cumsum'] = df2_2.sort_values(by=\"total\", ascending=False)[['total']].cumsum(axis=0)\n",
    "\n",
    "            tmp_total_rows = df2['total'].sum()\n",
    "\n",
    "            # Get the row index where the cumulative quantity reaches half the total.\n",
    "            # print \"AAA44\", tmp_total_rows, df2_2.head()\n",
    "            df2_3 = df2_2[df2_2['cumsum'] < vocabulary_mimimum_word_frequency_quantile * tmp_total_rows]  # .idxmax()\n",
    "            # print \"AAA34\", myindex, tmp_total_rows\n",
    "            # print df2_2.head()\n",
    "\n",
    "            # Get the price at that index\n",
    "            vocabulary_mimimum_word_frequency = df2_3.loc[\n",
    "                df2_3['cumsum'].idxmax(), 'total']  # int(list(df2_2['total'].iloc[myindex])[0])\n",
    "\n",
    "            if vocabulary_mimimum_word_frequency == 1:\n",
    "                vocabulary_mimimum_word_frequency = 0  # since 1 is going to prune a lot of words\n",
    "            print(\"Quantile based Minimum Frequency for %s is %s\" % (\n",
    "            vocabulary_mimimum_word_frequency_quantile, vocabulary_mimimum_word_frequency))\n",
    "            # df2 = df2[df2['total'] > vocabulary_mimimum_word_frequency]\n",
    "            # print \"xxxxxxx\", df2.head()\n",
    "\n",
    "            # print \"xxxxx\", df2.head()\n",
    "\n",
    "            if vocabulary_maximum_size and not convert_output_to_binary:\n",
    "                df2 = df2[(df2.index > vocabulary_maximum_size) | (\n",
    "                            df2['total'] < vocabulary_mimimum_word_frequency)]  # TODO: make it <=\n",
    "            else:\n",
    "                df2 = df2[(df2.index > math.pow(2, bit_size) - bit_size_offset) | (df2[\n",
    "                                                                                       'total'] < vocabulary_mimimum_word_frequency)]  # we subtract words to allow for the dummy word to be also stored.\n",
    "\n",
    "            # print \"xxxxx\", df2.head()\n",
    "\n",
    "            # vocabulary_mimimum_word_frequency = np.quantile(encode_mem_accesses(list(encoded_raw_diff_str)), vocabulary_mimimum_word_frequency_quantile) # angelos version  , vocabulary_mimimum_word_frequency_quantile)\n",
    "\n",
    "            # Set a dummy value to represent the ignored deltas. This will be converted later to a unique integer using a second tokenizer.\n",
    "            # print \"Length2 %s\" % len(df2.index)\n",
    "            df.loc[df.delta.isin(df2.delta), ['delta']] = dummy_word\n",
    "\n",
    "            # print \"xxxxxx\", df[df['delta'] == dummy_word]\n",
    "            # print \"Length1 %s\" % len(df.index)\n",
    "\n",
    "            # print df.head()\n",
    "            # print df[df['delta'] == dummy_word]\n",
    "            # df.describe()\n",
    "            encoded_raw_diff_pruned = df['delta']\n",
    "            # print \"AAA3\", encoded_raw_diff_pruned.head()\n",
    "            # print \"V3\"\n",
    "            # print encoded_raw_diff_pruned.head()\n",
    "\n",
    "            # print \"pruned\", encoded_raw_diff_pruned[:300]\n",
    "            del df, df2\n",
    "\n",
    "            # Calclulate accuracy reduction due to vocabulary pruning.\n",
    "            tmp_train, tmp_test = train_test_split(encoded_raw_diff_pruned, test_size=test_ratio, shuffle=False)\n",
    "            total_removals = Counter(encoded_raw_diff_pruned)[dummy_word]\n",
    "            total_rows = len(encoded_raw_diff_pruned)\n",
    "            train_removals = Counter(tmp_train)[dummy_word]\n",
    "            train_total = len(tmp_train)\n",
    "            test_removals = Counter(tmp_test)[dummy_word]\n",
    "            test_total = len(tmp_test)\n",
    "            print(total_removals, total_rows, train_removals, train_total, test_removals, test_total)\n",
    "            max_test_accuracy = 1 - test_removals / test_total\n",
    "            print(\"Max Accuracy: %s\" % max_test_accuracy)\n",
    "            print(\"Total Removals: %s\" % total_removals)\n",
    "\n",
    "            # Tokenize again the pruned differentials to produce unique vocabulary (classes)\n",
    "            encoded_raw_diff_pruned_str = [str(x) for x in list(encoded_raw_diff_pruned)]\n",
    "            tokenizer2 = Tokenizer()\n",
    "            tokenizer2.fit_on_texts(encoded_raw_diff_pruned_str)\n",
    "            encoded_final = tokenizer2.texts_to_sequences([' '.join(encoded_raw_diff_pruned_str)])[0]\n",
    "            final_vocab_size = len(tokenizer2.word_index) + 1\n",
    "            print('Pruned Vocabulary Size: %d' % final_vocab_size)\n",
    "\n",
    "            for word, index in tokenizer2.word_index.items():\n",
    "                if word == dummy_word:\n",
    "                    print(\"%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\", word, index)\n",
    "                    dummy_word_index = index\n",
    "                    break\n",
    "        #             set_plot_size(6,6)\n",
    "        #             _ = plt.hist(encoded_final, bins=100)\n",
    "        #             _ = plt.grid(True)\n",
    "        #             _ = plt.title(\"Histogram Of All Memory Deltas After Prunning\\nFor The %s App\" % app_name)\n",
    "        #             _ = plt.show()\n",
    "\n",
    "        else:\n",
    "            tokenizer = Tokenizer()\n",
    "            tokenizer.fit_on_texts(list(dataset))\n",
    "            encoded_final = tokenizer.texts_to_sequences([' '.join(list(dataset))])[0]\n",
    "            final_vocab_size = len(tokenizer.word_index) + 1\n",
    "    else:\n",
    "        # TODO: move this in the diff section or remove completely.\n",
    "        encoded_final = encode_mem_accesses(list(dataset))  # angelos version\n",
    "        final_vocab_size = len(set(encoded_final)) + 1\n",
    "\n",
    "    if decompose_timeseries:\n",
    "        # TODO: this is incomplete. Either fix or remove completely.\n",
    "        dataset = get_timeseries_decomposition(encoded_final, decomposition_frequency)[\n",
    "            2]  # TODO add back in the predictions the trend and seasonality\n",
    "        final_vocab_size = len(set(dataset)) + 1\n",
    "\n",
    "    # The series below are for visulaization purposes only.\n",
    "    if plot_timeseries:\n",
    "        if model_diffs:\n",
    "            encoded_raw_train, encoded_raw_test = train_test_split(encoded_raw, test_size=test_ratio, shuffle=False)\n",
    "            encoded_raw_diff_train, encoded_raw_diff_test = train_test_split(encoded_raw_diff, test_size=test_ratio,\n",
    "                                                                             shuffle=False)\n",
    "            plot_memory_trace(train_data=encoded_raw_train, test_data=encoded_raw_test, rows=200000, app_name=app_name,\n",
    "                              scenario_name=scenario_name + \" Raw\")\n",
    "            plot_memory_trace(train_data=encoded_raw_diff_train, test_data=encoded_raw_diff_test, rows=200000,\n",
    "                              app_name=app_name, scenario_name=scenario_name + \" Raw Diff\")\n",
    "\n",
    "        encoded_train, encoded_test = train_test_split(encoded_final, test_size=test_ratio, shuffle=False)\n",
    "        plot_memory_trace(train_data=encoded_train, test_data=encoded_test, rows=2000, app_name=app_name,\n",
    "                          scenario_name=scenario_name + \" Final\")\n",
    "\n",
    "    sequences = create_windowed_dataset(encoded_final, look_back)\n",
    "\n",
    "    print('Final Vocabulary Size: %d' % final_vocab_size)\n",
    "    print('Total Sequences: %d' % len(sequences))\n",
    "\n",
    "    # Pad the sequences to the same length (is not really needed here since we have fixed input windows).\n",
    "    # See documentation in the source code here: https://github.com/keras-team/keras-preprocessing/blob/master/keras_preprocessing/sequence.py\n",
    "    max_length = max([len(seq) for seq in sequences])\n",
    "    sequences = pad_sequences(sequences, maxlen=max_length, padding='pre')\n",
    "\n",
    "    # print encoded_final, sequences, final_vocab_size\n",
    "\n",
    "    return encoded_final, sequences, final_vocab_size, tokenizer, tokenizer2, max_test_accuracy, max_length, dummy_word, dummy_word_index, dummy_index, vocab_size_raw\n",
    "\n",
    "# In[] Define LSTM model\n",
    "def run_lstm_model(scenario=None):\n",
    "    \"\"\"\n",
    "    Encode the sequence of memory addresses to a sequence of integers\n",
    "    We can do it either using Keras, or by implementing our own convertion function (see above \"encode_mem_accesses\")\n",
    "    For the Keras approach, see documentation in the source code here: https://github.com/keras-team/keras-preprocessing/blob/master/keras_preprocessing/text.py\n",
    "    \"\"\"\n",
    "\n",
    "    use_manual_encoding = scenario['use_manual_encoding']\n",
    "    app_name = scenario['app_name']\n",
    "    decompose_timeseries = scenario['decompose_timeseries']\n",
    "    decomposition_frequency = scenario['decomposition_frequency']\n",
    "    test_ratio = scenario['test_ratio']\n",
    "    on_the_fly_testing = scenario['on_the_fly_testing']\n",
    "    plot_timeseries = scenario['plot_timeseries']\n",
    "    look_back = scenario['look_back_window']\n",
    "    scenario_name = scenario['scenario_name']\n",
    "    vocabulary_maximum_size = scenario['vocabulary_maximum_size']\n",
    "    vocabulary_mimimum_word_frequency_quantile = scenario['vocabulary_mimimum_word_frequency_quantile']\n",
    "    model_diffs = scenario['model_diffs']\n",
    "    lstm_batch_size = scenario['lstm_batch_size']\n",
    "    lstm_epochs = scenario['lstm_epochs']\n",
    "    verbosity = scenario['verbosity']\n",
    "    dropout_ratio = scenario['dropout_ratio']\n",
    "    lstm_size = scenario['lstm_size']\n",
    "    embedding_size = scenario['embedding_size']\n",
    "    prediction_batch_size = scenario['prediction_batch_size']\n",
    "    online_retraining = scenario['online_retraining']\n",
    "    online_learning_accuracy_threshold = scenario['online_learning_accuracy_threshold']\n",
    "    online_retraining_periods = scenario['online_retraining_periods']\n",
    "    online_retraining_period_size = scenario['online_retraining_period_size']\n",
    "    number_of_rows_to_model = scenario['number_of_rows_to_model']\n",
    "    model_type = scenario['model_type']\n",
    "    loss_function = scenario['loss_function']\n",
    "    activation_fuction = scenario['activation_function']\n",
    "    convert_output_to_binary = scenario['convert_output_to_binary']  # this is used for FPGA implementation.\n",
    "    bit_size = scenario['bit_size']\n",
    "    load_existing_pickles = scenario['load_existing_pickles']\n",
    "    unique_key = abs(hash(frozenset(scenario.items())))\n",
    "\n",
    "    misc_stats = {}\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    if online_retraining:\n",
    "        \"\"\"\n",
    "        This implements the online training/testing/retraining cyble of SDH project.\n",
    "        \"\"\"\n",
    "        retraining_period_counter = 1\n",
    "\n",
    "        # =====================================================================================================\n",
    "        # Data preparation\n",
    "        # =====================================================================================================\n",
    "        encoded_final, sequences, final_vocab_size, tokenizer, tokenizer2, max_test_accuracy, max_length, dummy_word, dummy_word_index, dummy_index,\\\n",
    "        vocab_size_raw = dataset_creator(scenario)\n",
    "        # =====================================================================================================\n",
    "\n",
    "        # =====================================================================================================\n",
    "        # Neural Network Configuration\n",
    "        # =====================================================================================================\n",
    "        if convert_output_to_binary:\n",
    "            # print final_vocab_size, embedding_size, max_length-1\n",
    "            model = Sequential()\n",
    "            model.add(Embedding(final_vocab_size, embedding_size, input_length=max_length - 1))\n",
    "            if USE_GPU:\n",
    "                model.add(CuDNNLSTM(lstm_size))\n",
    "            else:\n",
    "                model.add(LSTM(lstm_size))\n",
    "            model.add(Dropout(dropout_ratio))\n",
    "            model.add(Dense(bit_size,\n",
    "                            activation=activation_fuction))  # the size of this layer should align with the size of the bit representation of the output.\n",
    "            model.compile(loss=loss_function, optimizer='adam', metrics=[\n",
    "                'accuracy'])  # top_k_categorical_accuracy is still wrong but we have it for illustration purposes.\n",
    "        else:\n",
    "            model = Sequential()\n",
    "            model.add(Embedding(final_vocab_size, embedding_size, input_length=max_length - 1))\n",
    "\n",
    "            if USE_GPU:\n",
    "                model.add(CuDNNLSTM(lstm_size))\n",
    "            else:\n",
    "                model.add(LSTM(lstm_size))\n",
    "            model.add(Dropout(dropout_ratio))\n",
    "            model.add(Dense(final_vocab_size, activation=activation_fuction))\n",
    "            model.compile(loss=loss_function, optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "        if verbosity > 0:\n",
    "            print(model.summary())\n",
    "        SVG(model_to_dot(model, show_shapes=True, show_layer_names=False).create(prog='dot', format='svg'))\n",
    "        plot_model(model, to_file=NOTEBOOK_PLOTS_DIRECTORY + 'model_for_%s.png' % scenario_name, show_shapes=True,\n",
    "                   show_layer_names=False)\n",
    "        # =====================================================================================================\n",
    "\n",
    "        # =====================================================================================================\n",
    "        # Model training/testing\n",
    "        # =====================================================================================================\n",
    "\n",
    "        X, y = sequences[:, :-1], sequences[:, -1]\n",
    "        # print \"A4\", sequences\n",
    "        # Vectorize the output y (one hot encoding)\n",
    "        if convert_output_to_binary:\n",
    "            y = convert_to_binary(data=y, bit_size=bit_size)  # converts diffs to 16 bit representation\n",
    "        else:\n",
    "            y = to_categorical(y, num_classes=final_vocab_size)\n",
    "        # print \"A5\", y\n",
    "        period_online_learning_accuracy = []\n",
    "        period_online_learning_accuracy_avg = 0\n",
    "\n",
    "        overall_online_learning_accuracy = []  # tracks the time series of accuracy overall (never reset)\n",
    "        overall_retrain_tracker = []  # tracks when retrain happens for plotting purposes\n",
    "\n",
    "        # X = np.array([np.array(tmp_x) for tmp_x in X])\n",
    "        # y = np.matrix([np.array(tmp_y) for tmp_y in y])\n",
    "        # y = np.asarray(y, dtype=int)\n",
    "\n",
    "        X_train, X_test = train_test_split(X, train_size=number_of_rows_to_model,\n",
    "                                           test_size=online_retraining_period_size, shuffle=False)\n",
    "        \n",
    "        y_train, y_test = train_test_split(y, train_size=number_of_rows_to_model,\n",
    "                                           test_size=online_retraining_period_size, shuffle=False)\n",
    "\n",
    "        # y_train = np.array([np.array(x) for x in y_train])#np.array(y_train).reshape(len(y_train), 16)\n",
    "        # y_test = np.array([np.array(x) for x in y_test]) #np.asanyarray(y_test).reshape(len(y_train), 16)\n",
    "        # print \"A1\", y_train, y_test, y\n",
    "\n",
    "        # =====================================================================================================\n",
    "        # IMPORTANT: The code below modifies the dummy word mappings to be forcing a false positive to be counted.\n",
    "        if max_test_accuracy < 1:\n",
    "            print(\"Overwritting Ignored Words...\")\n",
    "            print(dummy_word_index)\n",
    "            if convert_output_to_binary:\n",
    "                y_test = np.array([[0 for tmp2 in tmp1] if all(\n",
    "                    tmp1 == convert_to_binary(data=[dummy_word_index], bit_size=bit_size)[0]) else tmp1 for tmp1 in\n",
    "                                   y_test])\n",
    "            else:\n",
    "                y_test = np.array(\n",
    "                    [[0 for tmp2 in tmp1] if argmax(tmp1) == dummy_word_index else tmp1 for tmp1 in y_test])\n",
    "            print(\"Overwritting Ignored Words Completted\")\n",
    "        # =====================================================================================================\n",
    "\n",
    "        while retraining_period_counter <= online_retraining_periods:\n",
    "            # Train the model either the first time or if the accuracy deteriorates\n",
    "            if retraining_period_counter == 1 or period_online_learning_accuracy_avg < online_learning_accuracy_threshold:\n",
    "                print(\"Retraining after %d periods\" % len(period_online_learning_accuracy))\n",
    "                model_file_name = NOTEBOOK_PICKLES_DIRECTORY + \"%s_retrain_at_period_%s_%s_8.h5\" % (\n",
    "                scenario_name, retraining_period_counter, unique_key)\n",
    "\n",
    "                if load_existing_pickles and os.path.isfile(model_file_name):\n",
    "                    model = load_model(model_file_name)\n",
    "                    train_history = None\n",
    "                    train_accuracy = -1  # train_history.history['acc'][-1]\n",
    "                else:\n",
    "                    train_history = model.fit(X_train,\n",
    "                                              y_train,\n",
    "                                              epochs=lstm_epochs,\n",
    "                                              verbose=verbosity,\n",
    "                                              shuffle=False,\n",
    "                                              batch_size=lstm_batch_size)\n",
    "\n",
    "                    model.save(model_file_name)\n",
    "                    train_accuracy = train_history.history['accuracy'][-1]\n",
    "                    period_online_learning_accuracy = []  # reset stats for the new period\n",
    "                    overall_retrain_tracker.append(1)\n",
    "            else:\n",
    "                overall_retrain_tracker.append(0)\n",
    "\n",
    "            if convert_output_to_binary:\n",
    "                time_s=time.time()\n",
    "                y_pred = model.predict([1,1,1])\n",
    "                print(\"time:\",time.time()-time_s)\n",
    "                print(\"1X_test:\",X_test)\n",
    "\n",
    "                y_pred[y_pred >= 0.5] = 1\n",
    "                y_pred[y_pred < 0.5] = 0\n",
    "\n",
    "                accuracy = accuracy_score(np.array(y_test), np.array(y_pred))\n",
    "\n",
    "                aaaaa = np.packbits(np.array(y_test, dtype=np.bool).reshape(-1, 2, 8)[:, ::-1]).view(np.uint16)\n",
    "                bbbbb = np.packbits(np.array(y_pred, dtype=np.bool).reshape(-1, 2, 8)[:, ::-1]).view(np.uint16)\n",
    "\n",
    "                np.savetxt('%s/y_test_%s.txt' % (NOTEBOOK_DATA_DIRECTORY, scenario_name), aaaaa, delimiter=',',\n",
    "                           fmt='%10.5f')\n",
    "                np.savetxt('%s/y_pred_%s.txt' % (NOTEBOOK_DATA_DIRECTORY, scenario_name), bbbbb, delimiter=',',\n",
    "                           fmt='%10.5f')\n",
    "\n",
    "            else:\n",
    "                test_history = model.evaluate(X_test,\n",
    "                                              y_test,\n",
    "                                              batch_size=prediction_batch_size,\n",
    "                                              verbose=verbosity)\n",
    "                print(\"X_test:\",X_test)\n",
    "                accuracy = test_history[1]\n",
    "\n",
    "            period_online_learning_accuracy.append(accuracy)\n",
    "            period_online_learning_accuracy_avg = np.array([period_online_learning_accuracy]).mean()\n",
    "            overall_online_learning_accuracy.append(accuracy)\n",
    "            print(\"Overall Online Accuracy\", overall_online_learning_accuracy)\n",
    "\n",
    "            retraining_period_counter += 1\n",
    "            # print \"A3\", y, (retraining_period_counter-1)*online_retraining_period_size, y.shape\n",
    "            X_train, X_test = train_test_split(X[(retraining_period_counter - 1) * online_retraining_period_size:, :],\n",
    "                                               train_size=number_of_rows_to_model,\n",
    "                                               test_size=online_retraining_period_size, shuffle=False)\n",
    "            y_train, y_test = train_test_split(y[(retraining_period_counter - 1) * online_retraining_period_size:, :],\n",
    "                                               train_size=number_of_rows_to_model,\n",
    "                                               test_size=online_retraining_period_size, shuffle=False)\n",
    "\n",
    "            y_train = np.asanyarray(y_train)\n",
    "            y_test = np.asanyarray(y_test)\n",
    "\n",
    "            # =====================================================================================================\n",
    "            # IMPORTANT: The code below modifies the dummy word mappings to be forcing a false positive to be counted.\n",
    "            if max_test_accuracy < 1:\n",
    "                print(\"Overwritting Ignored Words...\")\n",
    "                print(dummy_word_index)\n",
    "                if convert_output_to_binary:\n",
    "                    y_test = np.array([[0 for tmp2 in tmp1] if all(\n",
    "                        tmp1 == convert_to_binary(data=[dummy_word_index], bit_size=bit_size)[0]) else tmp1 for tmp1 in\n",
    "                                       y_test])\n",
    "                else:\n",
    "                    y_test = np.array(\n",
    "                        [[0 for tmp2 in tmp1] if argmax(tmp1) == dummy_word_index else tmp1 for tmp1 in y_test])\n",
    "                print(\"Overwritting Ignored Words Completted\")\n",
    "            # =====================================================================================================\n",
    "\n",
    "        # plot the online learning/retraining graph only at the end.\n",
    "        if len(overall_online_learning_accuracy) > 1:\n",
    "            set_plot_size(20, 8)\n",
    "            _ = plt.figure()\n",
    "            _ = plt.plot(range(1, len(overall_online_learning_accuracy) + 1), overall_online_learning_accuracy,\n",
    "                         linestyle='-', marker='^', markersize=8, linewidth=2)\n",
    "\n",
    "            for index, val in enumerate(overall_retrain_tracker):\n",
    "                if val == 1 and index > 0:\n",
    "                    # we don't flag as retraining the beginning of the testing phase\n",
    "                    _ = plt.annotate('retrained', fontsize=22, xy=(index + 1, overall_online_learning_accuracy[index]),\n",
    "                                     xytext=(index + 1.15, overall_online_learning_accuracy[index] + 0.15),\n",
    "                                     arrowprops=dict(facecolor='black', arrowstyle=\"->\"))\n",
    "\n",
    "            _ = plt.title(\"Online Testing Accuracy Over Time\\nFor The %s App\" % (app_name))\n",
    "            _ = plt.xlabel(\"Program Execution\")\n",
    "            _ = plt.ylabel(\"Accuracy\")\n",
    "            # _ = plt.legend(['Accuracy'], loc='upper left')\n",
    "            _ = plt.ylim(0, 1.2)\n",
    "            _ = plt.xlim(0.5, len(overall_online_learning_accuracy) + 0.5)\n",
    "            _ = plt.grid(True)\n",
    "            _ = plt.savefig(NOTEBOOK_PLOTS_DIRECTORY + \"online_accuracy_%s.eps\" % (scenario_name), bbox_inches='tight')\n",
    "            _ = plt.show(block=False)\n",
    "\n",
    "        # TODO: fix to return average of all\n",
    "        np.savetxt('%s/accuracy_%s.txt' % (NOTEBOOK_REPORT_DIRECTORY, scenario_name),\n",
    "                   np.array([overall_online_learning_accuracy]), delimiter=',', fmt='%10.5f')\n",
    "        np.savetxt('%s/online_retraining_tracker_%s.txt' % (NOTEBOOK_REPORT_DIRECTORY, scenario_name),\n",
    "                   np.array([overall_retrain_tracker]), delimiter=',', fmt='%10.5f')\n",
    "\n",
    "        misc_stats['execution_time'] = time.time() - start_time\n",
    "        misc_stats['vocab_size_raw'] = vocab_size_raw\n",
    "        misc_stats['final_vocab_size'] = final_vocab_size\n",
    "        misc_stats['params'] = model.count_params()\n",
    "        misc_stats['max_test_accuracy'] = max_test_accuracy\n",
    "\n",
    "        return train_history.history['accuracy'][-1], np.array(\n",
    "            overall_online_learning_accuracy).mean(), misc_stats  # test_history[1]\n",
    "\n",
    "        # print \"Train Accuracy %f, Test Accuracy %f\" % (train_accuracy, accuracy)\n",
    "        # return train_accuracy, accuracy, misc_stats\n",
    "\n",
    "    else:\n",
    "        # =====================================================================================================\n",
    "        # Data preparation\n",
    "        # =====================================================================================================\n",
    "        encoded_final, sequences, final_vocab_size, tokenizer, tokenizer2, max_test_accuracy, max_length, dummy_word, \\\n",
    "        dummy_word_index, dummy_index, vocab_size_raw = dataset_creator(\n",
    "            scenario)\n",
    "        # =====================================================================================================\n",
    "\n",
    "        # =====================================================================================================\n",
    "        # Neural Network Configuration\n",
    "        # =====================================================================================================\n",
    "        if convert_output_to_binary:\n",
    "            model = Sequential()\n",
    "            model.add(Embedding(final_vocab_size, embedding_size, input_length=max_length - 1))\n",
    "            if USE_GPU:\n",
    "                model.add(CuDNNLSTM(lstm_size))\n",
    "            else:\n",
    "                model.add(LSTM(lstm_size))\n",
    "            model.add(Dropout(dropout_ratio))\n",
    "            model.add(Dense(bit_size,\n",
    "                            activation=activation_fuction))  # the size of this layer should align with the size of the bit representation of the output.\n",
    "            model.compile(loss=loss_function, optimizer='adam', metrics=[\n",
    "                'accuracy'])  # top_k_categorical_accuracy is still wrong but we have it for illustration purposes.\n",
    "        else:\n",
    "            model = Sequential()\n",
    "            model.add(Embedding(final_vocab_size, embedding_size, input_length=max_length - 1))\n",
    "\n",
    "            if USE_GPU:\n",
    "                model.add(CuDNNLSTM(lstm_size))\n",
    "            else:\n",
    "                model.add(LSTM(lstm_size))\n",
    "            model.add(Dropout(dropout_ratio))\n",
    "            model.add(Dense(final_vocab_size, activation=activation_fuction))\n",
    "            model.compile(loss=loss_function, optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "        if verbosity > 0:\n",
    "            print(model.summary())\n",
    "        SVG(model_to_dot(model, show_shapes=True, show_layer_names=False).create(prog='dot', format='svg'))\n",
    "        plot_model(model, to_file=NOTEBOOK_PLOTS_DIRECTORY + 'model_for_%s.png' % scenario_name, show_shapes=True,\n",
    "                   show_layer_names=False)\n",
    "        # =====================================================================================================\n",
    "\n",
    "        # =====================================================================================================\n",
    "        # Model training/testing\n",
    "        # =====================================================================================================\n",
    "        X, y = sequences[:, :-1], sequences[:, -1]\n",
    "        # print X.shape, y.shape\n",
    "        # print \"A11\", y\n",
    "        # y = y.reshape((16, len(y)))\n",
    "\n",
    "        # print \"A7\", sequences\n",
    "        # Vectorize the output y (one hot encoding)\n",
    "        if convert_output_to_binary:\n",
    "            y = convert_to_binary(data=y, bit_size=bit_size)  # converts diffs to 16 bit representation\n",
    "        else:\n",
    "            y = to_categorical(y, num_classes=final_vocab_size)\n",
    "\n",
    "        # print y\n",
    "        # y = np.array([np.array(tmp_y) for tmp_y in y])\n",
    "        # y = y.reshape((y.shape[0], 16))\n",
    "        # print X.shape, y.shape\n",
    "        # print \"A8\", y.reshape(1, -1)\n",
    "\n",
    "        if on_the_fly_testing:\n",
    "            # TODO: fix the portion used for y_test to account for the pruned vocabulary\n",
    "            history = model.fit(X,\n",
    "                                y,\n",
    "                                validation_split=test_ratio,\n",
    "                                epochs=lstm_epochs,\n",
    "                                batch_size=lstm_batch_size,\n",
    "                                verbose=verbosity,\n",
    "                                shuffle=False)\n",
    "\n",
    "            save_obj(directory=NOTEBOOK_PICKLES_DIRECTORY, obj=model, name=\"%s_on_the_fly_testing\" % (scenario_name))\n",
    "            plot_on_the_fly_model_performance(history, app_name=app_name, scenario_name=scenario_name)\n",
    "\n",
    "            # TODO: fix max accuracy multiplier to be done automatically\n",
    "            np.savetxt('%s/accuracy_%s.txt' % (NOTEBOOK_REPORT_DIRECTORY, scenario_name),\n",
    "                       np.array([history.history['val_acc'][-1] * max_test_accuracy]), delimiter=',', fmt='%10.5f')\n",
    "            return history.history['accuracy'][-1] * max_test_accuracy, history.history['val_acc'][\n",
    "                -1] * max_test_accuracy, misc_stats\n",
    "\n",
    "        else:\n",
    "            X_train, X_test = train_test_split(X, test_size=test_ratio, shuffle=False)\n",
    "            y_train, y_test = train_test_split(y, test_size=test_ratio, shuffle=False)\n",
    "            # print \"A2\", y_train, y_test, y\n",
    "            # print X, X_train, X_test\n",
    "            # print y, y_train, y_test\n",
    "\n",
    "            # =====================================================================================================\n",
    "            # IMPORTANT: The code below modifies the dummy word mappings to be forcing a false positive to be counted.\n",
    "            if max_test_accuracy < 1:\n",
    "                print(\"Overwritting Ignored Words...\")\n",
    "                print(dummy_word_index)\n",
    "                if convert_output_to_binary:\n",
    "                    # print \"AA2\", y_test\n",
    "                    # for el in y_test:\n",
    "                    # print \"AA3\", el\n",
    "                    # print convert_to_binary(data=[dummy_word_index], bit_size=bit_size)\n",
    "                    # break\n",
    "                    # print pd.DataFrame(y_test).describe()\n",
    "                    # y_test = np.array([[0 for tmp2 in tmp1] if all(tmp1 == convert_to_binary(data=[dummy_word_index], bit_size=bit_size)[0]) else tmp1 for tmp1 in y_test])\n",
    "                    y_test = np.array([[0 for tmp2 in tmp1] if np.array_equal(tmp1,\n",
    "                                                                              convert_to_binary(data=[dummy_word_index],\n",
    "                                                                                                bit_size=bit_size)[\n",
    "                                                                                  0]) else tmp1 for tmp1 in y_test])\n",
    "\n",
    "                else:\n",
    "                    y_test = np.array(\n",
    "                        [[0 for tmp2 in tmp1] if argmax(tmp1) == dummy_word_index else tmp1 for tmp1 in y_test])\n",
    "                print(\"Overwritting Ignored Words Completted\")\n",
    "            # =====================================================================================================\n",
    "            # print X_train, y_train\n",
    "            model_file_name = NOTEBOOK_PICKLES_DIRECTORY + \"%s_train_test_split_%s_128.h5\" % (scenario_name, unique_key)\n",
    "\n",
    "            if load_existing_pickles and os.path.isfile(model_file_name):\n",
    "                model = load_model(model_file_name)\n",
    "                train_history = None\n",
    "                train_accuracy = -1  # train_history.history['acc'][-1]\n",
    "            else:\n",
    "                train_history = model.fit(X_train,\n",
    "                                          y_train,\n",
    "                                          epochs=lstm_epochs,\n",
    "                                          verbose=verbosity,\n",
    "                                          shuffle=False,\n",
    "                                          batch_size=lstm_batch_size)\n",
    "\n",
    "                model.save(model_file_name)\n",
    "                train_accuracy = train_history.history['accuracy'][-1]\n",
    "\n",
    "            if convert_output_to_binary:\n",
    "                time_s=time.time()\n",
    "                y_pred = model.predict(X_test)\n",
    "                print(\"time:\",time.time()-time_s)\n",
    "                print(\"2X_test:\",X_test)\n",
    "                # np.savetxt('y_test1.txt', y_test, delimiter=',')\n",
    "                # np.savetxt('y_pred1.txt', y_pred, delimiter=',')\n",
    "\n",
    "                y_pred[y_pred >= 0.5] = 1\n",
    "                y_pred[y_pred < 0.5] = 0\n",
    "\n",
    "                # np.savetxt('y_test2.txt', y_test, delimiter=',')\n",
    "                # np.savetxt('y_pred2.txt', y_pred, delimiter=',')\n",
    "\n",
    "                aaaaa = np.packbits(np.array(y_test, dtype=np.bool).reshape(-1, 2, 8)[:, ::-1]).view(np.uint16)\n",
    "                bbbbb = np.packbits(np.array(y_pred, dtype=np.bool).reshape(-1, 2, 8)[:, ::-1]).view(np.uint16)\n",
    "                # print \"ANGELOS\", scenario_name\n",
    "                np.savetxt('%s/y_test_%s.txt' % (NOTEBOOK_DATA_DIRECTORY, scenario_name), aaaaa, delimiter=',',\n",
    "                           fmt='%10.5f')\n",
    "                np.savetxt('%s/y_pred_%s.txt' % (NOTEBOOK_DATA_DIRECTORY, scenario_name), bbbbb, delimiter=',',\n",
    "                           fmt='%10.5f')\n",
    "\n",
    "                #                 plt.plot(aaaaa)\n",
    "                #                 plt.show()\n",
    "                #                 plt.plot(bbbbb)\n",
    "                #                 plt.title(\"Predictions vs Actual Data\")\n",
    "                #                 plt.show()\n",
    "\n",
    "                accuracy = accuracy_score(np.array(y_test), np.array(y_pred))\n",
    "                test_history = [0, accuracy]  # for backwards compatibility\n",
    "            else:\n",
    "                test_history = model.evaluate(X_test,\n",
    "                                              y_test,\n",
    "                                              batch_size=prediction_batch_size,\n",
    "                                              verbose=verbosity)\n",
    "                accuracy = test_history[1]\n",
    "                np.savetxt('%s/y_test_%s.txt' % (NOTEBOOK_DATA_DIRECTORY, scenario_name), [-1], delimiter=',',\n",
    "                           fmt='%10.5f')  # too much data; cannot be exported for efficiency reasons\n",
    "                np.savetxt('%s/y_pred_%s.txt' % (NOTEBOOK_DATA_DIRECTORY, scenario_name), [-1], delimiter=',',\n",
    "                           fmt='%10.5f')  # too much data; cannot be exported for efficiency reasons\n",
    "\n",
    "            misc_stats['execution_time'] = time.time() - start_time\n",
    "            misc_stats['vocab_size_raw'] = vocab_size_raw\n",
    "            misc_stats['final_vocab_size'] = final_vocab_size\n",
    "            misc_stats['params'] = model.count_params()\n",
    "            misc_stats['max_test_accuracy'] = max_test_accuracy\n",
    "\n",
    "            np.savetxt('%s/accuracy_%s.txt' % (NOTEBOOK_REPORT_DIRECTORY, scenario_name), np.array([accuracy]),\n",
    "                       delimiter=',', fmt='%10.5f')\n",
    "            plot_train_test_model_performance(train_history, test_history, app_name=app_name,\n",
    "                                              scenario_name=scenario_name)\n",
    "\n",
    "            print(\"Train Accuracy %f, Test Accuracy %f\" % (train_accuracy, accuracy))\n",
    "            return train_accuracy, accuracy, misc_stats\n",
    "            # =====================================================================================================\n",
    "\n",
    "# In [] Customizations\n",
    "from tensorflow.python.ops import math_ops\n",
    "from tensorflow.python.framework import ops\n",
    "from keras.backend import epsilon\n",
    "from tensorflow.python.ops import clip_ops\n",
    "from tensorflow.python.ops import nn\n",
    "\n",
    "\n",
    "def custom_cross_entropy(target, output, from_logits=False, axis=-1):\n",
    "    target = target[:, :-4]\n",
    "    output = output[:, :-4]\n",
    "\n",
    "    if not from_logits:\n",
    "        # transform back to logits\n",
    "        epsilon_ = ops.convert_to_tensor(epsilon(), dtype=output.dtype.base_dtype)\n",
    "        output = clip_ops.clip_by_value(output, epsilon_, 1 - epsilon_)\n",
    "        output = math_ops.log(output / (1 - output))\n",
    "    return nn.sigmoid_cross_entropy_with_logits(labels=target, logits=output)\n",
    "\n",
    "# In[] Model Evaluation Scenarios\n",
    "\n",
    "#Important Notes\n",
    "\n",
    "# Swaptions app needs a higher threshold for vocabulary capping. The best tried was 15. For the Blackscholes app we tried 5 and worked fine.\n",
    "\n",
    "trace_offsets = {\n",
    "    'swaptions_1_1M.out': 100000,\n",
    "}\n",
    "\n",
    "manager = Manager()\n",
    "\n",
    "all_results = manager.dict()  # this is for sharing data across processes and also store the features data that will be used for clustering\n",
    "\n",
    "modeling_scenarios = OrderedDict()\n",
    "\n",
    "\n",
    "def lstm_modeling_worker(scenario):\n",
    "    global all_results\n",
    "    import json\n",
    "\n",
    "    print(\"Executing Scenario %s\" % scenario['scenario_name'])\n",
    "\n",
    "    report_file_name = '%s/all_stats_%s_%s.json' % (NOTEBOOK_REPORT_DIRECTORY, scenario_name, scenario['id'])\n",
    "\n",
    "    if not scenario['skip_run_if_previous_stats_found'] or not os.path.isfile(report_file_name):\n",
    "        train_history, test_history, misc_stats = run_lstm_model(scenario)\n",
    "        all_results[scenario['scenario_name']] = [scenario, train_history, test_history, misc_stats]\n",
    "        '''\n",
    "        json = json.dumps(all_results[scenario['scenario_name']], indent=4)\n",
    "\n",
    "        f = open(report_file_name, \"w\")\n",
    "        f.write(json)\n",
    "        f.close()'''\n",
    "    else:\n",
    "        print(\"Skipping run since past results found for the same configuration...\")\n",
    "    return all_results\n",
    "\n",
    "# # 50/50 Split Analysis\n",
    "for trace in TRACE_FILE_NAMES:\n",
    "    if trace in [\n",
    "        'swaptions_1_1M.out',\n",
    "                 # 'swaptions_old_1_1M.out',\n",
    "                 # 'blackscholes_old_1_1M.out',\n",
    "                 # 'fluidanimate_old_1_1M.out'\n",
    "                 ]:\n",
    "        for model_type in [\"fpga\"]:  # \"vanilla\",  \"custom_loss_fpga\"\n",
    "            for pretrain_type in [\"rerun\", \"new\"]:\n",
    "                scenario_counter = 1\n",
    "                trace_short = trace.split(\".\")[0].replace(\"_mem\", \"\").capitalize()\n",
    "                for i in range(5, 6):\n",
    "                    # we store the scenario name as key, but also add it in the scenario configuration for availability in each function\n",
    "                    modeling_scenarios['LSTM_%s_Pretrained_%s_%s_%s' % (\n",
    "                        model_type.upper(), pretrain_type, scenario_counter, trace_short)] = {\n",
    "                        # trace params\n",
    "                        'scenario_name': 'LSTM_%s_Pretrained_%s_%s_%s' % (\n",
    "                            model_type.upper(), pretrain_type, scenario_counter, trace_short),\n",
    "                        'app_name': trace.split(\".\")[0].split(\"_\")[0].capitalize(),\n",
    "                        'trace_file_name': trace,\n",
    "                        'load_existing_pickles': True,\n",
    "                        'skip_run_if_previous_stats_found': True,\n",
    "\n",
    "                        # dataset params\n",
    "                        'keep_read_access_only': False,\n",
    "                        'number_of_rows_to_model': 400000,\n",
    "                        'number_of_rows_to_skip': trace_offsets[trace],  # int(TRACE_FILE_NAME_SIZES[trace]*3.0/5.0),\n",
    "                        'pretrain_type': pretrain_type,\n",
    "\n",
    "                        'model_diffs': True,\n",
    "                        # set to True if you want instead of the actual time series to model memory location differences.\n",
    "                        'vocabulary_maximum_size': 50000 if \"vanilla\" in model_type else 0,\n",
    "                        # this is to further reduce the dictionary size\n",
    "                        'vocabulary_mimimum_word_frequency_quantile': 0.95 if not \"fpga\" in model_type else 1,\n",
    "                        \"prune_lsb\": True if \"lsb\" in model_type else False,\n",
    "                        \"prune_length\": 1,\n",
    "                        # this corresponds to how many \"letters\" to be pruned from the HEX address (1 letter = 4 bits)\n",
    "                        \"bit_size\": 16,\n",
    "\n",
    "                        # Not Used\n",
    "                        'decompose_timeseries': False,  # not used #TODO: remove\n",
    "                        'decomposition_frequency': 10,  # not used #TODO: remove\n",
    "                        'use_manual_encoding': False,\n",
    "                        # not used #TODO: remove # True applies only to non-diff time series. --TODO: remove completely.\n",
    "\n",
    "                        # model params\n",
    "                        'model_type': model_type,  # None, #'fpga',\n",
    "                        'look_back_window': 3,\n",
    "                        'lstm_epochs': 2,\n",
    "                        'lstm_batch_size': 256,\n",
    "                        'lstm_size': 16,\n",
    "                        'dropout_ratio': 0.1,\n",
    "                        'embedding_size': 10,\n",
    "                        'verbosity': 1,\n",
    "                        'test_ratio': 0.1 * float(i),  # this does not apply to online learning\n",
    "                        'prediction_batch_size': 4096,  # this has an impact only if on_the_fly_testing is disabled\n",
    "                        'loss_function': 'categorical_crossentropy' if not \"fpga\" in model_type else \"binary_crossentropy\" if model_type in [\n",
    "                            \"fpga\", \"lsb_fpga\"] else custom_cross_entropy,\n",
    "                        # 'categorical_crossentropy', 'binary_crossentropy', # custom_crossentropy,  # binary_cross_entropy is needed for multi-label classification, otherwise we need categorical_crossentropy\n",
    "                        'activation_function': \"softmax\" if not \"fpga\" in model_type else \"sigmoid\",\n",
    "                        'convert_output_to_binary': True if \"fpga\" in model_type else False,\n",
    "\n",
    "                        # run-time params\n",
    "                        'on_the_fly_testing': False,\n",
    "                        # if True, it will run testing on the whole data for each epoch (good for plotting performance). Not used if online_retraining is enabled.\n",
    "                        'plot_timeseries': False,\n",
    "\n",
    "                        'online_retraining': False,\n",
    "                        # if this is True, then we model number_of_rows_to_model samples and then generate predictions for until the accuracy becomes smaller than online_learning_accuracy_threshold, and then we retrain etc.\n",
    "                        'online_learning_accuracy_threshold': 0.6,\n",
    "                        # It is used only if online_retraining is set to True.\n",
    "                        'online_retraining_periods': 5,  # It is used only if online_retraining is set to True.\n",
    "                        'online_retraining_period_size': 10000,\n",
    "                        # How many predictions to run before measuring cummulative accuracy for the given period. It is used only if online_retraining is set to True.\n",
    "                    }\n",
    "                    scenario_counter += 1\n",
    "\n",
    "                # calculate a unique ID for each scenario based on its values\n",
    "tmp_scenarios = modeling_scenarios.copy()\n",
    "for scenario_name, scenario in tmp_scenarios.items():\n",
    "    modeling_scenarios[scenario_name]['id'] = abs(hash(frozenset(scenario.items())))\n",
    "\n",
    "print (\"USE_GPU:\",USE_GPU)\n",
    "if not USE_GPU:\n",
    "    # with ProcessPoolExecutor(max_workers=NUMBER_OF_PROCESSES) as e:\n",
    "    for scenario_name, scenario in modeling_scenarios.items():\n",
    "        # e.submit(lstm_modeling_worker, scenario)\n",
    "        lstm_modeling_worker(scenario)\n",
    "else:\n",
    "    for scenario_name, scenario in modeling_scenarios.items():\n",
    "        lstm_modeling_worker(scenario)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 0.3886730670928955\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1.22219324e-04, 3.09258699e-03, 7.03305006e-04, 5.17368317e-04,\n",
       "        8.40455294e-04, 3.81946564e-04, 6.69538975e-04, 8.00669193e-04,\n",
       "        1.45098567e-03, 9.53307748e-03, 1.14919245e-02, 2.27427483e-02,\n",
       "        8.65122676e-03, 6.08502626e-02, 8.66370499e-02, 9.16935444e-01]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path=\"/home/pengmiao/Project/MEMSYS/Pem/data/output/notebooks/03_1/pickles/LSTM_FPGA_Pretrained_new_1_Swaptions_1_1m_train_test_split_5341913423611448998_16.h5\"\n",
    "model = load_model(file_path)\n",
    "import time\n",
    "x_p=np.array([[1,1,1]])\n",
    "time_s=time.time()\n",
    "y_p=model.predict(x_p)\n",
    "time_e=time.time()\n",
    "print(\"time:\",time_e-time_s)\n",
    "y_p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPU Inference time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Spyder Editor\n",
    "\n",
    "This is a temporary script file.\n",
    "\"\"\"\n",
    "%matplotlib inline\n",
    "import sys\n",
    "from utils import *\n",
    "X=[]\n",
    "\n",
    "if platform.system() == \"Linux\":\n",
    "    PROJECT_ROOT_DIRECTORY = \"/home/pengmiao/Project/MEMSYS/Pem/\"#\"/home/aggelos/projects/SDH/\"\n",
    "    sys.path.append(PROJECT_ROOT_DIRECTORY)\n",
    "    os.environ[\"TMP\"] = \"/tmp\"\n",
    "    USE_GPU = True\n",
    "else:\n",
    "    PROJECT_ROOT_DIRECTORY = \"E:/Lab/PyCharm/Pem_MEMSYS_try3/Anglos/\"\n",
    "    sys.path.append(PROJECT_ROOT_DIRECTORY)\n",
    "    USE_GPU = False\n",
    "\n",
    "DELETE_OLD_RESULTS = False\n",
    "\n",
    "NUMBER_OF_PROCESSES = 2\n",
    "\n",
    "PERFORM_EDA = False\n",
    "\n",
    "NOTEBOOK_ID = \"03_1\"\n",
    "\n",
    "README_TXT = \"\"\"# README\n",
    "## Ensemble modeling of memory access timeseries (using shapelets, LSTMs and more)\n",
    "\"\"\"\n",
    "###\n",
    "\n",
    "# Inputs:\n",
    "# TRACE_DIRECTORY = PROJECT_ROOT_DIRECTORY + \"data/input/\"\n",
    "#TRACE_DIRECTORY = \"E:/Lab/PyCharm/Pem_MEMSYS_try3/Anglos/data/\"\n",
    "TRACE_DIRECTORY =\"/home/pengmiao/Project/MEMSYS/data/\"\n",
    "TRACE_FILE_NAMES = [\n",
    "    'swaptions_1_1M.out'\n",
    "]  # more to be added here\n",
    "\n",
    "# Size of files in number of rows. This should be implemented as a single dict for both\n",
    "TRACE_FILE_NAME_SIZES = {\n",
    "    # \"swaptions_mem.out\": 66999281,\n",
    "    # \"blackscholes_mem.out\": 63141878,\n",
    "    # \"fluidanimate_mem.out\": 838028424\n",
    "\n",
    "    #'blackscholes_1.out': 63141878,\n",
    "    'swaptions_1_1M.out': 1000000\n",
    "\n",
    "}\n",
    "###\n",
    "\n",
    "# Outputs:\n",
    "NOTEBOOK_ROOT_DIRECTORY = PROJECT_ROOT_DIRECTORY + \"data/output/notebooks/%s/\" % NOTEBOOK_ID\n",
    "\n",
    "NOTEBOOK_PLOTS_DIRECTORY = NOTEBOOK_ROOT_DIRECTORY + \"figs/\"\n",
    "\n",
    "NOTEBOOK_DATA_DIRECTORY = NOTEBOOK_ROOT_DIRECTORY + \"data/\"\n",
    "\n",
    "NOTEBOOK_PICKLES_DIRECTORY = NOTEBOOK_ROOT_DIRECTORY + \"pickles/\"\n",
    "\n",
    "NOTEBOOK_REPORT_DIRECTORY = NOTEBOOK_ROOT_DIRECTORY + \"reports/\"\n",
    "\n",
    "###\n",
    "\n",
    "CURRENT_TIMESTAMP = get_current_timestamp()\n",
    "setup_report(data_dir=NOTEBOOK_ROOT_DIRECTORY, readme_text=README_TXT, delete_old_results=DELETE_OLD_RESULTS)\n",
    "setup_report(data_dir=NOTEBOOK_PLOTS_DIRECTORY, delete_old_results=DELETE_OLD_RESULTS)\n",
    "setup_report(data_dir=NOTEBOOK_DATA_DIRECTORY, delete_old_results=DELETE_OLD_RESULTS)\n",
    "setup_report(data_dir=NOTEBOOK_PICKLES_DIRECTORY, delete_old_results=DELETE_OLD_RESULTS)\n",
    "setup_report(data_dir=NOTEBOOK_REPORT_DIRECTORY, delete_old_results=DELETE_OLD_RESULTS)\n",
    "set_plot_style_for_paper()\n",
    "\n",
    "print(\"Destination Folder: %s\" % NOTEBOOK_ROOT_DIRECTORY)\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "# InteractiveShell.ast_node_interactivity = \"last_expr\"\n",
    "\n",
    "# this code adds also the variations of each primary trace, namely the ones with _2 and 1_rerun prefix.\n",
    "TRACE_FILE_NAMES_AND_VARIATIONS = []\n",
    "for trace in TRACE_FILE_NAMES:\n",
    "    if \"old\" not in trace:\n",
    "        TRACE_FILE_NAMES_AND_VARIATIONS.append(trace)\n",
    "        TRACE_FILE_NAMES_AND_VARIATIONS.append(trace.replace(\"1_1M\", \"2_1M\"))\n",
    "        TRACE_FILE_NAMES_AND_VARIATIONS.append(trace.replace(\"1_1M.out\", \"1_repeat_1M.out\"))\n",
    "    else:\n",
    "        TRACE_FILE_NAMES_AND_VARIATIONS.append(trace)\n",
    "print(TRACE_FILE_NAMES_AND_VARIATIONS)\n",
    "\n",
    "# In[]\n",
    "from sklearn.model_selection import train_test_split\n",
    "from numpy import array\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import to_categorical, Sequence\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.layers import LSTM, CuDNNLSTM\n",
    "from keras.layers import Embedding\n",
    "from keras.utils import plot_model\n",
    "from keras.models import load_model, save_model\n",
    "from IPython.display import SVG, display\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "import keras.backend as K\n",
    "from sys import getsizeof\n",
    "import statsmodels.api as sm\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "from multiprocessing import Manager\n",
    "from collections import Counter\n",
    "from numpy import argmax\n",
    "from sklearn.metrics import accuracy_score\n",
    "matplotlib.rcParams['text.usetex'] = False #True\n",
    "import time\n",
    "#from tensorflow.contrib.rnn import *\n",
    "\n",
    "if USE_GPU:\n",
    "    import tensorflow as tf\n",
    "    from keras.backend.tensorflow_backend import set_session\n",
    "    config = tf.compat.v1.ConfigProto( device_count = {'GPU': 0 , 'CPU': 8} )\n",
    "    config = tf.compat.v1.ConfigProto()\n",
    "    config.gpu_options.allow_growth = True  # dynamically grow the memory used on the GPU\n",
    "    config.log_device_placement = True  # to log device placement (on which device the operation ran)\n",
    "\n",
    "    sess = tf.compat.v1.Session(config=config)\n",
    "    #set_session(sess)\n",
    "    tf.compat.v1.keras.backend.set_session(sess)\n",
    "    print(tf.test.gpu_device_name())\n",
    "\n",
    "# In[] Data Preprocessing Functions\n",
    "def convert_to_binary(data=None, bit_size=16):\n",
    "    \"\"\"\n",
    "    Input: an array of integers\n",
    "    Returns a numpy array of arrays where each number is represented with a list of its binary digits\n",
    "    IMPORTANT: Currently 16 bit conversion is implemented below. For difference sizes, change 16 to something else.\n",
    "    \"\"\"\n",
    "    if bit_size == 16:\n",
    "        dataset = np.array([[int(d) for d in str('{0:016b}'.format(x))] for x in list(data)])\n",
    "    elif bit_size == 32 or bit_size not in [16, 32]:\n",
    "        if bit_size != 32:\n",
    "            print\n",
    "            \"Using 32bits delta representation\"\n",
    "        dataset = np.array([[int(d) for d in str('{0:032b}'.format(x))] for x in list(data)])\n",
    "    # print \"A10\", dataset[:10]\n",
    "    return dataset\n",
    "\n",
    "\n",
    "def difference(dataset, interval=1):\n",
    "    \"\"\"\n",
    "    Calculates the difference between a time-series and a lagged version of it\n",
    "    \"\"\"\n",
    "    diff = list()\n",
    "    for i in range(interval, len(dataset)):\n",
    "        value = dataset[i] - dataset[i - interval]\n",
    "        diff.append(value)\n",
    "    return diff\n",
    "\n",
    "\n",
    "def difference16(data=None, lag=1, prune_lsb=False, prune_length=None):\n",
    "    \"\"\"\n",
    "    Calculates the difference between a time-series and a lagged version of it that are represented in HEX format.\n",
    "    This can be used to convert memory addresses to integers.\n",
    "    \"\"\"\n",
    "    diff = list()\n",
    "    for i in range(lag, len(data)):\n",
    "        if prune_lsb:\n",
    "            value = int(data[i][:-prune_length] + '0' * prune_length, 16) - int(\n",
    "                data[i - lag][:-prune_length] + '0' * prune_length, 16)\n",
    "        else:\n",
    "            value = int(data[i], 16) - int(data[i - lag], 16)\n",
    "        diff.append(value)\n",
    "    return diff\n",
    "\n",
    "\n",
    "def inverse_difference(last_ob, value):\n",
    "    \"\"\"\n",
    "    Reconstructs the next value of a differenced time series.\n",
    "    \"\"\"\n",
    "    return value + last_ob\n",
    "\n",
    "# In[] Plot Configuration\n",
    "params = {\n",
    "    'axes.labelsize': 28,\n",
    "    'font.size': 24,\n",
    "    'legend.fontsize': 24,\n",
    "    'xtick.labelsize': 24,\n",
    "    'ytick.labelsize': 24,\n",
    "    'text.usetex': False, #True,\n",
    "    #'figure.figsize': [4.5, 4.5],\n",
    "    'figure.facecolor': 'w',\n",
    "    'figure.edgecolor': 'w',\n",
    "    'axes.facecolor': 'w',\n",
    "    'axes.edgecolor': 'gray',\n",
    "    'savefig.facecolor': 'w',\n",
    "    'savefig.edgecolor': 'g',\n",
    "    'savefig.pad_inches': 0.1,\n",
    "    'savefig.transparent': True,\n",
    "    'axes.titlepad': 24,\n",
    "    'axes.titlesize': 32\n",
    "}\n",
    "rcParams.update(params)\n",
    "\n",
    "# In[] Perform EDA\n",
    "\n",
    "# PERFORM_EDA = False\n",
    "NROWS = 500000\n",
    "\n",
    "manager = Manager()\n",
    "\n",
    "\n",
    "def run_eda(dataset=None, app_name=None, manual_encoding=False, decompose_timeseries=False, file_suffix=None):\n",
    "    set_plot_size(8, 8)\n",
    "\n",
    "    file_name_suffix = (\"tok_seq\" if not manual_encoding else \"manual_enc_seq\") + (\n",
    "        \"_decomposed\" if decompose_timeseries else \"\") + (\n",
    "                                   \"_%s_%s.eps\" % (app_name.replace(\" \", \"_\"), file_suffix)).replace(\"-\", \"_\").replace(\n",
    "        \" \", \"_\").lower()\n",
    "    report_name_prefix = (\"Of Mem Deltas  \" if decompose_timeseries else \"\") + (\n",
    "        \"\" if not manual_encoding else \"Of Manually\")\n",
    "\n",
    "    #     if not manual_encoding:\n",
    "    #         tokenizer = Tokenizer()\n",
    "    #         tokenizer.fit_on_texts(list(dataset))\n",
    "    #         encoded_all = tokenizer.texts_to_sequences([' '.join(list(dataset))])[0]\n",
    "    #     else:\n",
    "    #         encoded_all = encode_mem_accesses(list(dataset)) # angelos version\n",
    "    # TODO: cleanup code here since we are now passing deltas\n",
    "    encoded_all = dataset  # its already delta\n",
    "    if decompose_timeseries:\n",
    "        # decomposition implements diff for now\n",
    "\n",
    "        # encoded_all = get_timeseries_decomposition(data=encoded_all, frequency=decomposition_freq, plot=True, file_name_suffix=file_name_suffix, app_name=app_name, report_name_prefix=report_name_prefix)[2]\n",
    "        # encoded_all = [x for x in encoded_all if str(x) != 'nan']\n",
    "        encoded_all = difference(encoded_all, 1)\n",
    "\n",
    "    set_plot_size(16, 5)\n",
    "    _ = plt.figure()\n",
    "    # _ = pd.DataFrame(encoded_all, columns=[\"address\"]).plot(linewidth=1, fontsize=22)\n",
    "    _ = plt.plot(encoded_all, marker='x', markersize=8, linestyle='None')\n",
    "    _ = plt.ylim([-50000, 50000])\n",
    "    _ = plt.title(\"Memory Delta Time-Series %s\\nFor Trace %s\" % (report_name_prefix, app_name))\n",
    "    _ = plt.xlabel(\"Time\")\n",
    "    _ = plt.ylabel(\"Memory Address Delta\")\n",
    "    _ = plt.grid(True)\n",
    "    _ = plt.savefig(NOTEBOOK_PLOTS_DIRECTORY + \"raw_ts_pruned_%s\" % (file_name_suffix.replace(\".eps\", \"png\")),\n",
    "                    bbox_inches='tight')\n",
    "    _ = plt.show(block=False)\n",
    "    set_plot_size(8, 8)\n",
    "\n",
    "\n",
    "def eda_worker(dataset, app_name, file_suffix):\n",
    "    \"\"\"\n",
    "    Implements the main call that generates data for Experimental Data Analysis (EDA)\n",
    "    \"\"\"\n",
    "    run_eda(dataset=dataset, app_name=app_name, decompose_timeseries=False, manual_encoding=False,\n",
    "            file_suffix=file_suffix)\n",
    "\n",
    "# In[] Perform Time Series Shapelet Analysis\n",
    "rcParams['agg.path.chunksize'] = 10000\n",
    "\n",
    "# PERFORM_EDA = False\n",
    "NROWS = 10000\n",
    "\n",
    "NCHUNKS = 2\n",
    "SKIP_ROWS = 1000\n",
    "\n",
    "manager = Manager()\n",
    "\n",
    "# shapelet_report = manager.dict()\n",
    "shapelet_report = {}  # This nested dictionary cannot be implemented with multiprocesses bc its not mutable. So we fall back to using signle processes\n",
    "\n",
    "\n",
    "def run_shape_analyzer(dataset=None, app_name=None, manual_encoding=False, decompose_timeseries=False, chunk_id=None):\n",
    "    global shapelet_report\n",
    "    set_plot_size(30, 6)\n",
    "\n",
    "    encoded_all = dataset\n",
    "    file_name_suffix = (\"tok_seq\" if not manual_encoding else \"manual_enc_seq\") + (\n",
    "        \"_decomposed\" if decompose_timeseries else \"\") + (\"%s_%s.png\" % (chunk_id, app_name.replace(\" \", \"_\"))).replace(\n",
    "        \"-\", \"_\").replace(\" \", \"_\").lower()\n",
    "    report_name_prefix = (\"Of Mem Deltas  \" if decompose_timeseries else \"\") + (\n",
    "        \"\" if not manual_encoding else \"Of Manually\")\n",
    "\n",
    "    report_id = \"%s_%s_%s\" % (app_name, manual_encoding, decompose_timeseries)\n",
    "    report_name = app_name.replace(\" \", \"\")\n",
    "    params = {\n",
    "        \"manual_enconding\": manual_encoding,\n",
    "        \"decompose_timeseries\": decompose_timeseries\n",
    "    }\n",
    "\n",
    "    if report_id not in shapelet_report.keys():\n",
    "        shapelet_report[report_id] = {\n",
    "            \"report_name\": report_name,\n",
    "            \"params\": params,\n",
    "            \"plots\": {\n",
    "                \"movavg\": {},\n",
    "                \"rawts\": {},\n",
    "                \"diffts\": {},\n",
    "                \"rollacf\": {},\n",
    "                \"acfts\": {}\n",
    "            }\n",
    "        }\n",
    "    filename = NOTEBOOK_PLOTS_DIRECTORY + \"mov_avg_%s\" % (file_name_suffix)\n",
    "    print(filename)\n",
    "    print(encoded_all[:100])\n",
    "\n",
    "    _ = plt.figure()\n",
    "    _ = pd.DataFrame(encoded_all, columns=[\"address\"]).rolling(1000).mean().plot(linewidth=1, fontsize=22)\n",
    "    _ = plt.title(\"Moving Average %s\\nTrace %s\" % (report_name_prefix, app_name))\n",
    "    _ = plt.xlabel(\"Time\")\n",
    "    _ = plt.ylabel(\"Average Memory Address\")\n",
    "    _ = plt.grid(True)\n",
    "    _ = plt.savefig(filename, bbox_inches='tight')\n",
    "    _ = plt.show(block=False)\n",
    "    shapelet_report[report_id][\"plots\"][\"movavg\"][chunk_id] = filename\n",
    "\n",
    "    filename = NOTEBOOK_PLOTS_DIRECTORY + \"raw_ts_%s\" % (file_name_suffix)\n",
    "    _ = plt.figure()\n",
    "    _ = pd.DataFrame(encoded_all, columns=[\"address\"]).plot(linewidth=1, fontsize=22)\n",
    "    _ = plt.title(\"Raw Time-Series %s\\nTrace %s\" % (report_name_prefix, app_name))\n",
    "    _ = plt.xlabel(\"Time\")\n",
    "    _ = plt.ylabel(\"Memory Address\")\n",
    "    _ = plt.grid(True)\n",
    "    _ = plt.savefig(filename, bbox_inches='tight')\n",
    "    _ = plt.show(block=False)\n",
    "    shapelet_report[report_id][\"plots\"][\"rawts\"][chunk_id] = filename\n",
    "\n",
    "    # TODO: make this diff to be done directly on the MEM addresses (HEX)\n",
    "    filename = NOTEBOOK_PLOTS_DIRECTORY + \"diff_ts_%s\" % (file_name_suffix)\n",
    "    # _ = pd.DataFrame(encoded_all, columns=[\"address\"]).diff().plot(linewidth=1, fontsize=22)\n",
    "    # _ = pd.DataFrame(pd.DataFrame(encoded_all, columns=[\"address\"]).diff(), columns=[\"address\"]).rolling(1000).mean().plot(linewidth=1, fontsize=22)\n",
    "    _ = plt.figure()\n",
    "    _ = pd.DataFrame(encoded_all, columns=[\"address\"]).diff().plot(linewidth=1, fontsize=22)\n",
    "    _ = plt.title(\"Delta Time-Series %s\\nTrace %s\" % (report_name_prefix, app_name))\n",
    "    _ = plt.xlabel(\"Time\")\n",
    "    _ = plt.ylabel(\"Memory Address Deltas\")\n",
    "    _ = plt.grid(True)\n",
    "    _ = plt.savefig(filename, bbox_inches='tight')\n",
    "    _ = plt.show(block=False)\n",
    "    shapelet_report[report_id][\"plots\"][\"diffts\"][chunk_id] = filename\n",
    "\n",
    "\n",
    "def trace_shape_analyzer_worker(dataset, app_name, chunk_id):\n",
    "    \"\"\"\n",
    "    Implements the main call that generates data for Experimental Data Analysis (EDA)\n",
    "    \"\"\"\n",
    "    run_shape_analyzer(dataset=dataset, app_name=app_name, decompose_timeseries=False, manual_encoding=False,\n",
    "                       chunk_id=chunk_id)\n",
    "    # run_shape_analyzer(dataset=dataset, app_name=app_name, decompose_timeseries=False, manual_encoding=True, chunk_id=chunk_id)\n",
    "    # run_shape_analyzer(dataset=dataset, app_name=app_name, decompose_timeseries=True, manual_encoding=False, chunk_id=chunk_id)\n",
    "    # run_shape_analyzer(dataset=dataset, app_name=app_name, decompose_timeseries=True, manual_encoding=True, chunk_id=chunk_id)\n",
    "\n",
    "\n",
    "chunk = 0\n",
    "word_index = 1\n",
    "encoding_dictionary = defaultdict(int)\n",
    "\n",
    "print(dict(shapelet_report))\n",
    "\n",
    "\n",
    "# In[] Process Report\n",
    "def create_html_report(config, report_name):\n",
    "    page = []\n",
    "    page.append(\"\"\"<html>\n",
    "    <head>\n",
    "    <title>SDH Report</title>\n",
    "    </head>\n",
    "    <body>\"\"\")\n",
    "\n",
    "    # page.append('<ul>\\n')\n",
    "\n",
    "    for report_id, val in config.iteritems():\n",
    "        print(report_id)\n",
    "        page.append(\"<h1>%s</h1>\" % report_id.replace(\"_False_False\", \"\"))\n",
    "        page.append(\"\"\"\n",
    "            <table style=\"width:100%\">\n",
    "              <tr>\n",
    "                <th width=\"10%\">Metric Name</th>\n",
    "                <th width=\"90%\">Plot</th>\n",
    "              </tr>\n",
    "        \"\"\")\n",
    "        for k, v in val[\"plots\"].iteritems():\n",
    "            print(k, v)\n",
    "            for kk, vv in v.iteritems():\n",
    "                page.append('<tr><td>Chunk # %s of %s </td>' % (kk, k))\n",
    "                page.append('<td><img src=\"%s\"></td></tr>' % vv)\n",
    "\n",
    "        page.append('</table>\\n')\n",
    "    page.append('</body></html>')\n",
    "\n",
    "    with open(NOTEBOOK_REPORT_DIRECTORY + report_name + \".html\", \"w\") as text_file:\n",
    "        text_file.write('\\n'.join(page))\n",
    "\n",
    "\n",
    "if len(shapelet_report) > 0:\n",
    "    create_html_report(dict(shapelet_report), \"shapelet\")\n",
    "else:\n",
    "    print(\"Skipping EDA report generation\")\n",
    "\n",
    "\n",
    "# In[] Modeling Functions\n",
    "def precision(y_true, y_pred):\n",
    "    \"\"\"Precision metric. Only computes a batch-wise average of precision.\n",
    "-    Computes the precision, a metric for multi-label classification of\n",
    "-    how many selected items are relevant.\n",
    "-    \"\"\"\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "\n",
    "def recall(y_true, y_pred):\n",
    "    \"\"\"Recall metric.\n",
    "-    Only computes a batch-wise average of recall.\n",
    "-    Computes the recall, a metric for multi-label classification of\n",
    "-    how many relevant items are selected.\n",
    "-    \"\"\"\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "\n",
    "def fbeta_score(y_true, y_pred, beta=1):\n",
    "    \"\"\"Computes the F score.\n",
    "-    The F score is the weighted harmonic mean of precision and recall.\n",
    "-    Here it is only computed as a batch-wise average, not globally.\n",
    "-    This is useful for multi-label classification, where input samples can be\n",
    "-    classified as sets of labels. By only using accuracy (precision) a model\n",
    "-    would achieve a perfect score by simply assigning every class to every\n",
    "-    input. In order to avoid this, a metric should penalize incorrect class\n",
    "-    assignments as well (recall). The F-beta score (ranged from 0.0 to 1.0)\n",
    "-    computes this, as a weighted mean of the proportion of correct class\n",
    "-    assignments vs. the proportion of incorrect class assignments.\n",
    "-    With beta = 1, this is equivalent to a F-measure. With beta < 1, assigning\n",
    "-    correct classes becomes more important, and with beta > 1 the metric is\n",
    "-    instead weighted towards penalizing incorrect class assignments.\n",
    "-    \"\"\"\n",
    "    if beta < 0:\n",
    "        raise ValueError('The lowest choosable beta is zero (only precision).')\n",
    "\n",
    "        # If there are no true positives, fix the F score at 0 like sklearn.\n",
    "    if K.sum(K.round(K.clip(y_true, 0, 1))) == 0:\n",
    "        return 0\n",
    "    p = precision(y_true, y_pred)\n",
    "    r = recall(y_true, y_pred)\n",
    "    bb = beta ** 2\n",
    "    fbeta_score = (1 + bb) * (p * r) / (bb * p + r + K.epsilon())\n",
    "    return fbeta_score\n",
    "\n",
    "\n",
    "def fmeasure(y_true, y_pred):\n",
    "    \"\"\"Computes the f-measure, the harmonic mean of precision and recall.\n",
    "    Here it is only computed as a batch-wise average, not globally.\n",
    "    \"\"\"\n",
    "    return fbeta_score(y_true, y_pred, beta=1)\n",
    "\n",
    "\n",
    "def encode_mem_accesses(data):\n",
    "    \"\"\"\n",
    "    It implements a mapping between a set of strings to integers.\n",
    "    It does not have a limit in the max_dictionary_size supported.\n",
    "\n",
    "    data: data input should be in Pandas DF format\n",
    "    \"\"\"\n",
    "    tmp = defaultdict(int)\n",
    "    i = 1\n",
    "    encoded = []\n",
    "    for el in list(data):\n",
    "        if not tmp[el]:\n",
    "            # if el not in tmp.keys():\n",
    "            tmp[el] = i\n",
    "            i += 1\n",
    "        encoded.append(tmp[el])\n",
    "    return encoded\n",
    "\n",
    "\n",
    "def create_windowed_dataset(data, look_back):\n",
    "    \"\"\"\n",
    "    Create the dataset by grouping windows of memory accesses together (using the look_back parameter)\n",
    "\n",
    "    data: it should be a list of integers\n",
    "    \"\"\"\n",
    "    sequences = list()\n",
    "    for i in range(look_back, len(data)):\n",
    "        sequence = data[i - look_back:i + 1]\n",
    "        sequences.append(sequence)\n",
    "    return sequences\n",
    "\n",
    "\n",
    "def get_timeseries_decomposition(data=None, frequency=None, plot=False, report_name_prefix=None, file_name_suffix=None,\n",
    "                                 app_name=None):\n",
    "    # TODO: reimplement this\n",
    "    \"\"\"\n",
    "    data is a list of integers which is converted to address - date dataframe\n",
    "    \"\"\"\n",
    "    dta = pd.DataFrame(data)\n",
    "    dta['date'] = dta.index\n",
    "    dta.columns = [\"address\", \"date\"]\n",
    "\n",
    "    dta['date'] = pd.DatetimeIndex(dta.date)  # ,  format=\"%Y-%m-%d %H:%M:%S\")\n",
    "    # df.index = pd.to_datetime(df.index, unit='s')\n",
    "    # dta.address.interpolate(inplace=True)\n",
    "    dta.set_index('date', inplace=True)\n",
    "\n",
    "    # dta = dta.groupby(pd.TimeGrouper('%ss' % 1), as_index=True)['total'].sum()\n",
    "    res = sm.tsa.seasonal_decompose(dta, freq=frequency, model='additive')\n",
    "    if plot:\n",
    "        _ = plt.figure()\n",
    "        _ = res.plot()\n",
    "        _ = plt.title(\n",
    "            \"Time Series Decomposition Of %s Tokenized Sequence For Trace %s\" % (report_name_prefix, app_name))\n",
    "        _ = plt.grid(True)\n",
    "        _ = plt.savefig(NOTEBOOK_PLOTS_DIRECTORY + \"hist_%s\" % (file_name_suffix), bbox_inches='tight')\n",
    "        _ = plt.show(block=False)\n",
    "\n",
    "    return list(res.trend['address']), list(res.seasonal['address']), list(res.resid['address'])\n",
    "\n",
    "\n",
    "def plot_generic_timeseries(train_data=None,test_data=None, rows=2000, app_name=\"\", scenario_name=None):\n",
    "    set_plot_size(30, 4)\n",
    "    scenario_name = scenario_name.replace(\"_\", \"-\").replace(\" \", \"-\")\n",
    "\n",
    "    _ = plt.figure()\n",
    "    _ = plt.plot(train_data[:rows])  # , linestyle='-', marker='.', markersize=6, linewidth=1)\n",
    "    _ = plt.xlabel(\"Time\")\n",
    "    _ = plt.ylabel(\"Memory Address\")\n",
    "    _ = plt.title(\"Memory Access Timeseries For Trace %s - Scenario %s - Training Phase\" % (app_name, scenario_name))\n",
    "    _ = plt.grid(True)\n",
    "    _ = plt.savefig(NOTEBOOK_PLOTS_DIRECTORY + \"memory_accesses_training_%s_%s.eps\" % (app_name, scenario_name),\n",
    "                    bbox_inches='tight')\n",
    "    _ = plt.show(block=False)\n",
    "\n",
    "    _ = plt.figure()\n",
    "    _ = plt.plot(test_data[:rows])  # , linestyle='-', marker='.', markersize=6, linewidth=1)\n",
    "    _ = plt.xlabel(\"Time\")\n",
    "    _ = plt.ylabel(\"Memory Address\")\n",
    "    _ = plt.title(\"Memory Access Timeseries For Trace %s - Scenario %s - Testing Phase\" % (app_name, scenario_name))\n",
    "    _ = plt.grid(True)\n",
    "    _ = plt.savefig(NOTEBOOK_PLOTS_DIRECTORY + \"memory_accesses_testing_%s_%s.eps\" % (app_name, scenario_name),\n",
    "                    bbox_inches='tight')\n",
    "    _ = plt.show(block=False)\n",
    "\n",
    "\n",
    "def plot_memory_trace(train_data=None, test_data=None, rows=2000, app_name=\"\", scenario_name=None):\n",
    "    set_plot_size(30, 4)\n",
    "    scenario_name = scenario_name.replace(\"_\", \"-\").replace(\" \", \"-\")\n",
    "\n",
    "    _ = plt.figure()\n",
    "    _ = plt.plot(train_data[:rows])  # , linestyle='-', marker='.', markersize=6, linewidth=1)\n",
    "    _ = plt.xlabel(\"Time\")\n",
    "    _ = plt.ylabel(\"Memory Address\")\n",
    "    _ = plt.title(\"Memory Access Timeseries For Trace %s - Scenario %s - Training Phase\" % (app_name, scenario_name))\n",
    "    _ = plt.grid(True)\n",
    "    _ = plt.savefig(NOTEBOOK_PLOTS_DIRECTORY + \"memory_accesses_training_%s_%s.eps\" % (app_name, scenario_name),\n",
    "                    bbox_inches='tight')\n",
    "    _ = plt.show(block=False)\n",
    "\n",
    "    _ = plt.figure()\n",
    "    _ = plt.plot(test_data[:rows])  # , linestyle='-', marker='.', markersize=6, linewidth=1)\n",
    "    _ = plt.xlabel(\"Time\")\n",
    "    _ = plt.ylabel(\"Memory Address\")\n",
    "    _ = plt.title(\"Memory Access Timeseries For Trace %s - Scenario %s - Testing Phase\" % (app_name, scenario_name))\n",
    "    _ = plt.grid(True)\n",
    "    _ = plt.savefig(NOTEBOOK_PLOTS_DIRECTORY + \"memory_accesses_testing_%s_%s.eps\" % (app_name, scenario_name),\n",
    "                    bbox_inches='tight')\n",
    "    _ = plt.show(block=False)\n",
    "\n",
    "\n",
    "def plot_on_the_fly_model_performance(history=None, app_name=\"\", scenario_name=None):\n",
    "    # TODO: optimize function and remove key accesses from the dictionaries (pass them as params)\n",
    "    # Plot training & validation accuracy values\n",
    "    scenario_name = scenario_name.replace(\"_\", \"-\").replace(\" \", \"-\")\n",
    "\n",
    "    set_plot_size(6, 6)\n",
    "    _ = plt.figure()\n",
    "    _ = plt.plot(range(1, len(history.history['acc']) + 1), history.history['acc'], linestyle='-', marker='^',\n",
    "                 markersize=8, linewidth=2)\n",
    "    _ = plt.plot(range(1, len(history.history['val_acc']) + 1), history.history['val_acc'], linestyle='-', marker='s',\n",
    "                 markersize=8, linewidth=2)\n",
    "    _ = plt.title('Model Accuracy For Trace %s\\nScenario %s' % (app_name, scenario_name))\n",
    "    _ = plt.ylabel('Accuracy')\n",
    "    _ = plt.xlabel('Epoch No.')\n",
    "    _ = plt.grid(True)\n",
    "    _ = plt.legend(['Train', 'Test'], loc='upper left')\n",
    "    _ = plt.savefig(NOTEBOOK_PLOTS_DIRECTORY + \"train_test_accuracy_for_%s_%s.eps\" % (app_name, scenario_name),\n",
    "                    bbox_inches='tight')\n",
    "    _ = plt.show(block=False)\n",
    "\n",
    "    # Plot training & validation loss values\n",
    "    _ = plt.figure()\n",
    "    _ = plt.plot(range(1, len(history.history['loss']) + 1), history.history['loss'], linestyle='-', marker='^',\n",
    "                 markersize=8, linewidth=2)\n",
    "    _ = plt.plot(range(1, len(history.history['val_loss']) + 1), history.history['val_loss'], linestyle='-', marker='s',\n",
    "                 markersize=8, linewidth=2)\n",
    "    _ = plt.title('Model Loss For Trace %s\\nScenario %s' % (app_name, scenario_name))\n",
    "    _ = plt.ylabel('Loss')\n",
    "    _ = plt.xlabel('Epoch No.')\n",
    "    _ = plt.grid(True)\n",
    "    _ = plt.legend(['Train', 'Test'], loc='upper left')\n",
    "    _ = plt.savefig(NOTEBOOK_PLOTS_DIRECTORY + \"train_test_loss_for_%s_%s.eps\" % (app_name, scenario_name),\n",
    "                    bbox_inches='tight')\n",
    "    _ = plt.show(block=False)\n",
    "\n",
    "\n",
    "def plot_train_test_model_performance(train_history=None, test_history=None, app_name=\"\", scenario_name=None):\n",
    "    # TODO: optimize function and remove key accesses from the dictionaries (pass them as params)\n",
    "    if train_history is not None:\n",
    "        print('Final Training accuracy: %s' % (train_history.history['accuracy'][-1]))\n",
    "        print('Test score: %s' % test_history[0])\n",
    "        print('Test accuracy: %s' % test_history[1])\n",
    "        scenario_name = scenario_name.replace(\"_\", \"-\").replace(\" \", \"-\")\n",
    "        data = train_history.history['accuracy']\n",
    "        set_plot_size(6, 6)\n",
    "        _ = plt.figure()\n",
    "        _ = plt.plot(range(1, len(data) + 1), data, linestyle='-', marker='^', markersize=8, linewidth=2)\n",
    "        _ = plt.xticks(range(1, len(data) + 1))\n",
    "        _ = plt.title('Training Accuracy Per Epoch\\nTrace %s' % (app_name))\n",
    "        _ = plt.ylabel('Accuracy')\n",
    "        _ = plt.xlabel('Epoch No.')\n",
    "        _ = plt.grid(True)\n",
    "        # _ = plt.legend(['Train'], loc='upper left')\n",
    "        _ = plt.savefig(NOTEBOOK_PLOTS_DIRECTORY + \"train_and_test_accuracy_for_%s_%s.eps\" % (app_name, scenario_name),\n",
    "                        bbox_inches='tight')\n",
    "        _ = plt.show(block=False)\n",
    "\n",
    "\n",
    "def approx_entropy(U, m, r):\n",
    "    try:\n",
    "        U = np.array(U)\n",
    "\n",
    "        def _maxdist(x_i, x_j):\n",
    "            return max([abs(ua - va) for ua, va in zip(x_i, x_j)])\n",
    "\n",
    "        def _phi(m):\n",
    "            x = [[U[j] for j in range(i, i + m - 1 + 1)] for i in range(N - m + 1)]\n",
    "            C = [len([1 for x_j in x if _maxdist(x_i, x_j) <= r]) / (N - m + 1.0) for x_i in x]\n",
    "            return (N - m + 1.0) ** (-1) * sum(np.log(C))\n",
    "\n",
    "        N = len(U)\n",
    "        return abs(_phi(m + 1) - _phi(m))\n",
    "    except:\n",
    "        print(U)\n",
    "        raise\n",
    "\n",
    "\n",
    "def sample_entropy(data):\n",
    "    p_data = pd.Series(data).value_counts() / len(data)  # calculates the probabilities\n",
    "    entropy = sc.stats.entropy(p_data)  # input probabilities to get the entropy\n",
    "    return entropy\n",
    "\n",
    "# In[] LSTM Model Implementation\n",
    "def dataset_creator(scenario):\n",
    "    use_manual_encoding = scenario['use_manual_encoding']\n",
    "    app_name = scenario['app_name']\n",
    "    decompose_timeseries = scenario['decompose_timeseries']\n",
    "    decomposition_frequency = scenario['decomposition_frequency']\n",
    "    test_ratio = scenario['test_ratio']\n",
    "    on_the_fly_testing = scenario['on_the_fly_testing']\n",
    "    plot_timeseries = scenario['plot_timeseries']\n",
    "    look_back = scenario['look_back_window']\n",
    "    scenario_name = scenario['scenario_name']\n",
    "    vocabulary_maximum_size = scenario['vocabulary_maximum_size']\n",
    "    vocabulary_mimimum_word_frequency_quantile = scenario['vocabulary_mimimum_word_frequency_quantile']\n",
    "    model_diffs = scenario['model_diffs']\n",
    "    lstm_batch_size = scenario['lstm_batch_size']\n",
    "    lstm_epochs = scenario['lstm_epochs']\n",
    "    verbosity = scenario['verbosity']\n",
    "    dropout_ratio = scenario['dropout_ratio']\n",
    "    lstm_size = scenario['lstm_size']\n",
    "    embedding_size = scenario['embedding_size']\n",
    "    prediction_batch_size = scenario['prediction_batch_size']\n",
    "    online_retraining = scenario['online_retraining']\n",
    "    online_learning_accuracy_threshold = scenario['online_learning_accuracy_threshold']\n",
    "    online_retraining_periods = scenario['online_retraining_periods']\n",
    "    online_retraining_period_size = scenario['online_retraining_period_size']\n",
    "    number_of_rows_to_model = scenario['number_of_rows_to_model']\n",
    "    number_of_rows_to_skip = scenario['number_of_rows_to_skip']\n",
    "    keep_read_access_only = scenario['keep_read_access_only']\n",
    "    prune_lsb = scenario['prune_lsb']\n",
    "    prune_length = scenario['prune_length']\n",
    "    pretrain_type = scenario[\"pretrain_type\"]\n",
    "    bit_size = scenario[\"bit_size\"]\n",
    "    convert_output_to_binary = scenario['convert_output_to_binary']  # this is used for FPGA implementation.\n",
    "\n",
    "    max_test_accuracy = 1\n",
    "    # used to reduce accuracy appropriatelly in case of rounding/approximations in the prediction address.\n",
    "\n",
    "    tokenizer = None\n",
    "    tokenizer2 = None\n",
    "\n",
    "    # This is used to represent rare words and not get encoded individually, which then will be\n",
    "    # flagged as false positives (or negatives) and use them to reduce the model accuracy\n",
    "    # All the rare words will be encoded with the following value.\n",
    "    dummy_word = \"0xffffffff\"\n",
    "    dummy_word_index = -1  # this is the index of the dummy word (to be set later)\n",
    "\n",
    "    # this is to be used to spoof the index of the dummy word and thus force false positive\n",
    "    # determination during testing (since these words cannot be predicted)\n",
    "    dummy_index = -1\n",
    "\n",
    "    # Set total rows to None to load all the rows for online learning. Else keep as many as we need.\n",
    "    total_rows = scenario['number_of_rows_to_model'] if not online_retraining else \\\n",
    "        scenario['number_of_rows_to_model'] + online_retraining_period_size * (online_retraining_periods + 2)\n",
    "    print(\"Running for %d\" % total_rows)\n",
    "\n",
    "    if pretrain_type is None:\n",
    "        dataset_verbose = pd.read_csv(TRACE_DIRECTORY + scenario['trace_file_name'], sep=\" \", nrows=total_rows,\n",
    "                                      skiprows=scenario['number_of_rows_to_skip'])\n",
    "    else:\n",
    "        ### This implements testing with a pretrained model\n",
    "        # TODO: put this info about the rerun files at the begining of the script as a dictionary.\n",
    "        comparison_file_name = scenario['trace_file_name']\n",
    "        if pretrain_type == \"rerun\":\n",
    "            comparison_file_name = comparison_file_name.replace(\"_1M.out\", \"\") + \"_repeat_1M.out\"\n",
    "        if pretrain_type == \"new\":\n",
    "            comparison_file_name = comparison_file_name.replace(\"1_\", \"2_\")\n",
    "        ###\n",
    "\n",
    "        #dataset_verbose1 = pd.read_csv(TRACE_DIRECTORY + comparison_file_name, sep=\" \",\n",
    "        #                               nrows=int(math.floor(total_rows / 2.0)),\n",
    "        #                               skiprows=scenario['number_of_rows_to_skip'])\n",
    "        dataset_verbose1 = pd.read_csv(TRACE_DIRECTORY + comparison_file_name,sep=\" \",\n",
    "                                       nrows=int(math.floor(total_rows / 2.0)),\n",
    "                                       skiprows=scenario['number_of_rows_to_skip'])\n",
    "        #dataset_verbose1.columns = [\"instruction\", \"address\"]\n",
    "        #print(dataset_verbose1)\n",
    "        dataset_verbose1.columns = [\"instruction\", \"type\", \"address\"]\n",
    "        #Pem\n",
    "       # dataset_verbose1.columns = [\"address\"]\n",
    "\n",
    "        #dataset_verbose2 = pd.read_csv(TRACE_DIRECTORY + comparison_file_name, sep=\" \",\n",
    "        #                               nrows=int(math.ceil(total_rows / 2.0)),\n",
    "        #                               skiprows=scenario['number_of_rows_to_skip'] + int(math.floor(total_rows / 2.0)))\n",
    "        dataset_verbose2 = pd.read_csv(TRACE_DIRECTORY + comparison_file_name,sep=\" \",\n",
    "                                       nrows=int(math.ceil(total_rows / 2.0)),\n",
    "                                       skiprows=scenario['number_of_rows_to_skip'] + int(math.floor(total_rows / 2.0)))\n",
    "        #dataset_verbose2.columns = [\"instruction\", \"address\"]\n",
    "        # Pem\n",
    "        dataset_verbose2.columns = [\"instruction\", \"type\", \"address\"]\n",
    "\n",
    "        dataset_verbose = dataset_verbose1.append(dataset_verbose2, ignore_index=True)\n",
    "\n",
    "\n",
    "    dataset_verbose.columns = [\"instruction\", \"type\", \"address\"]\n",
    "    if keep_read_access_only:\n",
    "        dataset_verbose = dataset_verbose[dataset_verbose[\"type\"] == \"R\"]\n",
    "    # print dataset_verbose.head()\n",
    "    # print dataset_verbose.describe()\n",
    "\n",
    "    dataset = dataset_verbose['address']\n",
    "    del dataset_verbose\n",
    "\n",
    "    if not use_manual_encoding:\n",
    "        if model_diffs:\n",
    "            print(\"Tokenizing ...\")\n",
    "            # Tokenize raw memory address to convert them to integers\n",
    "            tokenizer = Tokenizer()\n",
    "            tokenizer.fit_on_texts(list(dataset))\n",
    "            concat_dataset = [' '.join(list(dataset))]\n",
    "            # This is used only for plotting purposes\n",
    "            encoded_raw = tokenizer.texts_to_sequences(concat_dataset)[0]\n",
    "\n",
    "            vocab_size_raw = len(tokenizer.word_index) + 1\n",
    "            print('Raw Vocabulary Size: %d' % vocab_size_raw)\n",
    "\n",
    "            # calculate diffs of integer memory addresses\n",
    "            # print dataset\n",
    "\n",
    "            encoded_raw_diff = difference16(data=list(dataset), lag=1, prune_lsb=prune_lsb, prune_length=prune_length)\n",
    "\n",
    "            encoded_raw_diff_str = [\"%s%d\" % (\"1x\" if x < 0 else \"0x\", abs(x)) for x in encoded_raw_diff]\n",
    "            df = pd.DataFrame(encoded_raw_diff_str)\n",
    "            # print df\n",
    "\n",
    "            df.columns = ['delta']\n",
    "\n",
    "            df2 = pd.DataFrame(pd.Series(encoded_raw_diff_str).value_counts())\n",
    "            # print \"Length2 %s\" % len(df2.index)\n",
    "            df2.columns = ['total']\n",
    "            df2['delta'] = df2.index\n",
    "            # print \"xxxxx\", df2\n",
    "            df2 = df2.reset_index(drop=True)\n",
    "            df2.columns = ['total', 'delta']\n",
    "            # print \"V2\", df2\n",
    "            bit_size_offset = 3\n",
    "\n",
    "            df2_2 = df2[['total']].copy()\n",
    "            df2_2['cumsum'] = df2_2.sort_values(by=\"total\", ascending=False)[['total']].cumsum(axis=0)\n",
    "\n",
    "            tmp_total_rows = df2['total'].sum()\n",
    "\n",
    "            # Get the row index where the cumulative quantity reaches half the total.\n",
    "            # print \"AAA44\", tmp_total_rows, df2_2.head()\n",
    "            df2_3 = df2_2[df2_2['cumsum'] < vocabulary_mimimum_word_frequency_quantile * tmp_total_rows]  # .idxmax()\n",
    "            # print \"AAA34\", myindex, tmp_total_rows\n",
    "            # print df2_2.head()\n",
    "\n",
    "            # Get the price at that index\n",
    "            vocabulary_mimimum_word_frequency = df2_3.loc[\n",
    "                df2_3['cumsum'].idxmax(), 'total']  # int(list(df2_2['total'].iloc[myindex])[0])\n",
    "\n",
    "            if vocabulary_mimimum_word_frequency == 1:\n",
    "                vocabulary_mimimum_word_frequency = 0  # since 1 is going to prune a lot of words\n",
    "            print(\"Quantile based Minimum Frequency for %s is %s\" % (\n",
    "            vocabulary_mimimum_word_frequency_quantile, vocabulary_mimimum_word_frequency))\n",
    "            # df2 = df2[df2['total'] > vocabulary_mimimum_word_frequency]\n",
    "            # print \"xxxxxxx\", df2.head()\n",
    "\n",
    "            # print \"xxxxx\", df2.head()\n",
    "\n",
    "            if vocabulary_maximum_size and not convert_output_to_binary:\n",
    "                df2 = df2[(df2.index > vocabulary_maximum_size) | (\n",
    "                            df2['total'] < vocabulary_mimimum_word_frequency)]  # TODO: make it <=\n",
    "            else:\n",
    "                df2 = df2[(df2.index > math.pow(2, bit_size) - bit_size_offset) | (df2[\n",
    "                                                                                       'total'] < vocabulary_mimimum_word_frequency)]  # we subtract words to allow for the dummy word to be also stored.\n",
    "\n",
    "            # print \"xxxxx\", df2.head()\n",
    "\n",
    "            # vocabulary_mimimum_word_frequency = np.quantile(encode_mem_accesses(list(encoded_raw_diff_str)), vocabulary_mimimum_word_frequency_quantile) # angelos version  , vocabulary_mimimum_word_frequency_quantile)\n",
    "\n",
    "            # Set a dummy value to represent the ignored deltas. This will be converted later to a unique integer using a second tokenizer.\n",
    "            # print \"Length2 %s\" % len(df2.index)\n",
    "            df.loc[df.delta.isin(df2.delta), ['delta']] = dummy_word\n",
    "\n",
    "            # print \"xxxxxx\", df[df['delta'] == dummy_word]\n",
    "            # print \"Length1 %s\" % len(df.index)\n",
    "\n",
    "            # print df.head()\n",
    "            # print df[df['delta'] == dummy_word]\n",
    "            # df.describe()\n",
    "            encoded_raw_diff_pruned = df['delta']\n",
    "            # print \"AAA3\", encoded_raw_diff_pruned.head()\n",
    "            # print \"V3\"\n",
    "            # print encoded_raw_diff_pruned.head()\n",
    "\n",
    "            # print \"pruned\", encoded_raw_diff_pruned[:300]\n",
    "            del df, df2\n",
    "\n",
    "            # Calclulate accuracy reduction due to vocabulary pruning.\n",
    "            tmp_train, tmp_test = train_test_split(encoded_raw_diff_pruned, test_size=test_ratio, shuffle=False)\n",
    "            total_removals = Counter(encoded_raw_diff_pruned)[dummy_word]\n",
    "            total_rows = len(encoded_raw_diff_pruned)\n",
    "            train_removals = Counter(tmp_train)[dummy_word]\n",
    "            train_total = len(tmp_train)\n",
    "            test_removals = Counter(tmp_test)[dummy_word]\n",
    "            test_total = len(tmp_test)\n",
    "            print(total_removals, total_rows, train_removals, train_total, test_removals, test_total)\n",
    "            max_test_accuracy = 1 - test_removals / test_total\n",
    "            print(\"Max Accuracy: %s\" % max_test_accuracy)\n",
    "            print(\"Total Removals: %s\" % total_removals)\n",
    "\n",
    "            # Tokenize again the pruned differentials to produce unique vocabulary (classes)\n",
    "            encoded_raw_diff_pruned_str = [str(x) for x in list(encoded_raw_diff_pruned)]\n",
    "            tokenizer2 = Tokenizer()\n",
    "            tokenizer2.fit_on_texts(encoded_raw_diff_pruned_str)\n",
    "            encoded_final = tokenizer2.texts_to_sequences([' '.join(encoded_raw_diff_pruned_str)])[0]\n",
    "            final_vocab_size = len(tokenizer2.word_index) + 1\n",
    "            print('Pruned Vocabulary Size: %d' % final_vocab_size)\n",
    "\n",
    "            for word, index in tokenizer2.word_index.items():\n",
    "                if word == dummy_word:\n",
    "                    print(\"%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\", word, index)\n",
    "                    dummy_word_index = index\n",
    "                    break\n",
    "        #             set_plot_size(6,6)\n",
    "        #             _ = plt.hist(encoded_final, bins=100)\n",
    "        #             _ = plt.grid(True)\n",
    "        #             _ = plt.title(\"Histogram Of All Memory Deltas After Prunning\\nFor The %s App\" % app_name)\n",
    "        #             _ = plt.show()\n",
    "\n",
    "        else:\n",
    "            tokenizer = Tokenizer()\n",
    "            tokenizer.fit_on_texts(list(dataset))\n",
    "            encoded_final = tokenizer.texts_to_sequences([' '.join(list(dataset))])[0]\n",
    "            final_vocab_size = len(tokenizer.word_index) + 1\n",
    "    else:\n",
    "        # TODO: move this in the diff section or remove completely.\n",
    "        encoded_final = encode_mem_accesses(list(dataset))  # angelos version\n",
    "        final_vocab_size = len(set(encoded_final)) + 1\n",
    "\n",
    "    if decompose_timeseries:\n",
    "        # TODO: this is incomplete. Either fix or remove completely.\n",
    "        dataset = get_timeseries_decomposition(encoded_final, decomposition_frequency)[\n",
    "            2]  # TODO add back in the predictions the trend and seasonality\n",
    "        final_vocab_size = len(set(dataset)) + 1\n",
    "\n",
    "    # The series below are for visulaization purposes only.\n",
    "    if plot_timeseries:\n",
    "        if model_diffs:\n",
    "            encoded_raw_train, encoded_raw_test = train_test_split(encoded_raw, test_size=test_ratio, shuffle=False)\n",
    "            encoded_raw_diff_train, encoded_raw_diff_test = train_test_split(encoded_raw_diff, test_size=test_ratio,\n",
    "                                                                             shuffle=False)\n",
    "            plot_memory_trace(train_data=encoded_raw_train, test_data=encoded_raw_test, rows=200000, app_name=app_name,\n",
    "                              scenario_name=scenario_name + \" Raw\")\n",
    "            plot_memory_trace(train_data=encoded_raw_diff_train, test_data=encoded_raw_diff_test, rows=200000,\n",
    "                              app_name=app_name, scenario_name=scenario_name + \" Raw Diff\")\n",
    "\n",
    "        encoded_train, encoded_test = train_test_split(encoded_final, test_size=test_ratio, shuffle=False)\n",
    "        plot_memory_trace(train_data=encoded_train, test_data=encoded_test, rows=2000, app_name=app_name,\n",
    "                          scenario_name=scenario_name + \" Final\")\n",
    "\n",
    "    sequences = create_windowed_dataset(encoded_final, look_back)\n",
    "\n",
    "    print('Final Vocabulary Size: %d' % final_vocab_size)\n",
    "    print('Total Sequences: %d' % len(sequences))\n",
    "\n",
    "    # Pad the sequences to the same length (is not really needed here since we have fixed input windows).\n",
    "    # See documentation in the source code here: https://github.com/keras-team/keras-preprocessing/blob/master/keras_preprocessing/sequence.py\n",
    "    max_length = max([len(seq) for seq in sequences])\n",
    "    sequences = pad_sequences(sequences, maxlen=max_length, padding='pre')\n",
    "\n",
    "    # print encoded_final, sequences, final_vocab_size\n",
    "\n",
    "    return encoded_final, sequences, final_vocab_size, tokenizer, tokenizer2, max_test_accuracy, max_length, dummy_word, dummy_word_index, dummy_index, vocab_size_raw\n",
    "\n",
    "# In[] Define LSTM model\n",
    "def run_lstm_model(scenario=None):\n",
    "    \"\"\"\n",
    "    Encode the sequence of memory addresses to a sequence of integers\n",
    "    We can do it either using Keras, or by implementing our own convertion function (see above \"encode_mem_accesses\")\n",
    "    For the Keras approach, see documentation in the source code here: https://github.com/keras-team/keras-preprocessing/blob/master/keras_preprocessing/text.py\n",
    "    \"\"\"\n",
    "\n",
    "    use_manual_encoding = scenario['use_manual_encoding']\n",
    "    app_name = scenario['app_name']\n",
    "    decompose_timeseries = scenario['decompose_timeseries']\n",
    "    decomposition_frequency = scenario['decomposition_frequency']\n",
    "    test_ratio = scenario['test_ratio']\n",
    "    on_the_fly_testing = scenario['on_the_fly_testing']\n",
    "    plot_timeseries = scenario['plot_timeseries']\n",
    "    look_back = scenario['look_back_window']\n",
    "    scenario_name = scenario['scenario_name']\n",
    "    vocabulary_maximum_size = scenario['vocabulary_maximum_size']\n",
    "    vocabulary_mimimum_word_frequency_quantile = scenario['vocabulary_mimimum_word_frequency_quantile']\n",
    "    model_diffs = scenario['model_diffs']\n",
    "    lstm_batch_size = scenario['lstm_batch_size']\n",
    "    lstm_epochs = scenario['lstm_epochs']\n",
    "    verbosity = scenario['verbosity']\n",
    "    dropout_ratio = scenario['dropout_ratio']\n",
    "    lstm_size = scenario['lstm_size']\n",
    "    embedding_size = scenario['embedding_size']\n",
    "    prediction_batch_size = scenario['prediction_batch_size']\n",
    "    online_retraining = scenario['online_retraining']\n",
    "    online_learning_accuracy_threshold = scenario['online_learning_accuracy_threshold']\n",
    "    online_retraining_periods = scenario['online_retraining_periods']\n",
    "    online_retraining_period_size = scenario['online_retraining_period_size']\n",
    "    number_of_rows_to_model = scenario['number_of_rows_to_model']\n",
    "    model_type = scenario['model_type']\n",
    "    loss_function = scenario['loss_function']\n",
    "    activation_fuction = scenario['activation_function']\n",
    "    convert_output_to_binary = scenario['convert_output_to_binary']  # this is used for FPGA implementation.\n",
    "    bit_size = scenario['bit_size']\n",
    "    load_existing_pickles = scenario['load_existing_pickles']\n",
    "    unique_key = abs(hash(frozenset(scenario.items())))\n",
    "\n",
    "    misc_stats = {}\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    if online_retraining:\n",
    "        \"\"\"\n",
    "        This implements the online training/testing/retraining cyble of SDH project.\n",
    "        \"\"\"\n",
    "        retraining_period_counter = 1\n",
    "\n",
    "        # =====================================================================================================\n",
    "        # Data preparation\n",
    "        # =====================================================================================================\n",
    "        encoded_final, sequences, final_vocab_size, tokenizer, tokenizer2, max_test_accuracy, max_length, dummy_word, dummy_word_index, dummy_index,\\\n",
    "        vocab_size_raw = dataset_creator(scenario)\n",
    "        # =====================================================================================================\n",
    "\n",
    "        # =====================================================================================================\n",
    "        # Neural Network Configuration\n",
    "        # =====================================================================================================\n",
    "        if convert_output_to_binary:\n",
    "            # print final_vocab_size, embedding_size, max_length-1\n",
    "            model = Sequential()\n",
    "            model.add(Embedding(final_vocab_size, embedding_size, input_length=max_length - 1))\n",
    "            if USE_GPU:\n",
    "                model.add(CuDNNLSTM(lstm_size))\n",
    "            else:\n",
    "                model.add(LSTM(lstm_size))\n",
    "            model.add(Dropout(dropout_ratio))\n",
    "            model.add(Dense(bit_size,\n",
    "                            activation=activation_fuction))  # the size of this layer should align with the size of the bit representation of the output.\n",
    "            model.compile(loss=loss_function, optimizer='adam', metrics=[\n",
    "                'accuracy'])  # top_k_categorical_accuracy is still wrong but we have it for illustration purposes.\n",
    "        else:\n",
    "            model = Sequential()\n",
    "            model.add(Embedding(final_vocab_size, embedding_size, input_length=max_length - 1))\n",
    "\n",
    "            if USE_GPU:\n",
    "                model.add(CuDNNLSTM(lstm_size))\n",
    "            else:\n",
    "                model.add(LSTM(lstm_size))\n",
    "            model.add(Dropout(dropout_ratio))\n",
    "            model.add(Dense(final_vocab_size, activation=activation_fuction))\n",
    "            model.compile(loss=loss_function, optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "        if verbosity > 0:\n",
    "            print(model.summary())\n",
    "        SVG(model_to_dot(model, show_shapes=True, show_layer_names=False).create(prog='dot', format='svg'))\n",
    "        plot_model(model, to_file=NOTEBOOK_PLOTS_DIRECTORY + 'model_for_%s.png' % scenario_name, show_shapes=True,\n",
    "                   show_layer_names=False)\n",
    "        # =====================================================================================================\n",
    "\n",
    "        # =====================================================================================================\n",
    "        # Model training/testing\n",
    "        # =====================================================================================================\n",
    "\n",
    "        X, y = sequences[:, :-1], sequences[:, -1]\n",
    "        # print \"A4\", sequences\n",
    "        # Vectorize the output y (one hot encoding)\n",
    "        if convert_output_to_binary:\n",
    "            y = convert_to_binary(data=y, bit_size=bit_size)  # converts diffs to 16 bit representation\n",
    "        else:\n",
    "            y = to_categorical(y, num_classes=final_vocab_size)\n",
    "        # print \"A5\", y\n",
    "        period_online_learning_accuracy = []\n",
    "        period_online_learning_accuracy_avg = 0\n",
    "\n",
    "        overall_online_learning_accuracy = []  # tracks the time series of accuracy overall (never reset)\n",
    "        overall_retrain_tracker = []  # tracks when retrain happens for plotting purposes\n",
    "\n",
    "        # X = np.array([np.array(tmp_x) for tmp_x in X])\n",
    "        # y = np.matrix([np.array(tmp_y) for tmp_y in y])\n",
    "        # y = np.asarray(y, dtype=int)\n",
    "\n",
    "        X_train, X_test = train_test_split(X, train_size=number_of_rows_to_model,\n",
    "                                           test_size=online_retraining_period_size, shuffle=False)\n",
    "        \n",
    "        y_train, y_test = train_test_split(y, train_size=number_of_rows_to_model,\n",
    "                                           test_size=online_retraining_period_size, shuffle=False)\n",
    "\n",
    "        # y_train = np.array([np.array(x) for x in y_train])#np.array(y_train).reshape(len(y_train), 16)\n",
    "        # y_test = np.array([np.array(x) for x in y_test]) #np.asanyarray(y_test).reshape(len(y_train), 16)\n",
    "        # print \"A1\", y_train, y_test, y\n",
    "\n",
    "        # =====================================================================================================\n",
    "        # IMPORTANT: The code below modifies the dummy word mappings to be forcing a false positive to be counted.\n",
    "        if max_test_accuracy < 1:\n",
    "            print(\"Overwritting Ignored Words...\")\n",
    "            print(dummy_word_index)\n",
    "            if convert_output_to_binary:\n",
    "                y_test = np.array([[0 for tmp2 in tmp1] if all(\n",
    "                    tmp1 == convert_to_binary(data=[dummy_word_index], bit_size=bit_size)[0]) else tmp1 for tmp1 in\n",
    "                                   y_test])\n",
    "            else:\n",
    "                y_test = np.array(\n",
    "                    [[0 for tmp2 in tmp1] if argmax(tmp1) == dummy_word_index else tmp1 for tmp1 in y_test])\n",
    "            print(\"Overwritting Ignored Words Completted\")\n",
    "        # =====================================================================================================\n",
    "\n",
    "        while retraining_period_counter <= online_retraining_periods:\n",
    "            # Train the model either the first time or if the accuracy deteriorates\n",
    "            if retraining_period_counter == 1 or period_online_learning_accuracy_avg < online_learning_accuracy_threshold:\n",
    "                print(\"Retraining after %d periods\" % len(period_online_learning_accuracy))\n",
    "                model_file_name = NOTEBOOK_PICKLES_DIRECTORY + \"%s_retrain_at_period_%s_%s_8.h5\" % (\n",
    "                scenario_name, retraining_period_counter, unique_key)\n",
    "\n",
    "                if load_existing_pickles and os.path.isfile(model_file_name):\n",
    "                    model = load_model(model_file_name)\n",
    "                    train_history = None\n",
    "                    train_accuracy = -1  # train_history.history['acc'][-1]\n",
    "                else:\n",
    "                    train_history = model.fit(X_train,\n",
    "                                              y_train,\n",
    "                                              epochs=lstm_epochs,\n",
    "                                              verbose=verbosity,\n",
    "                                              shuffle=False,\n",
    "                                              batch_size=lstm_batch_size)\n",
    "\n",
    "                    model.save(model_file_name)\n",
    "                    train_accuracy = train_history.history['accuracy'][-1]\n",
    "                    period_online_learning_accuracy = []  # reset stats for the new period\n",
    "                    overall_retrain_tracker.append(1)\n",
    "            else:\n",
    "                overall_retrain_tracker.append(0)\n",
    "\n",
    "            if convert_output_to_binary:\n",
    "                time_s=time.time()\n",
    "                y_pred = model.predict([1,1,1])\n",
    "                print(\"time:\",time.time()-time_s)\n",
    "                print(\"1X_test:\",X_test)\n",
    "\n",
    "                y_pred[y_pred >= 0.5] = 1\n",
    "                y_pred[y_pred < 0.5] = 0\n",
    "\n",
    "                accuracy = accuracy_score(np.array(y_test), np.array(y_pred))\n",
    "\n",
    "                aaaaa = np.packbits(np.array(y_test, dtype=np.bool).reshape(-1, 2, 8)[:, ::-1]).view(np.uint16)\n",
    "                bbbbb = np.packbits(np.array(y_pred, dtype=np.bool).reshape(-1, 2, 8)[:, ::-1]).view(np.uint16)\n",
    "\n",
    "                np.savetxt('%s/y_test_%s.txt' % (NOTEBOOK_DATA_DIRECTORY, scenario_name), aaaaa, delimiter=',',\n",
    "                           fmt='%10.5f')\n",
    "                np.savetxt('%s/y_pred_%s.txt' % (NOTEBOOK_DATA_DIRECTORY, scenario_name), bbbbb, delimiter=',',\n",
    "                           fmt='%10.5f')\n",
    "\n",
    "            else:\n",
    "                test_history = model.evaluate(X_test,\n",
    "                                              y_test,\n",
    "                                              batch_size=prediction_batch_size,\n",
    "                                              verbose=verbosity)\n",
    "                print(\"X_test:\",X_test)\n",
    "                accuracy = test_history[1]\n",
    "\n",
    "            period_online_learning_accuracy.append(accuracy)\n",
    "            period_online_learning_accuracy_avg = np.array([period_online_learning_accuracy]).mean()\n",
    "            overall_online_learning_accuracy.append(accuracy)\n",
    "            print(\"Overall Online Accuracy\", overall_online_learning_accuracy)\n",
    "\n",
    "            retraining_period_counter += 1\n",
    "            # print \"A3\", y, (retraining_period_counter-1)*online_retraining_period_size, y.shape\n",
    "            X_train, X_test = train_test_split(X[(retraining_period_counter - 1) * online_retraining_period_size:, :],\n",
    "                                               train_size=number_of_rows_to_model,\n",
    "                                               test_size=online_retraining_period_size, shuffle=False)\n",
    "            y_train, y_test = train_test_split(y[(retraining_period_counter - 1) * online_retraining_period_size:, :],\n",
    "                                               train_size=number_of_rows_to_model,\n",
    "                                               test_size=online_retraining_period_size, shuffle=False)\n",
    "\n",
    "            y_train = np.asanyarray(y_train)\n",
    "            y_test = np.asanyarray(y_test)\n",
    "\n",
    "            # =====================================================================================================\n",
    "            # IMPORTANT: The code below modifies the dummy word mappings to be forcing a false positive to be counted.\n",
    "            if max_test_accuracy < 1:\n",
    "                print(\"Overwritting Ignored Words...\")\n",
    "                print(dummy_word_index)\n",
    "                if convert_output_to_binary:\n",
    "                    y_test = np.array([[0 for tmp2 in tmp1] if all(\n",
    "                        tmp1 == convert_to_binary(data=[dummy_word_index], bit_size=bit_size)[0]) else tmp1 for tmp1 in\n",
    "                                       y_test])\n",
    "                else:\n",
    "                    y_test = np.array(\n",
    "                        [[0 for tmp2 in tmp1] if argmax(tmp1) == dummy_word_index else tmp1 for tmp1 in y_test])\n",
    "                print(\"Overwritting Ignored Words Completted\")\n",
    "            # =====================================================================================================\n",
    "\n",
    "        # plot the online learning/retraining graph only at the end.\n",
    "        if len(overall_online_learning_accuracy) > 1:\n",
    "            set_plot_size(20, 8)\n",
    "            _ = plt.figure()\n",
    "            _ = plt.plot(range(1, len(overall_online_learning_accuracy) + 1), overall_online_learning_accuracy,\n",
    "                         linestyle='-', marker='^', markersize=8, linewidth=2)\n",
    "\n",
    "            for index, val in enumerate(overall_retrain_tracker):\n",
    "                if val == 1 and index > 0:\n",
    "                    # we don't flag as retraining the beginning of the testing phase\n",
    "                    _ = plt.annotate('retrained', fontsize=22, xy=(index + 1, overall_online_learning_accuracy[index]),\n",
    "                                     xytext=(index + 1.15, overall_online_learning_accuracy[index] + 0.15),\n",
    "                                     arrowprops=dict(facecolor='black', arrowstyle=\"->\"))\n",
    "\n",
    "            _ = plt.title(\"Online Testing Accuracy Over Time\\nFor The %s App\" % (app_name))\n",
    "            _ = plt.xlabel(\"Program Execution\")\n",
    "            _ = plt.ylabel(\"Accuracy\")\n",
    "            # _ = plt.legend(['Accuracy'], loc='upper left')\n",
    "            _ = plt.ylim(0, 1.2)\n",
    "            _ = plt.xlim(0.5, len(overall_online_learning_accuracy) + 0.5)\n",
    "            _ = plt.grid(True)\n",
    "            _ = plt.savefig(NOTEBOOK_PLOTS_DIRECTORY + \"online_accuracy_%s.eps\" % (scenario_name), bbox_inches='tight')\n",
    "            _ = plt.show(block=False)\n",
    "\n",
    "        # TODO: fix to return average of all\n",
    "        np.savetxt('%s/accuracy_%s.txt' % (NOTEBOOK_REPORT_DIRECTORY, scenario_name),\n",
    "                   np.array([overall_online_learning_accuracy]), delimiter=',', fmt='%10.5f')\n",
    "        np.savetxt('%s/online_retraining_tracker_%s.txt' % (NOTEBOOK_REPORT_DIRECTORY, scenario_name),\n",
    "                   np.array([overall_retrain_tracker]), delimiter=',', fmt='%10.5f')\n",
    "\n",
    "        misc_stats['execution_time'] = time.time() - start_time\n",
    "        misc_stats['vocab_size_raw'] = vocab_size_raw\n",
    "        misc_stats['final_vocab_size'] = final_vocab_size\n",
    "        misc_stats['params'] = model.count_params()\n",
    "        misc_stats['max_test_accuracy'] = max_test_accuracy\n",
    "\n",
    "        return train_history.history['accuracy'][-1], np.array(\n",
    "            overall_online_learning_accuracy).mean(), misc_stats  # test_history[1]\n",
    "\n",
    "        # print \"Train Accuracy %f, Test Accuracy %f\" % (train_accuracy, accuracy)\n",
    "        # return train_accuracy, accuracy, misc_stats\n",
    "\n",
    "    else:\n",
    "        # =====================================================================================================\n",
    "        # Data preparation\n",
    "        # =====================================================================================================\n",
    "        encoded_final, sequences, final_vocab_size, tokenizer, tokenizer2, max_test_accuracy, max_length, dummy_word, \\\n",
    "        dummy_word_index, dummy_index, vocab_size_raw = dataset_creator(\n",
    "            scenario)\n",
    "        # =====================================================================================================\n",
    "\n",
    "        # =====================================================================================================\n",
    "        # Neural Network Configuration\n",
    "        # =====================================================================================================\n",
    "        if convert_output_to_binary:\n",
    "            model = Sequential()\n",
    "            model.add(Embedding(final_vocab_size, embedding_size, input_length=max_length - 1))\n",
    "            if USE_GPU:\n",
    "                model.add(CuDNNLSTM(lstm_size))\n",
    "            else:\n",
    "                model.add(LSTM(lstm_size))\n",
    "            model.add(Dropout(dropout_ratio))\n",
    "            model.add(Dense(bit_size,\n",
    "                            activation=activation_fuction))  # the size of this layer should align with the size of the bit representation of the output.\n",
    "            model.compile(loss=loss_function, optimizer='adam', metrics=[\n",
    "                'accuracy'])  # top_k_categorical_accuracy is still wrong but we have it for illustration purposes.\n",
    "        else:\n",
    "            model = Sequential()\n",
    "            model.add(Embedding(final_vocab_size, embedding_size, input_length=max_length - 1))\n",
    "\n",
    "            if USE_GPU:\n",
    "                model.add(CuDNNLSTM(lstm_size))\n",
    "            else:\n",
    "                model.add(LSTM(lstm_size))\n",
    "            model.add(Dropout(dropout_ratio))\n",
    "            model.add(Dense(final_vocab_size, activation=activation_fuction))\n",
    "            model.compile(loss=loss_function, optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "        if verbosity > 0:\n",
    "            print(model.summary())\n",
    "        SVG(model_to_dot(model, show_shapes=True, show_layer_names=False).create(prog='dot', format='svg'))\n",
    "        plot_model(model, to_file=NOTEBOOK_PLOTS_DIRECTORY + 'model_for_%s.png' % scenario_name, show_shapes=True,\n",
    "                   show_layer_names=False)\n",
    "        # =====================================================================================================\n",
    "\n",
    "        # =====================================================================================================\n",
    "        # Model training/testing\n",
    "        # =====================================================================================================\n",
    "        X, y = sequences[:, :-1], sequences[:, -1]\n",
    "        # print X.shape, y.shape\n",
    "        # print \"A11\", y\n",
    "        # y = y.reshape((16, len(y)))\n",
    "\n",
    "        # print \"A7\", sequences\n",
    "        # Vectorize the output y (one hot encoding)\n",
    "        if convert_output_to_binary:\n",
    "            y = convert_to_binary(data=y, bit_size=bit_size)  # converts diffs to 16 bit representation\n",
    "        else:\n",
    "            y = to_categorical(y, num_classes=final_vocab_size)\n",
    "\n",
    "        # print y\n",
    "        # y = np.array([np.array(tmp_y) for tmp_y in y])\n",
    "        # y = y.reshape((y.shape[0], 16))\n",
    "        # print X.shape, y.shape\n",
    "        # print \"A8\", y.reshape(1, -1)\n",
    "\n",
    "        if on_the_fly_testing:\n",
    "            # TODO: fix the portion used for y_test to account for the pruned vocabulary\n",
    "            history = model.fit(X,\n",
    "                                y,\n",
    "                                validation_split=test_ratio,\n",
    "                                epochs=lstm_epochs,\n",
    "                                batch_size=lstm_batch_size,\n",
    "                                verbose=verbosity,\n",
    "                                shuffle=False)\n",
    "\n",
    "            save_obj(directory=NOTEBOOK_PICKLES_DIRECTORY, obj=model, name=\"%s_on_the_fly_testing\" % (scenario_name))\n",
    "            plot_on_the_fly_model_performance(history, app_name=app_name, scenario_name=scenario_name)\n",
    "\n",
    "            # TODO: fix max accuracy multiplier to be done automatically\n",
    "            np.savetxt('%s/accuracy_%s.txt' % (NOTEBOOK_REPORT_DIRECTORY, scenario_name),\n",
    "                       np.array([history.history['val_acc'][-1] * max_test_accuracy]), delimiter=',', fmt='%10.5f')\n",
    "            return history.history['accuracy'][-1] * max_test_accuracy, history.history['val_acc'][\n",
    "                -1] * max_test_accuracy, misc_stats\n",
    "\n",
    "        else:\n",
    "            X_train, X_test = train_test_split(X, test_size=test_ratio, shuffle=False)\n",
    "            y_train, y_test = train_test_split(y, test_size=test_ratio, shuffle=False)\n",
    "            # print \"A2\", y_train, y_test, y\n",
    "            # print X, X_train, X_test\n",
    "            # print y, y_train, y_test\n",
    "\n",
    "            # =====================================================================================================\n",
    "            # IMPORTANT: The code below modifies the dummy word mappings to be forcing a false positive to be counted.\n",
    "            if max_test_accuracy < 1:\n",
    "                print(\"Overwritting Ignored Words...\")\n",
    "                print(dummy_word_index)\n",
    "                if convert_output_to_binary:\n",
    "                    # print \"AA2\", y_test\n",
    "                    # for el in y_test:\n",
    "                    # print \"AA3\", el\n",
    "                    # print convert_to_binary(data=[dummy_word_index], bit_size=bit_size)\n",
    "                    # break\n",
    "                    # print pd.DataFrame(y_test).describe()\n",
    "                    # y_test = np.array([[0 for tmp2 in tmp1] if all(tmp1 == convert_to_binary(data=[dummy_word_index], bit_size=bit_size)[0]) else tmp1 for tmp1 in y_test])\n",
    "                    y_test = np.array([[0 for tmp2 in tmp1] if np.array_equal(tmp1,\n",
    "                                                                              convert_to_binary(data=[dummy_word_index],\n",
    "                                                                                                bit_size=bit_size)[\n",
    "                                                                                  0]) else tmp1 for tmp1 in y_test])\n",
    "\n",
    "                else:\n",
    "                    y_test = np.array(\n",
    "                        [[0 for tmp2 in tmp1] if argmax(tmp1) == dummy_word_index else tmp1 for tmp1 in y_test])\n",
    "                print(\"Overwritting Ignored Words Completted\")\n",
    "            # =====================================================================================================\n",
    "            # print X_train, y_train\n",
    "            model_file_name = NOTEBOOK_PICKLES_DIRECTORY + \"%s_train_test_split_%s_128.h5\" % (scenario_name, unique_key)\n",
    "\n",
    "            if load_existing_pickles and os.path.isfile(model_file_name):\n",
    "                model = load_model(model_file_name)\n",
    "                train_history = None\n",
    "                train_accuracy = -1  # train_history.history['acc'][-1]\n",
    "            else:\n",
    "                train_history = model.fit(X_train,\n",
    "                                          y_train,\n",
    "                                          epochs=lstm_epochs,\n",
    "                                          verbose=verbosity,\n",
    "                                          shuffle=False,\n",
    "                                          batch_size=lstm_batch_size)\n",
    "\n",
    "                model.save(model_file_name)\n",
    "                train_accuracy = train_history.history['accuracy'][-1]\n",
    "\n",
    "            if convert_output_to_binary:\n",
    "                time_s=time.time()\n",
    "                y_pred = model.predict(X_test)\n",
    "                print(\"time:\",time.time()-time_s)\n",
    "                print(\"2X_test:\",X_test)\n",
    "                # np.savetxt('y_test1.txt', y_test, delimiter=',')\n",
    "                # np.savetxt('y_pred1.txt', y_pred, delimiter=',')\n",
    "\n",
    "                y_pred[y_pred >= 0.5] = 1\n",
    "                y_pred[y_pred < 0.5] = 0\n",
    "\n",
    "                # np.savetxt('y_test2.txt', y_test, delimiter=',')\n",
    "                # np.savetxt('y_pred2.txt', y_pred, delimiter=',')\n",
    "\n",
    "                aaaaa = np.packbits(np.array(y_test, dtype=np.bool).reshape(-1, 2, 8)[:, ::-1]).view(np.uint16)\n",
    "                bbbbb = np.packbits(np.array(y_pred, dtype=np.bool).reshape(-1, 2, 8)[:, ::-1]).view(np.uint16)\n",
    "                # print \"ANGELOS\", scenario_name\n",
    "                np.savetxt('%s/y_test_%s.txt' % (NOTEBOOK_DATA_DIRECTORY, scenario_name), aaaaa, delimiter=',',\n",
    "                           fmt='%10.5f')\n",
    "                np.savetxt('%s/y_pred_%s.txt' % (NOTEBOOK_DATA_DIRECTORY, scenario_name), bbbbb, delimiter=',',\n",
    "                           fmt='%10.5f')\n",
    "\n",
    "                #                 plt.plot(aaaaa)\n",
    "                #                 plt.show()\n",
    "                #                 plt.plot(bbbbb)\n",
    "                #                 plt.title(\"Predictions vs Actual Data\")\n",
    "                #                 plt.show()\n",
    "\n",
    "                accuracy = accuracy_score(np.array(y_test), np.array(y_pred))\n",
    "                test_history = [0, accuracy]  # for backwards compatibility\n",
    "            else:\n",
    "                test_history = model.evaluate(X_test,\n",
    "                                              y_test,\n",
    "                                              batch_size=prediction_batch_size,\n",
    "                                              verbose=verbosity)\n",
    "                accuracy = test_history[1]\n",
    "                np.savetxt('%s/y_test_%s.txt' % (NOTEBOOK_DATA_DIRECTORY, scenario_name), [-1], delimiter=',',\n",
    "                           fmt='%10.5f')  # too much data; cannot be exported for efficiency reasons\n",
    "                np.savetxt('%s/y_pred_%s.txt' % (NOTEBOOK_DATA_DIRECTORY, scenario_name), [-1], delimiter=',',\n",
    "                           fmt='%10.5f')  # too much data; cannot be exported for efficiency reasons\n",
    "\n",
    "            misc_stats['execution_time'] = time.time() - start_time\n",
    "            misc_stats['vocab_size_raw'] = vocab_size_raw\n",
    "            misc_stats['final_vocab_size'] = final_vocab_size\n",
    "            misc_stats['params'] = model.count_params()\n",
    "            misc_stats['max_test_accuracy'] = max_test_accuracy\n",
    "\n",
    "            np.savetxt('%s/accuracy_%s.txt' % (NOTEBOOK_REPORT_DIRECTORY, scenario_name), np.array([accuracy]),\n",
    "                       delimiter=',', fmt='%10.5f')\n",
    "            plot_train_test_model_performance(train_history, test_history, app_name=app_name,\n",
    "                                              scenario_name=scenario_name)\n",
    "\n",
    "            print(\"Train Accuracy %f, Test Accuracy %f\" % (train_accuracy, accuracy))\n",
    "            return train_accuracy, accuracy, misc_stats\n",
    "            # =====================================================================================================\n",
    "\n",
    "# In [] Customizations\n",
    "from tensorflow.python.ops import math_ops\n",
    "from tensorflow.python.framework import ops\n",
    "from keras.backend import epsilon\n",
    "from tensorflow.python.ops import clip_ops\n",
    "from tensorflow.python.ops import nn\n",
    "\n",
    "\n",
    "def custom_cross_entropy(target, output, from_logits=False, axis=-1):\n",
    "    target = target[:, :-4]\n",
    "    output = output[:, :-4]\n",
    "\n",
    "    if not from_logits:\n",
    "        # transform back to logits\n",
    "        epsilon_ = ops.convert_to_tensor(epsilon(), dtype=output.dtype.base_dtype)\n",
    "        output = clip_ops.clip_by_value(output, epsilon_, 1 - epsilon_)\n",
    "        output = math_ops.log(output / (1 - output))\n",
    "    return nn.sigmoid_cross_entropy_with_logits(labels=target, logits=output)\n",
    "\n",
    "# In[] Model Evaluation Scenarios\n",
    "\n",
    "#Important Notes\n",
    "\n",
    "# Swaptions app needs a higher threshold for vocabulary capping. The best tried was 15. For the Blackscholes app we tried 5 and worked fine.\n",
    "\n",
    "trace_offsets = {\n",
    "    'swaptions_1_1M.out': 100000,\n",
    "}\n",
    "\n",
    "manager = Manager()\n",
    "\n",
    "all_results = manager.dict()  # this is for sharing data across processes and also store the features data that will be used for clustering\n",
    "\n",
    "modeling_scenarios = OrderedDict()\n",
    "\n",
    "\n",
    "def lstm_modeling_worker(scenario):\n",
    "    global all_results\n",
    "    import json\n",
    "\n",
    "    print(\"Executing Scenario %s\" % scenario['scenario_name'])\n",
    "\n",
    "    report_file_name = '%s/all_stats_%s_%s.json' % (NOTEBOOK_REPORT_DIRECTORY, scenario_name, scenario['id'])\n",
    "\n",
    "    if not scenario['skip_run_if_previous_stats_found'] or not os.path.isfile(report_file_name):\n",
    "        train_history, test_history, misc_stats = run_lstm_model(scenario)\n",
    "        all_results[scenario['scenario_name']] = [scenario, train_history, test_history, misc_stats]\n",
    "        '''\n",
    "        json = json.dumps(all_results[scenario['scenario_name']], indent=4)\n",
    "\n",
    "        f = open(report_file_name, \"w\")\n",
    "        f.write(json)\n",
    "        f.close()'''\n",
    "    else:\n",
    "        print(\"Skipping run since past results found for the same configuration...\")\n",
    "    return all_results\n",
    "\n",
    "# # 50/50 Split Analysis\n",
    "for trace in TRACE_FILE_NAMES:\n",
    "    if trace in [\n",
    "        'swaptions_1_1M.out',\n",
    "                 # 'swaptions_old_1_1M.out',\n",
    "                 # 'blackscholes_old_1_1M.out',\n",
    "                 # 'fluidanimate_old_1_1M.out'\n",
    "                 ]:\n",
    "        for model_type in [\"fpga\"]:  # \"vanilla\",  \"custom_loss_fpga\"\n",
    "            for pretrain_type in [\"rerun\", \"new\"]:\n",
    "                scenario_counter = 1\n",
    "                trace_short = trace.split(\".\")[0].replace(\"_mem\", \"\").capitalize()\n",
    "                for i in range(5, 6):\n",
    "                    # we store the scenario name as key, but also add it in the scenario configuration for availability in each function\n",
    "                    modeling_scenarios['LSTM_%s_Pretrained_%s_%s_%s' % (\n",
    "                        model_type.upper(), pretrain_type, scenario_counter, trace_short)] = {\n",
    "                        # trace params\n",
    "                        'scenario_name': 'LSTM_%s_Pretrained_%s_%s_%s' % (\n",
    "                            model_type.upper(), pretrain_type, scenario_counter, trace_short),\n",
    "                        'app_name': trace.split(\".\")[0].split(\"_\")[0].capitalize(),\n",
    "                        'trace_file_name': trace,\n",
    "                        'load_existing_pickles': True,\n",
    "                        'skip_run_if_previous_stats_found': True,\n",
    "\n",
    "                        # dataset params\n",
    "                        'keep_read_access_only': False,\n",
    "                        'number_of_rows_to_model': 400000,\n",
    "                        'number_of_rows_to_skip': trace_offsets[trace],  # int(TRACE_FILE_NAME_SIZES[trace]*3.0/5.0),\n",
    "                        'pretrain_type': pretrain_type,\n",
    "\n",
    "                        'model_diffs': True,\n",
    "                        # set to True if you want instead of the actual time series to model memory location differences.\n",
    "                        'vocabulary_maximum_size': 50000 if \"vanilla\" in model_type else 0,\n",
    "                        # this is to further reduce the dictionary size\n",
    "                        'vocabulary_mimimum_word_frequency_quantile': 0.95 if not \"fpga\" in model_type else 1,\n",
    "                        \"prune_lsb\": True if \"lsb\" in model_type else False,\n",
    "                        \"prune_length\": 1,\n",
    "                        # this corresponds to how many \"letters\" to be pruned from the HEX address (1 letter = 4 bits)\n",
    "                        \"bit_size\": 16,\n",
    "\n",
    "                        # Not Used\n",
    "                        'decompose_timeseries': False,  # not used #TODO: remove\n",
    "                        'decomposition_frequency': 10,  # not used #TODO: remove\n",
    "                        'use_manual_encoding': False,\n",
    "                        # not used #TODO: remove # True applies only to non-diff time series. --TODO: remove completely.\n",
    "\n",
    "                        # model params\n",
    "                        'model_type': model_type,  # None, #'fpga',\n",
    "                        'look_back_window': 3,\n",
    "                        'lstm_epochs': 2,\n",
    "                        'lstm_batch_size': 256,\n",
    "                        'lstm_size': 8,\n",
    "                        'dropout_ratio': 0.1,\n",
    "                        'embedding_size': 10,\n",
    "                        'verbosity': 1,\n",
    "                        'test_ratio': 0.1 * float(i),  # this does not apply to online learning\n",
    "                        'prediction_batch_size': 4096,  # this has an impact only if on_the_fly_testing is disabled\n",
    "                        'loss_function': 'categorical_crossentropy' if not \"fpga\" in model_type else \"binary_crossentropy\" if model_type in [\n",
    "                            \"fpga\", \"lsb_fpga\"] else custom_cross_entropy,\n",
    "                        # 'categorical_crossentropy', 'binary_crossentropy', # custom_crossentropy,  # binary_cross_entropy is needed for multi-label classification, otherwise we need categorical_crossentropy\n",
    "                        'activation_function': \"softmax\" if not \"fpga\" in model_type else \"sigmoid\",\n",
    "                        'convert_output_to_binary': True if \"fpga\" in model_type else False,\n",
    "\n",
    "                        # run-time params\n",
    "                        'on_the_fly_testing': False,\n",
    "                        # if True, it will run testing on the whole data for each epoch (good for plotting performance). Not used if online_retraining is enabled.\n",
    "                        'plot_timeseries': False,\n",
    "\n",
    "                        'online_retraining': False,\n",
    "                        # if this is True, then we model number_of_rows_to_model samples and then generate predictions for until the accuracy becomes smaller than online_learning_accuracy_threshold, and then we retrain etc.\n",
    "                        'online_learning_accuracy_threshold': 0.6,\n",
    "                        # It is used only if online_retraining is set to True.\n",
    "                        'online_retraining_periods': 5,  # It is used only if online_retraining is set to True.\n",
    "                        'online_retraining_period_size': 10000,\n",
    "                        # How many predictions to run before measuring cummulative accuracy for the given period. It is used only if online_retraining is set to True.\n",
    "                    }\n",
    "                    scenario_counter += 1\n",
    "\n",
    "                # calculate a unique ID for each scenario based on its values\n",
    "tmp_scenarios = modeling_scenarios.copy()\n",
    "for scenario_name, scenario in tmp_scenarios.items():\n",
    "    modeling_scenarios[scenario_name]['id'] = abs(hash(frozenset(scenario.items())))\n",
    "\n",
    "print (\"USE_GPU:\",USE_GPU)\n",
    "if not USE_GPU:\n",
    "    # with ProcessPoolExecutor(max_workers=NUMBER_OF_PROCESSES) as e:\n",
    "    for scenario_name, scenario in modeling_scenarios.items():\n",
    "        # e.submit(lstm_modeling_worker, scenario)\n",
    "        lstm_modeling_worker(scenario)\n",
    "else:\n",
    "    for scenario_name, scenario in modeling_scenarios.items():\n",
    "        lstm_modeling_worker(scenario)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Spyder Editor\n",
    "\n",
    "This is a temporary script file.\n",
    "\"\"\"\n",
    "%matplotlib inline\n",
    "import sys\n",
    "from utils import *\n",
    "X=[]\n",
    "\n",
    "if platform.system() == \"Linux\":\n",
    "    PROJECT_ROOT_DIRECTORY = \"/home/pengmiao/Project/MEMSYS/Pem/\"#\"/home/aggelos/projects/SDH/\"\n",
    "    sys.path.append(PROJECT_ROOT_DIRECTORY)\n",
    "    os.environ[\"TMP\"] = \"/tmp\"\n",
    "    USE_GPU = True\n",
    "else:\n",
    "    PROJECT_ROOT_DIRECTORY = \"E:/Lab/PyCharm/Pem_MEMSYS_try3/Anglos/\"\n",
    "    sys.path.append(PROJECT_ROOT_DIRECTORY)\n",
    "    USE_GPU = False\n",
    "\n",
    "DELETE_OLD_RESULTS = False\n",
    "\n",
    "NUMBER_OF_PROCESSES = 2\n",
    "\n",
    "PERFORM_EDA = False\n",
    "\n",
    "NOTEBOOK_ID = \"03_1\"\n",
    "\n",
    "README_TXT = \"\"\"# README\n",
    "## Ensemble modeling of memory access timeseries (using shapelets, LSTMs and more)\n",
    "\"\"\"\n",
    "###\n",
    "\n",
    "# Inputs:\n",
    "# TRACE_DIRECTORY = PROJECT_ROOT_DIRECTORY + \"data/input/\"\n",
    "#TRACE_DIRECTORY = \"E:/Lab/PyCharm/Pem_MEMSYS_try3/Anglos/data/\"\n",
    "TRACE_DIRECTORY =\"/home/pengmiao/Project/MEMSYS/data/\"\n",
    "TRACE_FILE_NAMES = [\n",
    "    'swaptions_1_1M.out'\n",
    "]  # more to be added here\n",
    "\n",
    "# Size of files in number of rows. This should be implemented as a single dict for both\n",
    "TRACE_FILE_NAME_SIZES = {\n",
    "    # \"swaptions_mem.out\": 66999281,\n",
    "    # \"blackscholes_mem.out\": 63141878,\n",
    "    # \"fluidanimate_mem.out\": 838028424\n",
    "\n",
    "    #'blackscholes_1.out': 63141878,\n",
    "    'swaptions_1_1M.out': 1000000\n",
    "\n",
    "}\n",
    "###\n",
    "\n",
    "# Outputs:\n",
    "NOTEBOOK_ROOT_DIRECTORY = PROJECT_ROOT_DIRECTORY + \"data/output/notebooks/%s/\" % NOTEBOOK_ID\n",
    "\n",
    "NOTEBOOK_PLOTS_DIRECTORY = NOTEBOOK_ROOT_DIRECTORY + \"figs/\"\n",
    "\n",
    "NOTEBOOK_DATA_DIRECTORY = NOTEBOOK_ROOT_DIRECTORY + \"data/\"\n",
    "\n",
    "NOTEBOOK_PICKLES_DIRECTORY = NOTEBOOK_ROOT_DIRECTORY + \"pickles/\"\n",
    "\n",
    "NOTEBOOK_REPORT_DIRECTORY = NOTEBOOK_ROOT_DIRECTORY + \"reports/\"\n",
    "\n",
    "###\n",
    "\n",
    "CURRENT_TIMESTAMP = get_current_timestamp()\n",
    "setup_report(data_dir=NOTEBOOK_ROOT_DIRECTORY, readme_text=README_TXT, delete_old_results=DELETE_OLD_RESULTS)\n",
    "setup_report(data_dir=NOTEBOOK_PLOTS_DIRECTORY, delete_old_results=DELETE_OLD_RESULTS)\n",
    "setup_report(data_dir=NOTEBOOK_DATA_DIRECTORY, delete_old_results=DELETE_OLD_RESULTS)\n",
    "setup_report(data_dir=NOTEBOOK_PICKLES_DIRECTORY, delete_old_results=DELETE_OLD_RESULTS)\n",
    "setup_report(data_dir=NOTEBOOK_REPORT_DIRECTORY, delete_old_results=DELETE_OLD_RESULTS)\n",
    "set_plot_style_for_paper()\n",
    "\n",
    "print(\"Destination Folder: %s\" % NOTEBOOK_ROOT_DIRECTORY)\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "# InteractiveShell.ast_node_interactivity = \"last_expr\"\n",
    "\n",
    "# this code adds also the variations of each primary trace, namely the ones with _2 and 1_rerun prefix.\n",
    "TRACE_FILE_NAMES_AND_VARIATIONS = []\n",
    "for trace in TRACE_FILE_NAMES:\n",
    "    if \"old\" not in trace:\n",
    "        TRACE_FILE_NAMES_AND_VARIATIONS.append(trace)\n",
    "        TRACE_FILE_NAMES_AND_VARIATIONS.append(trace.replace(\"1_1M\", \"2_1M\"))\n",
    "        TRACE_FILE_NAMES_AND_VARIATIONS.append(trace.replace(\"1_1M.out\", \"1_repeat_1M.out\"))\n",
    "    else:\n",
    "        TRACE_FILE_NAMES_AND_VARIATIONS.append(trace)\n",
    "print(TRACE_FILE_NAMES_AND_VARIATIONS)\n",
    "\n",
    "# In[]\n",
    "from sklearn.model_selection import train_test_split\n",
    "from numpy import array\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import to_categorical, Sequence\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.layers import LSTM, CuDNNLSTM\n",
    "from keras.layers import Embedding\n",
    "from keras.utils import plot_model\n",
    "from keras.models import load_model, save_model\n",
    "from IPython.display import SVG, display\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "import keras.backend as K\n",
    "from sys import getsizeof\n",
    "import statsmodels.api as sm\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "from multiprocessing import Manager\n",
    "from collections import Counter\n",
    "from numpy import argmax\n",
    "from sklearn.metrics import accuracy_score\n",
    "matplotlib.rcParams['text.usetex'] = False #True\n",
    "import time\n",
    "#from tensorflow.contrib.rnn import *\n",
    "\n",
    "if USE_GPU:\n",
    "    import tensorflow as tf\n",
    "    from keras.backend.tensorflow_backend import set_session\n",
    "    config = tf.compat.v1.ConfigProto( device_count = {'GPU': 0 , 'CPU': 8} )\n",
    "    config = tf.compat.v1.ConfigProto()\n",
    "    config.gpu_options.allow_growth = True  # dynamically grow the memory used on the GPU\n",
    "    config.log_device_placement = True  # to log device placement (on which device the operation ran)\n",
    "\n",
    "    sess = tf.compat.v1.Session(config=config)\n",
    "    #set_session(sess)\n",
    "    tf.compat.v1.keras.backend.set_session(sess)\n",
    "    print(tf.test.gpu_device_name())\n",
    "\n",
    "# In[] Data Preprocessing Functions\n",
    "def convert_to_binary(data=None, bit_size=16):\n",
    "    \"\"\"\n",
    "    Input: an array of integers\n",
    "    Returns a numpy array of arrays where each number is represented with a list of its binary digits\n",
    "    IMPORTANT: Currently 16 bit conversion is implemented below. For difference sizes, change 16 to something else.\n",
    "    \"\"\"\n",
    "    if bit_size == 16:\n",
    "        dataset = np.array([[int(d) for d in str('{0:016b}'.format(x))] for x in list(data)])\n",
    "    elif bit_size == 32 or bit_size not in [16, 32]:\n",
    "        if bit_size != 32:\n",
    "            print\n",
    "            \"Using 32bits delta representation\"\n",
    "        dataset = np.array([[int(d) for d in str('{0:032b}'.format(x))] for x in list(data)])\n",
    "    # print \"A10\", dataset[:10]\n",
    "    return dataset\n",
    "\n",
    "\n",
    "def difference(dataset, interval=1):\n",
    "    \"\"\"\n",
    "    Calculates the difference between a time-series and a lagged version of it\n",
    "    \"\"\"\n",
    "    diff = list()\n",
    "    for i in range(interval, len(dataset)):\n",
    "        value = dataset[i] - dataset[i - interval]\n",
    "        diff.append(value)\n",
    "    return diff\n",
    "\n",
    "\n",
    "def difference16(data=None, lag=1, prune_lsb=False, prune_length=None):\n",
    "    \"\"\"\n",
    "    Calculates the difference between a time-series and a lagged version of it that are represented in HEX format.\n",
    "    This can be used to convert memory addresses to integers.\n",
    "    \"\"\"\n",
    "    diff = list()\n",
    "    for i in range(lag, len(data)):\n",
    "        if prune_lsb:\n",
    "            value = int(data[i][:-prune_length] + '0' * prune_length, 16) - int(\n",
    "                data[i - lag][:-prune_length] + '0' * prune_length, 16)\n",
    "        else:\n",
    "            value = int(data[i], 16) - int(data[i - lag], 16)\n",
    "        diff.append(value)\n",
    "    return diff\n",
    "\n",
    "\n",
    "def inverse_difference(last_ob, value):\n",
    "    \"\"\"\n",
    "    Reconstructs the next value of a differenced time series.\n",
    "    \"\"\"\n",
    "    return value + last_ob\n",
    "\n",
    "# In[] Plot Configuration\n",
    "params = {\n",
    "    'axes.labelsize': 28,\n",
    "    'font.size': 24,\n",
    "    'legend.fontsize': 24,\n",
    "    'xtick.labelsize': 24,\n",
    "    'ytick.labelsize': 24,\n",
    "    'text.usetex': False, #True,\n",
    "    #'figure.figsize': [4.5, 4.5],\n",
    "    'figure.facecolor': 'w',\n",
    "    'figure.edgecolor': 'w',\n",
    "    'axes.facecolor': 'w',\n",
    "    'axes.edgecolor': 'gray',\n",
    "    'savefig.facecolor': 'w',\n",
    "    'savefig.edgecolor': 'g',\n",
    "    'savefig.pad_inches': 0.1,\n",
    "    'savefig.transparent': True,\n",
    "    'axes.titlepad': 24,\n",
    "    'axes.titlesize': 32\n",
    "}\n",
    "rcParams.update(params)\n",
    "\n",
    "# In[] Perform EDA\n",
    "\n",
    "# PERFORM_EDA = False\n",
    "NROWS = 500000\n",
    "\n",
    "manager = Manager()\n",
    "\n",
    "\n",
    "def run_eda(dataset=None, app_name=None, manual_encoding=False, decompose_timeseries=False, file_suffix=None):\n",
    "    set_plot_size(8, 8)\n",
    "\n",
    "    file_name_suffix = (\"tok_seq\" if not manual_encoding else \"manual_enc_seq\") + (\n",
    "        \"_decomposed\" if decompose_timeseries else \"\") + (\n",
    "                                   \"_%s_%s.eps\" % (app_name.replace(\" \", \"_\"), file_suffix)).replace(\"-\", \"_\").replace(\n",
    "        \" \", \"_\").lower()\n",
    "    report_name_prefix = (\"Of Mem Deltas  \" if decompose_timeseries else \"\") + (\n",
    "        \"\" if not manual_encoding else \"Of Manually\")\n",
    "\n",
    "    #     if not manual_encoding:\n",
    "    #         tokenizer = Tokenizer()\n",
    "    #         tokenizer.fit_on_texts(list(dataset))\n",
    "    #         encoded_all = tokenizer.texts_to_sequences([' '.join(list(dataset))])[0]\n",
    "    #     else:\n",
    "    #         encoded_all = encode_mem_accesses(list(dataset)) # angelos version\n",
    "    # TODO: cleanup code here since we are now passing deltas\n",
    "    encoded_all = dataset  # its already delta\n",
    "    if decompose_timeseries:\n",
    "        # decomposition implements diff for now\n",
    "\n",
    "        # encoded_all = get_timeseries_decomposition(data=encoded_all, frequency=decomposition_freq, plot=True, file_name_suffix=file_name_suffix, app_name=app_name, report_name_prefix=report_name_prefix)[2]\n",
    "        # encoded_all = [x for x in encoded_all if str(x) != 'nan']\n",
    "        encoded_all = difference(encoded_all, 1)\n",
    "\n",
    "    set_plot_size(16, 5)\n",
    "    _ = plt.figure()\n",
    "    # _ = pd.DataFrame(encoded_all, columns=[\"address\"]).plot(linewidth=1, fontsize=22)\n",
    "    _ = plt.plot(encoded_all, marker='x', markersize=8, linestyle='None')\n",
    "    _ = plt.ylim([-50000, 50000])\n",
    "    _ = plt.title(\"Memory Delta Time-Series %s\\nFor Trace %s\" % (report_name_prefix, app_name))\n",
    "    _ = plt.xlabel(\"Time\")\n",
    "    _ = plt.ylabel(\"Memory Address Delta\")\n",
    "    _ = plt.grid(True)\n",
    "    _ = plt.savefig(NOTEBOOK_PLOTS_DIRECTORY + \"raw_ts_pruned_%s\" % (file_name_suffix.replace(\".eps\", \"png\")),\n",
    "                    bbox_inches='tight')\n",
    "    _ = plt.show(block=False)\n",
    "    set_plot_size(8, 8)\n",
    "\n",
    "\n",
    "def eda_worker(dataset, app_name, file_suffix):\n",
    "    \"\"\"\n",
    "    Implements the main call that generates data for Experimental Data Analysis (EDA)\n",
    "    \"\"\"\n",
    "    run_eda(dataset=dataset, app_name=app_name, decompose_timeseries=False, manual_encoding=False,\n",
    "            file_suffix=file_suffix)\n",
    "\n",
    "# In[] Perform Time Series Shapelet Analysis\n",
    "rcParams['agg.path.chunksize'] = 10000\n",
    "\n",
    "# PERFORM_EDA = False\n",
    "NROWS = 10000\n",
    "\n",
    "NCHUNKS = 2\n",
    "SKIP_ROWS = 1000\n",
    "\n",
    "manager = Manager()\n",
    "\n",
    "# shapelet_report = manager.dict()\n",
    "shapelet_report = {}  # This nested dictionary cannot be implemented with multiprocesses bc its not mutable. So we fall back to using signle processes\n",
    "\n",
    "\n",
    "def run_shape_analyzer(dataset=None, app_name=None, manual_encoding=False, decompose_timeseries=False, chunk_id=None):\n",
    "    global shapelet_report\n",
    "    set_plot_size(30, 6)\n",
    "\n",
    "    encoded_all = dataset\n",
    "    file_name_suffix = (\"tok_seq\" if not manual_encoding else \"manual_enc_seq\") + (\n",
    "        \"_decomposed\" if decompose_timeseries else \"\") + (\"%s_%s.png\" % (chunk_id, app_name.replace(\" \", \"_\"))).replace(\n",
    "        \"-\", \"_\").replace(\" \", \"_\").lower()\n",
    "    report_name_prefix = (\"Of Mem Deltas  \" if decompose_timeseries else \"\") + (\n",
    "        \"\" if not manual_encoding else \"Of Manually\")\n",
    "\n",
    "    report_id = \"%s_%s_%s\" % (app_name, manual_encoding, decompose_timeseries)\n",
    "    report_name = app_name.replace(\" \", \"\")\n",
    "    params = {\n",
    "        \"manual_enconding\": manual_encoding,\n",
    "        \"decompose_timeseries\": decompose_timeseries\n",
    "    }\n",
    "\n",
    "    if report_id not in shapelet_report.keys():\n",
    "        shapelet_report[report_id] = {\n",
    "            \"report_name\": report_name,\n",
    "            \"params\": params,\n",
    "            \"plots\": {\n",
    "                \"movavg\": {},\n",
    "                \"rawts\": {},\n",
    "                \"diffts\": {},\n",
    "                \"rollacf\": {},\n",
    "                \"acfts\": {}\n",
    "            }\n",
    "        }\n",
    "    filename = NOTEBOOK_PLOTS_DIRECTORY + \"mov_avg_%s\" % (file_name_suffix)\n",
    "    print(filename)\n",
    "    print(encoded_all[:100])\n",
    "\n",
    "    _ = plt.figure()\n",
    "    _ = pd.DataFrame(encoded_all, columns=[\"address\"]).rolling(1000).mean().plot(linewidth=1, fontsize=22)\n",
    "    _ = plt.title(\"Moving Average %s\\nTrace %s\" % (report_name_prefix, app_name))\n",
    "    _ = plt.xlabel(\"Time\")\n",
    "    _ = plt.ylabel(\"Average Memory Address\")\n",
    "    _ = plt.grid(True)\n",
    "    _ = plt.savefig(filename, bbox_inches='tight')\n",
    "    _ = plt.show(block=False)\n",
    "    shapelet_report[report_id][\"plots\"][\"movavg\"][chunk_id] = filename\n",
    "\n",
    "    filename = NOTEBOOK_PLOTS_DIRECTORY + \"raw_ts_%s\" % (file_name_suffix)\n",
    "    _ = plt.figure()\n",
    "    _ = pd.DataFrame(encoded_all, columns=[\"address\"]).plot(linewidth=1, fontsize=22)\n",
    "    _ = plt.title(\"Raw Time-Series %s\\nTrace %s\" % (report_name_prefix, app_name))\n",
    "    _ = plt.xlabel(\"Time\")\n",
    "    _ = plt.ylabel(\"Memory Address\")\n",
    "    _ = plt.grid(True)\n",
    "    _ = plt.savefig(filename, bbox_inches='tight')\n",
    "    _ = plt.show(block=False)\n",
    "    shapelet_report[report_id][\"plots\"][\"rawts\"][chunk_id] = filename\n",
    "\n",
    "    # TODO: make this diff to be done directly on the MEM addresses (HEX)\n",
    "    filename = NOTEBOOK_PLOTS_DIRECTORY + \"diff_ts_%s\" % (file_name_suffix)\n",
    "    # _ = pd.DataFrame(encoded_all, columns=[\"address\"]).diff().plot(linewidth=1, fontsize=22)\n",
    "    # _ = pd.DataFrame(pd.DataFrame(encoded_all, columns=[\"address\"]).diff(), columns=[\"address\"]).rolling(1000).mean().plot(linewidth=1, fontsize=22)\n",
    "    _ = plt.figure()\n",
    "    _ = pd.DataFrame(encoded_all, columns=[\"address\"]).diff().plot(linewidth=1, fontsize=22)\n",
    "    _ = plt.title(\"Delta Time-Series %s\\nTrace %s\" % (report_name_prefix, app_name))\n",
    "    _ = plt.xlabel(\"Time\")\n",
    "    _ = plt.ylabel(\"Memory Address Deltas\")\n",
    "    _ = plt.grid(True)\n",
    "    _ = plt.savefig(filename, bbox_inches='tight')\n",
    "    _ = plt.show(block=False)\n",
    "    shapelet_report[report_id][\"plots\"][\"diffts\"][chunk_id] = filename\n",
    "\n",
    "\n",
    "def trace_shape_analyzer_worker(dataset, app_name, chunk_id):\n",
    "    \"\"\"\n",
    "    Implements the main call that generates data for Experimental Data Analysis (EDA)\n",
    "    \"\"\"\n",
    "    run_shape_analyzer(dataset=dataset, app_name=app_name, decompose_timeseries=False, manual_encoding=False,\n",
    "                       chunk_id=chunk_id)\n",
    "    # run_shape_analyzer(dataset=dataset, app_name=app_name, decompose_timeseries=False, manual_encoding=True, chunk_id=chunk_id)\n",
    "    # run_shape_analyzer(dataset=dataset, app_name=app_name, decompose_timeseries=True, manual_encoding=False, chunk_id=chunk_id)\n",
    "    # run_shape_analyzer(dataset=dataset, app_name=app_name, decompose_timeseries=True, manual_encoding=True, chunk_id=chunk_id)\n",
    "\n",
    "\n",
    "chunk = 0\n",
    "word_index = 1\n",
    "encoding_dictionary = defaultdict(int)\n",
    "\n",
    "print(dict(shapelet_report))\n",
    "\n",
    "\n",
    "# In[] Process Report\n",
    "def create_html_report(config, report_name):\n",
    "    page = []\n",
    "    page.append(\"\"\"<html>\n",
    "    <head>\n",
    "    <title>SDH Report</title>\n",
    "    </head>\n",
    "    <body>\"\"\")\n",
    "\n",
    "    # page.append('<ul>\\n')\n",
    "\n",
    "    for report_id, val in config.iteritems():\n",
    "        print(report_id)\n",
    "        page.append(\"<h1>%s</h1>\" % report_id.replace(\"_False_False\", \"\"))\n",
    "        page.append(\"\"\"\n",
    "            <table style=\"width:100%\">\n",
    "              <tr>\n",
    "                <th width=\"10%\">Metric Name</th>\n",
    "                <th width=\"90%\">Plot</th>\n",
    "              </tr>\n",
    "        \"\"\")\n",
    "        for k, v in val[\"plots\"].iteritems():\n",
    "            print(k, v)\n",
    "            for kk, vv in v.iteritems():\n",
    "                page.append('<tr><td>Chunk # %s of %s </td>' % (kk, k))\n",
    "                page.append('<td><img src=\"%s\"></td></tr>' % vv)\n",
    "\n",
    "        page.append('</table>\\n')\n",
    "    page.append('</body></html>')\n",
    "\n",
    "    with open(NOTEBOOK_REPORT_DIRECTORY + report_name + \".html\", \"w\") as text_file:\n",
    "        text_file.write('\\n'.join(page))\n",
    "\n",
    "\n",
    "if len(shapelet_report) > 0:\n",
    "    create_html_report(dict(shapelet_report), \"shapelet\")\n",
    "else:\n",
    "    print(\"Skipping EDA report generation\")\n",
    "\n",
    "\n",
    "# In[] Modeling Functions\n",
    "def precision(y_true, y_pred):\n",
    "    \"\"\"Precision metric. Only computes a batch-wise average of precision.\n",
    "-    Computes the precision, a metric for multi-label classification of\n",
    "-    how many selected items are relevant.\n",
    "-    \"\"\"\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "\n",
    "def recall(y_true, y_pred):\n",
    "    \"\"\"Recall metric.\n",
    "-    Only computes a batch-wise average of recall.\n",
    "-    Computes the recall, a metric for multi-label classification of\n",
    "-    how many relevant items are selected.\n",
    "-    \"\"\"\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "\n",
    "def fbeta_score(y_true, y_pred, beta=1):\n",
    "    \"\"\"Computes the F score.\n",
    "-    The F score is the weighted harmonic mean of precision and recall.\n",
    "-    Here it is only computed as a batch-wise average, not globally.\n",
    "-    This is useful for multi-label classification, where input samples can be\n",
    "-    classified as sets of labels. By only using accuracy (precision) a model\n",
    "-    would achieve a perfect score by simply assigning every class to every\n",
    "-    input. In order to avoid this, a metric should penalize incorrect class\n",
    "-    assignments as well (recall). The F-beta score (ranged from 0.0 to 1.0)\n",
    "-    computes this, as a weighted mean of the proportion of correct class\n",
    "-    assignments vs. the proportion of incorrect class assignments.\n",
    "-    With beta = 1, this is equivalent to a F-measure. With beta < 1, assigning\n",
    "-    correct classes becomes more important, and with beta > 1 the metric is\n",
    "-    instead weighted towards penalizing incorrect class assignments.\n",
    "-    \"\"\"\n",
    "    if beta < 0:\n",
    "        raise ValueError('The lowest choosable beta is zero (only precision).')\n",
    "\n",
    "        # If there are no true positives, fix the F score at 0 like sklearn.\n",
    "    if K.sum(K.round(K.clip(y_true, 0, 1))) == 0:\n",
    "        return 0\n",
    "    p = precision(y_true, y_pred)\n",
    "    r = recall(y_true, y_pred)\n",
    "    bb = beta ** 2\n",
    "    fbeta_score = (1 + bb) * (p * r) / (bb * p + r + K.epsilon())\n",
    "    return fbeta_score\n",
    "\n",
    "\n",
    "def fmeasure(y_true, y_pred):\n",
    "    \"\"\"Computes the f-measure, the harmonic mean of precision and recall.\n",
    "    Here it is only computed as a batch-wise average, not globally.\n",
    "    \"\"\"\n",
    "    return fbeta_score(y_true, y_pred, beta=1)\n",
    "\n",
    "\n",
    "def encode_mem_accesses(data):\n",
    "    \"\"\"\n",
    "    It implements a mapping between a set of strings to integers.\n",
    "    It does not have a limit in the max_dictionary_size supported.\n",
    "\n",
    "    data: data input should be in Pandas DF format\n",
    "    \"\"\"\n",
    "    tmp = defaultdict(int)\n",
    "    i = 1\n",
    "    encoded = []\n",
    "    for el in list(data):\n",
    "        if not tmp[el]:\n",
    "            # if el not in tmp.keys():\n",
    "            tmp[el] = i\n",
    "            i += 1\n",
    "        encoded.append(tmp[el])\n",
    "    return encoded\n",
    "\n",
    "\n",
    "def create_windowed_dataset(data, look_back):\n",
    "    \"\"\"\n",
    "    Create the dataset by grouping windows of memory accesses together (using the look_back parameter)\n",
    "\n",
    "    data: it should be a list of integers\n",
    "    \"\"\"\n",
    "    sequences = list()\n",
    "    for i in range(look_back, len(data)):\n",
    "        sequence = data[i - look_back:i + 1]\n",
    "        sequences.append(sequence)\n",
    "    return sequences\n",
    "\n",
    "\n",
    "def get_timeseries_decomposition(data=None, frequency=None, plot=False, report_name_prefix=None, file_name_suffix=None,\n",
    "                                 app_name=None):\n",
    "    # TODO: reimplement this\n",
    "    \"\"\"\n",
    "    data is a list of integers which is converted to address - date dataframe\n",
    "    \"\"\"\n",
    "    dta = pd.DataFrame(data)\n",
    "    dta['date'] = dta.index\n",
    "    dta.columns = [\"address\", \"date\"]\n",
    "\n",
    "    dta['date'] = pd.DatetimeIndex(dta.date)  # ,  format=\"%Y-%m-%d %H:%M:%S\")\n",
    "    # df.index = pd.to_datetime(df.index, unit='s')\n",
    "    # dta.address.interpolate(inplace=True)\n",
    "    dta.set_index('date', inplace=True)\n",
    "\n",
    "    # dta = dta.groupby(pd.TimeGrouper('%ss' % 1), as_index=True)['total'].sum()\n",
    "    res = sm.tsa.seasonal_decompose(dta, freq=frequency, model='additive')\n",
    "    if plot:\n",
    "        _ = plt.figure()\n",
    "        _ = res.plot()\n",
    "        _ = plt.title(\n",
    "            \"Time Series Decomposition Of %s Tokenized Sequence For Trace %s\" % (report_name_prefix, app_name))\n",
    "        _ = plt.grid(True)\n",
    "        _ = plt.savefig(NOTEBOOK_PLOTS_DIRECTORY + \"hist_%s\" % (file_name_suffix), bbox_inches='tight')\n",
    "        _ = plt.show(block=False)\n",
    "\n",
    "    return list(res.trend['address']), list(res.seasonal['address']), list(res.resid['address'])\n",
    "\n",
    "\n",
    "def plot_generic_timeseries(train_data=None,test_data=None, rows=2000, app_name=\"\", scenario_name=None):\n",
    "    set_plot_size(30, 4)\n",
    "    scenario_name = scenario_name.replace(\"_\", \"-\").replace(\" \", \"-\")\n",
    "\n",
    "    _ = plt.figure()\n",
    "    _ = plt.plot(train_data[:rows])  # , linestyle='-', marker='.', markersize=6, linewidth=1)\n",
    "    _ = plt.xlabel(\"Time\")\n",
    "    _ = plt.ylabel(\"Memory Address\")\n",
    "    _ = plt.title(\"Memory Access Timeseries For Trace %s - Scenario %s - Training Phase\" % (app_name, scenario_name))\n",
    "    _ = plt.grid(True)\n",
    "    _ = plt.savefig(NOTEBOOK_PLOTS_DIRECTORY + \"memory_accesses_training_%s_%s.eps\" % (app_name, scenario_name),\n",
    "                    bbox_inches='tight')\n",
    "    _ = plt.show(block=False)\n",
    "\n",
    "    _ = plt.figure()\n",
    "    _ = plt.plot(test_data[:rows])  # , linestyle='-', marker='.', markersize=6, linewidth=1)\n",
    "    _ = plt.xlabel(\"Time\")\n",
    "    _ = plt.ylabel(\"Memory Address\")\n",
    "    _ = plt.title(\"Memory Access Timeseries For Trace %s - Scenario %s - Testing Phase\" % (app_name, scenario_name))\n",
    "    _ = plt.grid(True)\n",
    "    _ = plt.savefig(NOTEBOOK_PLOTS_DIRECTORY + \"memory_accesses_testing_%s_%s.eps\" % (app_name, scenario_name),\n",
    "                    bbox_inches='tight')\n",
    "    _ = plt.show(block=False)\n",
    "\n",
    "\n",
    "def plot_memory_trace(train_data=None, test_data=None, rows=2000, app_name=\"\", scenario_name=None):\n",
    "    set_plot_size(30, 4)\n",
    "    scenario_name = scenario_name.replace(\"_\", \"-\").replace(\" \", \"-\")\n",
    "\n",
    "    _ = plt.figure()\n",
    "    _ = plt.plot(train_data[:rows])  # , linestyle='-', marker='.', markersize=6, linewidth=1)\n",
    "    _ = plt.xlabel(\"Time\")\n",
    "    _ = plt.ylabel(\"Memory Address\")\n",
    "    _ = plt.title(\"Memory Access Timeseries For Trace %s - Scenario %s - Training Phase\" % (app_name, scenario_name))\n",
    "    _ = plt.grid(True)\n",
    "    _ = plt.savefig(NOTEBOOK_PLOTS_DIRECTORY + \"memory_accesses_training_%s_%s.eps\" % (app_name, scenario_name),\n",
    "                    bbox_inches='tight')\n",
    "    _ = plt.show(block=False)\n",
    "\n",
    "    _ = plt.figure()\n",
    "    _ = plt.plot(test_data[:rows])  # , linestyle='-', marker='.', markersize=6, linewidth=1)\n",
    "    _ = plt.xlabel(\"Time\")\n",
    "    _ = plt.ylabel(\"Memory Address\")\n",
    "    _ = plt.title(\"Memory Access Timeseries For Trace %s - Scenario %s - Testing Phase\" % (app_name, scenario_name))\n",
    "    _ = plt.grid(True)\n",
    "    _ = plt.savefig(NOTEBOOK_PLOTS_DIRECTORY + \"memory_accesses_testing_%s_%s.eps\" % (app_name, scenario_name),\n",
    "                    bbox_inches='tight')\n",
    "    _ = plt.show(block=False)\n",
    "\n",
    "\n",
    "def plot_on_the_fly_model_performance(history=None, app_name=\"\", scenario_name=None):\n",
    "    # TODO: optimize function and remove key accesses from the dictionaries (pass them as params)\n",
    "    # Plot training & validation accuracy values\n",
    "    scenario_name = scenario_name.replace(\"_\", \"-\").replace(\" \", \"-\")\n",
    "\n",
    "    set_plot_size(6, 6)\n",
    "    _ = plt.figure()\n",
    "    _ = plt.plot(range(1, len(history.history['acc']) + 1), history.history['acc'], linestyle='-', marker='^',\n",
    "                 markersize=8, linewidth=2)\n",
    "    _ = plt.plot(range(1, len(history.history['val_acc']) + 1), history.history['val_acc'], linestyle='-', marker='s',\n",
    "                 markersize=8, linewidth=2)\n",
    "    _ = plt.title('Model Accuracy For Trace %s\\nScenario %s' % (app_name, scenario_name))\n",
    "    _ = plt.ylabel('Accuracy')\n",
    "    _ = plt.xlabel('Epoch No.')\n",
    "    _ = plt.grid(True)\n",
    "    _ = plt.legend(['Train', 'Test'], loc='upper left')\n",
    "    _ = plt.savefig(NOTEBOOK_PLOTS_DIRECTORY + \"train_test_accuracy_for_%s_%s.eps\" % (app_name, scenario_name),\n",
    "                    bbox_inches='tight')\n",
    "    _ = plt.show(block=False)\n",
    "\n",
    "    # Plot training & validation loss values\n",
    "    _ = plt.figure()\n",
    "    _ = plt.plot(range(1, len(history.history['loss']) + 1), history.history['loss'], linestyle='-', marker='^',\n",
    "                 markersize=8, linewidth=2)\n",
    "    _ = plt.plot(range(1, len(history.history['val_loss']) + 1), history.history['val_loss'], linestyle='-', marker='s',\n",
    "                 markersize=8, linewidth=2)\n",
    "    _ = plt.title('Model Loss For Trace %s\\nScenario %s' % (app_name, scenario_name))\n",
    "    _ = plt.ylabel('Loss')\n",
    "    _ = plt.xlabel('Epoch No.')\n",
    "    _ = plt.grid(True)\n",
    "    _ = plt.legend(['Train', 'Test'], loc='upper left')\n",
    "    _ = plt.savefig(NOTEBOOK_PLOTS_DIRECTORY + \"train_test_loss_for_%s_%s.eps\" % (app_name, scenario_name),\n",
    "                    bbox_inches='tight')\n",
    "    _ = plt.show(block=False)\n",
    "\n",
    "\n",
    "def plot_train_test_model_performance(train_history=None, test_history=None, app_name=\"\", scenario_name=None):\n",
    "    # TODO: optimize function and remove key accesses from the dictionaries (pass them as params)\n",
    "    if train_history is not None:\n",
    "        print('Final Training accuracy: %s' % (train_history.history['accuracy'][-1]))\n",
    "        print('Test score: %s' % test_history[0])\n",
    "        print('Test accuracy: %s' % test_history[1])\n",
    "        scenario_name = scenario_name.replace(\"_\", \"-\").replace(\" \", \"-\")\n",
    "        data = train_history.history['accuracy']\n",
    "        set_plot_size(6, 6)\n",
    "        _ = plt.figure()\n",
    "        _ = plt.plot(range(1, len(data) + 1), data, linestyle='-', marker='^', markersize=8, linewidth=2)\n",
    "        _ = plt.xticks(range(1, len(data) + 1))\n",
    "        _ = plt.title('Training Accuracy Per Epoch\\nTrace %s' % (app_name))\n",
    "        _ = plt.ylabel('Accuracy')\n",
    "        _ = plt.xlabel('Epoch No.')\n",
    "        _ = plt.grid(True)\n",
    "        # _ = plt.legend(['Train'], loc='upper left')\n",
    "        _ = plt.savefig(NOTEBOOK_PLOTS_DIRECTORY + \"train_and_test_accuracy_for_%s_%s.eps\" % (app_name, scenario_name),\n",
    "                        bbox_inches='tight')\n",
    "        _ = plt.show(block=False)\n",
    "\n",
    "\n",
    "def approx_entropy(U, m, r):\n",
    "    try:\n",
    "        U = np.array(U)\n",
    "\n",
    "        def _maxdist(x_i, x_j):\n",
    "            return max([abs(ua - va) for ua, va in zip(x_i, x_j)])\n",
    "\n",
    "        def _phi(m):\n",
    "            x = [[U[j] for j in range(i, i + m - 1 + 1)] for i in range(N - m + 1)]\n",
    "            C = [len([1 for x_j in x if _maxdist(x_i, x_j) <= r]) / (N - m + 1.0) for x_i in x]\n",
    "            return (N - m + 1.0) ** (-1) * sum(np.log(C))\n",
    "\n",
    "        N = len(U)\n",
    "        return abs(_phi(m + 1) - _phi(m))\n",
    "    except:\n",
    "        print(U)\n",
    "        raise\n",
    "\n",
    "\n",
    "def sample_entropy(data):\n",
    "    p_data = pd.Series(data).value_counts() / len(data)  # calculates the probabilities\n",
    "    entropy = sc.stats.entropy(p_data)  # input probabilities to get the entropy\n",
    "    return entropy\n",
    "\n",
    "# In[] LSTM Model Implementation\n",
    "def dataset_creator(scenario):\n",
    "    use_manual_encoding = scenario['use_manual_encoding']\n",
    "    app_name = scenario['app_name']\n",
    "    decompose_timeseries = scenario['decompose_timeseries']\n",
    "    decomposition_frequency = scenario['decomposition_frequency']\n",
    "    test_ratio = scenario['test_ratio']\n",
    "    on_the_fly_testing = scenario['on_the_fly_testing']\n",
    "    plot_timeseries = scenario['plot_timeseries']\n",
    "    look_back = scenario['look_back_window']\n",
    "    scenario_name = scenario['scenario_name']\n",
    "    vocabulary_maximum_size = scenario['vocabulary_maximum_size']\n",
    "    vocabulary_mimimum_word_frequency_quantile = scenario['vocabulary_mimimum_word_frequency_quantile']\n",
    "    model_diffs = scenario['model_diffs']\n",
    "    lstm_batch_size = scenario['lstm_batch_size']\n",
    "    lstm_epochs = scenario['lstm_epochs']\n",
    "    verbosity = scenario['verbosity']\n",
    "    dropout_ratio = scenario['dropout_ratio']\n",
    "    lstm_size = scenario['lstm_size']\n",
    "    embedding_size = scenario['embedding_size']\n",
    "    prediction_batch_size = scenario['prediction_batch_size']\n",
    "    online_retraining = scenario['online_retraining']\n",
    "    online_learning_accuracy_threshold = scenario['online_learning_accuracy_threshold']\n",
    "    online_retraining_periods = scenario['online_retraining_periods']\n",
    "    online_retraining_period_size = scenario['online_retraining_period_size']\n",
    "    number_of_rows_to_model = scenario['number_of_rows_to_model']\n",
    "    number_of_rows_to_skip = scenario['number_of_rows_to_skip']\n",
    "    keep_read_access_only = scenario['keep_read_access_only']\n",
    "    prune_lsb = scenario['prune_lsb']\n",
    "    prune_length = scenario['prune_length']\n",
    "    pretrain_type = scenario[\"pretrain_type\"]\n",
    "    bit_size = scenario[\"bit_size\"]\n",
    "    convert_output_to_binary = scenario['convert_output_to_binary']  # this is used for FPGA implementation.\n",
    "\n",
    "    max_test_accuracy = 1\n",
    "    # used to reduce accuracy appropriatelly in case of rounding/approximations in the prediction address.\n",
    "\n",
    "    tokenizer = None\n",
    "    tokenizer2 = None\n",
    "\n",
    "    # This is used to represent rare words and not get encoded individually, which then will be\n",
    "    # flagged as false positives (or negatives) and use them to reduce the model accuracy\n",
    "    # All the rare words will be encoded with the following value.\n",
    "    dummy_word = \"0xffffffff\"\n",
    "    dummy_word_index = -1  # this is the index of the dummy word (to be set later)\n",
    "\n",
    "    # this is to be used to spoof the index of the dummy word and thus force false positive\n",
    "    # determination during testing (since these words cannot be predicted)\n",
    "    dummy_index = -1\n",
    "\n",
    "    # Set total rows to None to load all the rows for online learning. Else keep as many as we need.\n",
    "    total_rows = scenario['number_of_rows_to_model'] if not online_retraining else \\\n",
    "        scenario['number_of_rows_to_model'] + online_retraining_period_size * (online_retraining_periods + 2)\n",
    "    print(\"Running for %d\" % total_rows)\n",
    "\n",
    "    if pretrain_type is None:\n",
    "        dataset_verbose = pd.read_csv(TRACE_DIRECTORY + scenario['trace_file_name'], sep=\" \", nrows=total_rows,\n",
    "                                      skiprows=scenario['number_of_rows_to_skip'])\n",
    "    else:\n",
    "        ### This implements testing with a pretrained model\n",
    "        # TODO: put this info about the rerun files at the begining of the script as a dictionary.\n",
    "        comparison_file_name = scenario['trace_file_name']\n",
    "        if pretrain_type == \"rerun\":\n",
    "            comparison_file_name = comparison_file_name.replace(\"_1M.out\", \"\") + \"_repeat_1M.out\"\n",
    "        if pretrain_type == \"new\":\n",
    "            comparison_file_name = comparison_file_name.replace(\"1_\", \"2_\")\n",
    "        ###\n",
    "\n",
    "        #dataset_verbose1 = pd.read_csv(TRACE_DIRECTORY + comparison_file_name, sep=\" \",\n",
    "        #                               nrows=int(math.floor(total_rows / 2.0)),\n",
    "        #                               skiprows=scenario['number_of_rows_to_skip'])\n",
    "        dataset_verbose1 = pd.read_csv(TRACE_DIRECTORY + comparison_file_name,sep=\" \",\n",
    "                                       nrows=int(math.floor(total_rows / 2.0)),\n",
    "                                       skiprows=scenario['number_of_rows_to_skip'])\n",
    "        #dataset_verbose1.columns = [\"instruction\", \"address\"]\n",
    "        #print(dataset_verbose1)\n",
    "        dataset_verbose1.columns = [\"instruction\", \"type\", \"address\"]\n",
    "        #Pem\n",
    "       # dataset_verbose1.columns = [\"address\"]\n",
    "\n",
    "        #dataset_verbose2 = pd.read_csv(TRACE_DIRECTORY + comparison_file_name, sep=\" \",\n",
    "        #                               nrows=int(math.ceil(total_rows / 2.0)),\n",
    "        #                               skiprows=scenario['number_of_rows_to_skip'] + int(math.floor(total_rows / 2.0)))\n",
    "        dataset_verbose2 = pd.read_csv(TRACE_DIRECTORY + comparison_file_name,sep=\" \",\n",
    "                                       nrows=int(math.ceil(total_rows / 2.0)),\n",
    "                                       skiprows=scenario['number_of_rows_to_skip'] + int(math.floor(total_rows / 2.0)))\n",
    "        #dataset_verbose2.columns = [\"instruction\", \"address\"]\n",
    "        # Pem\n",
    "        dataset_verbose2.columns = [\"instruction\", \"type\", \"address\"]\n",
    "\n",
    "        dataset_verbose = dataset_verbose1.append(dataset_verbose2, ignore_index=True)\n",
    "\n",
    "\n",
    "    dataset_verbose.columns = [\"instruction\", \"type\", \"address\"]\n",
    "    if keep_read_access_only:\n",
    "        dataset_verbose = dataset_verbose[dataset_verbose[\"type\"] == \"R\"]\n",
    "    # print dataset_verbose.head()\n",
    "    # print dataset_verbose.describe()\n",
    "\n",
    "    dataset = dataset_verbose['address']\n",
    "    del dataset_verbose\n",
    "\n",
    "    if not use_manual_encoding:\n",
    "        if model_diffs:\n",
    "            print(\"Tokenizing ...\")\n",
    "            # Tokenize raw memory address to convert them to integers\n",
    "            tokenizer = Tokenizer()\n",
    "            tokenizer.fit_on_texts(list(dataset))\n",
    "            concat_dataset = [' '.join(list(dataset))]\n",
    "            # This is used only for plotting purposes\n",
    "            encoded_raw = tokenizer.texts_to_sequences(concat_dataset)[0]\n",
    "\n",
    "            vocab_size_raw = len(tokenizer.word_index) + 1\n",
    "            print('Raw Vocabulary Size: %d' % vocab_size_raw)\n",
    "\n",
    "            # calculate diffs of integer memory addresses\n",
    "            # print dataset\n",
    "\n",
    "            encoded_raw_diff = difference16(data=list(dataset), lag=1, prune_lsb=prune_lsb, prune_length=prune_length)\n",
    "\n",
    "            encoded_raw_diff_str = [\"%s%d\" % (\"1x\" if x < 0 else \"0x\", abs(x)) for x in encoded_raw_diff]\n",
    "            df = pd.DataFrame(encoded_raw_diff_str)\n",
    "            # print df\n",
    "\n",
    "            df.columns = ['delta']\n",
    "\n",
    "            df2 = pd.DataFrame(pd.Series(encoded_raw_diff_str).value_counts())\n",
    "            # print \"Length2 %s\" % len(df2.index)\n",
    "            df2.columns = ['total']\n",
    "            df2['delta'] = df2.index\n",
    "            # print \"xxxxx\", df2\n",
    "            df2 = df2.reset_index(drop=True)\n",
    "            df2.columns = ['total', 'delta']\n",
    "            # print \"V2\", df2\n",
    "            bit_size_offset = 3\n",
    "\n",
    "            df2_2 = df2[['total']].copy()\n",
    "            df2_2['cumsum'] = df2_2.sort_values(by=\"total\", ascending=False)[['total']].cumsum(axis=0)\n",
    "\n",
    "            tmp_total_rows = df2['total'].sum()\n",
    "\n",
    "            # Get the row index where the cumulative quantity reaches half the total.\n",
    "            # print \"AAA44\", tmp_total_rows, df2_2.head()\n",
    "            df2_3 = df2_2[df2_2['cumsum'] < vocabulary_mimimum_word_frequency_quantile * tmp_total_rows]  # .idxmax()\n",
    "            # print \"AAA34\", myindex, tmp_total_rows\n",
    "            # print df2_2.head()\n",
    "\n",
    "            # Get the price at that index\n",
    "            vocabulary_mimimum_word_frequency = df2_3.loc[\n",
    "                df2_3['cumsum'].idxmax(), 'total']  # int(list(df2_2['total'].iloc[myindex])[0])\n",
    "\n",
    "            if vocabulary_mimimum_word_frequency == 1:\n",
    "                vocabulary_mimimum_word_frequency = 0  # since 1 is going to prune a lot of words\n",
    "            print(\"Quantile based Minimum Frequency for %s is %s\" % (\n",
    "            vocabulary_mimimum_word_frequency_quantile, vocabulary_mimimum_word_frequency))\n",
    "            # df2 = df2[df2['total'] > vocabulary_mimimum_word_frequency]\n",
    "            # print \"xxxxxxx\", df2.head()\n",
    "\n",
    "            # print \"xxxxx\", df2.head()\n",
    "\n",
    "            if vocabulary_maximum_size and not convert_output_to_binary:\n",
    "                df2 = df2[(df2.index > vocabulary_maximum_size) | (\n",
    "                            df2['total'] < vocabulary_mimimum_word_frequency)]  # TODO: make it <=\n",
    "            else:\n",
    "                df2 = df2[(df2.index > math.pow(2, bit_size) - bit_size_offset) | (df2[\n",
    "                                                                                       'total'] < vocabulary_mimimum_word_frequency)]  # we subtract words to allow for the dummy word to be also stored.\n",
    "\n",
    "            # print \"xxxxx\", df2.head()\n",
    "\n",
    "            # vocabulary_mimimum_word_frequency = np.quantile(encode_mem_accesses(list(encoded_raw_diff_str)), vocabulary_mimimum_word_frequency_quantile) # angelos version  , vocabulary_mimimum_word_frequency_quantile)\n",
    "\n",
    "            # Set a dummy value to represent the ignored deltas. This will be converted later to a unique integer using a second tokenizer.\n",
    "            # print \"Length2 %s\" % len(df2.index)\n",
    "            df.loc[df.delta.isin(df2.delta), ['delta']] = dummy_word\n",
    "\n",
    "            # print \"xxxxxx\", df[df['delta'] == dummy_word]\n",
    "            # print \"Length1 %s\" % len(df.index)\n",
    "\n",
    "            # print df.head()\n",
    "            # print df[df['delta'] == dummy_word]\n",
    "            # df.describe()\n",
    "            encoded_raw_diff_pruned = df['delta']\n",
    "            # print \"AAA3\", encoded_raw_diff_pruned.head()\n",
    "            # print \"V3\"\n",
    "            # print encoded_raw_diff_pruned.head()\n",
    "\n",
    "            # print \"pruned\", encoded_raw_diff_pruned[:300]\n",
    "            del df, df2\n",
    "\n",
    "            # Calclulate accuracy reduction due to vocabulary pruning.\n",
    "            tmp_train, tmp_test = train_test_split(encoded_raw_diff_pruned, test_size=test_ratio, shuffle=False)\n",
    "            total_removals = Counter(encoded_raw_diff_pruned)[dummy_word]\n",
    "            total_rows = len(encoded_raw_diff_pruned)\n",
    "            train_removals = Counter(tmp_train)[dummy_word]\n",
    "            train_total = len(tmp_train)\n",
    "            test_removals = Counter(tmp_test)[dummy_word]\n",
    "            test_total = len(tmp_test)\n",
    "            print(total_removals, total_rows, train_removals, train_total, test_removals, test_total)\n",
    "            max_test_accuracy = 1 - test_removals / test_total\n",
    "            print(\"Max Accuracy: %s\" % max_test_accuracy)\n",
    "            print(\"Total Removals: %s\" % total_removals)\n",
    "\n",
    "            # Tokenize again the pruned differentials to produce unique vocabulary (classes)\n",
    "            encoded_raw_diff_pruned_str = [str(x) for x in list(encoded_raw_diff_pruned)]\n",
    "            tokenizer2 = Tokenizer()\n",
    "            tokenizer2.fit_on_texts(encoded_raw_diff_pruned_str)\n",
    "            encoded_final = tokenizer2.texts_to_sequences([' '.join(encoded_raw_diff_pruned_str)])[0]\n",
    "            final_vocab_size = len(tokenizer2.word_index) + 1\n",
    "            print('Pruned Vocabulary Size: %d' % final_vocab_size)\n",
    "\n",
    "            for word, index in tokenizer2.word_index.items():\n",
    "                if word == dummy_word:\n",
    "                    print(\"%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\", word, index)\n",
    "                    dummy_word_index = index\n",
    "                    break\n",
    "        #             set_plot_size(6,6)\n",
    "        #             _ = plt.hist(encoded_final, bins=100)\n",
    "        #             _ = plt.grid(True)\n",
    "        #             _ = plt.title(\"Histogram Of All Memory Deltas After Prunning\\nFor The %s App\" % app_name)\n",
    "        #             _ = plt.show()\n",
    "\n",
    "        else:\n",
    "            tokenizer = Tokenizer()\n",
    "            tokenizer.fit_on_texts(list(dataset))\n",
    "            encoded_final = tokenizer.texts_to_sequences([' '.join(list(dataset))])[0]\n",
    "            final_vocab_size = len(tokenizer.word_index) + 1\n",
    "    else:\n",
    "        # TODO: move this in the diff section or remove completely.\n",
    "        encoded_final = encode_mem_accesses(list(dataset))  # angelos version\n",
    "        final_vocab_size = len(set(encoded_final)) + 1\n",
    "\n",
    "    if decompose_timeseries:\n",
    "        # TODO: this is incomplete. Either fix or remove completely.\n",
    "        dataset = get_timeseries_decomposition(encoded_final, decomposition_frequency)[\n",
    "            2]  # TODO add back in the predictions the trend and seasonality\n",
    "        final_vocab_size = len(set(dataset)) + 1\n",
    "\n",
    "    # The series below are for visulaization purposes only.\n",
    "    if plot_timeseries:\n",
    "        if model_diffs:\n",
    "            encoded_raw_train, encoded_raw_test = train_test_split(encoded_raw, test_size=test_ratio, shuffle=False)\n",
    "            encoded_raw_diff_train, encoded_raw_diff_test = train_test_split(encoded_raw_diff, test_size=test_ratio,\n",
    "                                                                             shuffle=False)\n",
    "            plot_memory_trace(train_data=encoded_raw_train, test_data=encoded_raw_test, rows=200000, app_name=app_name,\n",
    "                              scenario_name=scenario_name + \" Raw\")\n",
    "            plot_memory_trace(train_data=encoded_raw_diff_train, test_data=encoded_raw_diff_test, rows=200000,\n",
    "                              app_name=app_name, scenario_name=scenario_name + \" Raw Diff\")\n",
    "\n",
    "        encoded_train, encoded_test = train_test_split(encoded_final, test_size=test_ratio, shuffle=False)\n",
    "        plot_memory_trace(train_data=encoded_train, test_data=encoded_test, rows=2000, app_name=app_name,\n",
    "                          scenario_name=scenario_name + \" Final\")\n",
    "\n",
    "    sequences = create_windowed_dataset(encoded_final, look_back)\n",
    "\n",
    "    print('Final Vocabulary Size: %d' % final_vocab_size)\n",
    "    print('Total Sequences: %d' % len(sequences))\n",
    "\n",
    "    # Pad the sequences to the same length (is not really needed here since we have fixed input windows).\n",
    "    # See documentation in the source code here: https://github.com/keras-team/keras-preprocessing/blob/master/keras_preprocessing/sequence.py\n",
    "    max_length = max([len(seq) for seq in sequences])\n",
    "    sequences = pad_sequences(sequences, maxlen=max_length, padding='pre')\n",
    "\n",
    "    # print encoded_final, sequences, final_vocab_size\n",
    "\n",
    "    return encoded_final, sequences, final_vocab_size, tokenizer, tokenizer2, max_test_accuracy, max_length, dummy_word, dummy_word_index, dummy_index, vocab_size_raw\n",
    "\n",
    "# In[] Define LSTM model\n",
    "def run_lstm_model(scenario=None):\n",
    "    \"\"\"\n",
    "    Encode the sequence of memory addresses to a sequence of integers\n",
    "    We can do it either using Keras, or by implementing our own convertion function (see above \"encode_mem_accesses\")\n",
    "    For the Keras approach, see documentation in the source code here: https://github.com/keras-team/keras-preprocessing/blob/master/keras_preprocessing/text.py\n",
    "    \"\"\"\n",
    "\n",
    "    use_manual_encoding = scenario['use_manual_encoding']\n",
    "    app_name = scenario['app_name']\n",
    "    decompose_timeseries = scenario['decompose_timeseries']\n",
    "    decomposition_frequency = scenario['decomposition_frequency']\n",
    "    test_ratio = scenario['test_ratio']\n",
    "    on_the_fly_testing = scenario['on_the_fly_testing']\n",
    "    plot_timeseries = scenario['plot_timeseries']\n",
    "    look_back = scenario['look_back_window']\n",
    "    scenario_name = scenario['scenario_name']\n",
    "    vocabulary_maximum_size = scenario['vocabulary_maximum_size']\n",
    "    vocabulary_mimimum_word_frequency_quantile = scenario['vocabulary_mimimum_word_frequency_quantile']\n",
    "    model_diffs = scenario['model_diffs']\n",
    "    lstm_batch_size = scenario['lstm_batch_size']\n",
    "    lstm_epochs = scenario['lstm_epochs']\n",
    "    verbosity = scenario['verbosity']\n",
    "    dropout_ratio = scenario['dropout_ratio']\n",
    "    lstm_size = scenario['lstm_size']\n",
    "    embedding_size = scenario['embedding_size']\n",
    "    prediction_batch_size = scenario['prediction_batch_size']\n",
    "    online_retraining = scenario['online_retraining']\n",
    "    online_learning_accuracy_threshold = scenario['online_learning_accuracy_threshold']\n",
    "    online_retraining_periods = scenario['online_retraining_periods']\n",
    "    online_retraining_period_size = scenario['online_retraining_period_size']\n",
    "    number_of_rows_to_model = scenario['number_of_rows_to_model']\n",
    "    model_type = scenario['model_type']\n",
    "    loss_function = scenario['loss_function']\n",
    "    activation_fuction = scenario['activation_function']\n",
    "    convert_output_to_binary = scenario['convert_output_to_binary']  # this is used for FPGA implementation.\n",
    "    bit_size = scenario['bit_size']\n",
    "    load_existing_pickles = scenario['load_existing_pickles']\n",
    "    unique_key = abs(hash(frozenset(scenario.items())))\n",
    "\n",
    "    misc_stats = {}\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    if online_retraining:\n",
    "        \"\"\"\n",
    "        This implements the online training/testing/retraining cyble of SDH project.\n",
    "        \"\"\"\n",
    "        retraining_period_counter = 1\n",
    "\n",
    "        # =====================================================================================================\n",
    "        # Data preparation\n",
    "        # =====================================================================================================\n",
    "        encoded_final, sequences, final_vocab_size, tokenizer, tokenizer2, max_test_accuracy, max_length, dummy_word, dummy_word_index, dummy_index,\\\n",
    "        vocab_size_raw = dataset_creator(scenario)\n",
    "        # =====================================================================================================\n",
    "\n",
    "        # =====================================================================================================\n",
    "        # Neural Network Configuration\n",
    "        # =====================================================================================================\n",
    "        if convert_output_to_binary:\n",
    "            # print final_vocab_size, embedding_size, max_length-1\n",
    "            model = Sequential()\n",
    "            model.add(Embedding(final_vocab_size, embedding_size, input_length=max_length - 1))\n",
    "            if USE_GPU:\n",
    "                model.add(CuDNNLSTM(lstm_size))\n",
    "            else:\n",
    "                model.add(LSTM(lstm_size))\n",
    "            model.add(Dropout(dropout_ratio))\n",
    "            model.add(Dense(bit_size,\n",
    "                            activation=activation_fuction))  # the size of this layer should align with the size of the bit representation of the output.\n",
    "            model.compile(loss=loss_function, optimizer='adam', metrics=[\n",
    "                'accuracy'])  # top_k_categorical_accuracy is still wrong but we have it for illustration purposes.\n",
    "        else:\n",
    "            model = Sequential()\n",
    "            model.add(Embedding(final_vocab_size, embedding_size, input_length=max_length - 1))\n",
    "\n",
    "            if USE_GPU:\n",
    "                model.add(CuDNNLSTM(lstm_size))\n",
    "            else:\n",
    "                model.add(LSTM(lstm_size))\n",
    "            model.add(Dropout(dropout_ratio))\n",
    "            model.add(Dense(final_vocab_size, activation=activation_fuction))\n",
    "            model.compile(loss=loss_function, optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "        if verbosity > 0:\n",
    "            print(model.summary())\n",
    "        SVG(model_to_dot(model, show_shapes=True, show_layer_names=False).create(prog='dot', format='svg'))\n",
    "        plot_model(model, to_file=NOTEBOOK_PLOTS_DIRECTORY + 'model_for_%s.png' % scenario_name, show_shapes=True,\n",
    "                   show_layer_names=False)\n",
    "        # =====================================================================================================\n",
    "\n",
    "        # =====================================================================================================\n",
    "        # Model training/testing\n",
    "        # =====================================================================================================\n",
    "\n",
    "        X, y = sequences[:, :-1], sequences[:, -1]\n",
    "        # print \"A4\", sequences\n",
    "        # Vectorize the output y (one hot encoding)\n",
    "        if convert_output_to_binary:\n",
    "            y = convert_to_binary(data=y, bit_size=bit_size)  # converts diffs to 16 bit representation\n",
    "        else:\n",
    "            y = to_categorical(y, num_classes=final_vocab_size)\n",
    "        # print \"A5\", y\n",
    "        period_online_learning_accuracy = []\n",
    "        period_online_learning_accuracy_avg = 0\n",
    "\n",
    "        overall_online_learning_accuracy = []  # tracks the time series of accuracy overall (never reset)\n",
    "        overall_retrain_tracker = []  # tracks when retrain happens for plotting purposes\n",
    "\n",
    "        # X = np.array([np.array(tmp_x) for tmp_x in X])\n",
    "        # y = np.matrix([np.array(tmp_y) for tmp_y in y])\n",
    "        # y = np.asarray(y, dtype=int)\n",
    "\n",
    "        X_train, X_test = train_test_split(X, train_size=number_of_rows_to_model,\n",
    "                                           test_size=online_retraining_period_size, shuffle=False)\n",
    "        \n",
    "        y_train, y_test = train_test_split(y, train_size=number_of_rows_to_model,\n",
    "                                           test_size=online_retraining_period_size, shuffle=False)\n",
    "\n",
    "        # y_train = np.array([np.array(x) for x in y_train])#np.array(y_train).reshape(len(y_train), 16)\n",
    "        # y_test = np.array([np.array(x) for x in y_test]) #np.asanyarray(y_test).reshape(len(y_train), 16)\n",
    "        # print \"A1\", y_train, y_test, y\n",
    "\n",
    "        # =====================================================================================================\n",
    "        # IMPORTANT: The code below modifies the dummy word mappings to be forcing a false positive to be counted.\n",
    "        if max_test_accuracy < 1:\n",
    "            print(\"Overwritting Ignored Words...\")\n",
    "            print(dummy_word_index)\n",
    "            if convert_output_to_binary:\n",
    "                y_test = np.array([[0 for tmp2 in tmp1] if all(\n",
    "                    tmp1 == convert_to_binary(data=[dummy_word_index], bit_size=bit_size)[0]) else tmp1 for tmp1 in\n",
    "                                   y_test])\n",
    "            else:\n",
    "                y_test = np.array(\n",
    "                    [[0 for tmp2 in tmp1] if argmax(tmp1) == dummy_word_index else tmp1 for tmp1 in y_test])\n",
    "            print(\"Overwritting Ignored Words Completted\")\n",
    "        # =====================================================================================================\n",
    "\n",
    "        while retraining_period_counter <= online_retraining_periods:\n",
    "            # Train the model either the first time or if the accuracy deteriorates\n",
    "            if retraining_period_counter == 1 or period_online_learning_accuracy_avg < online_learning_accuracy_threshold:\n",
    "                print(\"Retraining after %d periods\" % len(period_online_learning_accuracy))\n",
    "                model_file_name = NOTEBOOK_PICKLES_DIRECTORY + \"%s_retrain_at_period_%s_%s_8.h5\" % (\n",
    "                scenario_name, retraining_period_counter, unique_key)\n",
    "\n",
    "                if load_existing_pickles and os.path.isfile(model_file_name):\n",
    "                    model = load_model(model_file_name)\n",
    "                    train_history = None\n",
    "                    train_accuracy = -1  # train_history.history['acc'][-1]\n",
    "                else:\n",
    "                    train_history = model.fit(X_train,\n",
    "                                              y_train,\n",
    "                                              epochs=lstm_epochs,\n",
    "                                              verbose=verbosity,\n",
    "                                              shuffle=False,\n",
    "                                              batch_size=lstm_batch_size)\n",
    "\n",
    "                    model.save(model_file_name)\n",
    "                    train_accuracy = train_history.history['accuracy'][-1]\n",
    "                    period_online_learning_accuracy = []  # reset stats for the new period\n",
    "                    overall_retrain_tracker.append(1)\n",
    "            else:\n",
    "                overall_retrain_tracker.append(0)\n",
    "\n",
    "            if convert_output_to_binary:\n",
    "                time_s=time.time()\n",
    "                y_pred = model.predict([1,1,1])\n",
    "                print(\"time:\",time.time()-time_s)\n",
    "                print(\"1X_test:\",X_test)\n",
    "\n",
    "                y_pred[y_pred >= 0.5] = 1\n",
    "                y_pred[y_pred < 0.5] = 0\n",
    "\n",
    "                accuracy = accuracy_score(np.array(y_test), np.array(y_pred))\n",
    "\n",
    "                aaaaa = np.packbits(np.array(y_test, dtype=np.bool).reshape(-1, 2, 8)[:, ::-1]).view(np.uint16)\n",
    "                bbbbb = np.packbits(np.array(y_pred, dtype=np.bool).reshape(-1, 2, 8)[:, ::-1]).view(np.uint16)\n",
    "\n",
    "                np.savetxt('%s/y_test_%s.txt' % (NOTEBOOK_DATA_DIRECTORY, scenario_name), aaaaa, delimiter=',',\n",
    "                           fmt='%10.5f')\n",
    "                np.savetxt('%s/y_pred_%s.txt' % (NOTEBOOK_DATA_DIRECTORY, scenario_name), bbbbb, delimiter=',',\n",
    "                           fmt='%10.5f')\n",
    "\n",
    "            else:\n",
    "                test_history = model.evaluate(X_test,\n",
    "                                              y_test,\n",
    "                                              batch_size=prediction_batch_size,\n",
    "                                              verbose=verbosity)\n",
    "                print(\"X_test:\",X_test)\n",
    "                accuracy = test_history[1]\n",
    "\n",
    "            period_online_learning_accuracy.append(accuracy)\n",
    "            period_online_learning_accuracy_avg = np.array([period_online_learning_accuracy]).mean()\n",
    "            overall_online_learning_accuracy.append(accuracy)\n",
    "            print(\"Overall Online Accuracy\", overall_online_learning_accuracy)\n",
    "\n",
    "            retraining_period_counter += 1\n",
    "            # print \"A3\", y, (retraining_period_counter-1)*online_retraining_period_size, y.shape\n",
    "            X_train, X_test = train_test_split(X[(retraining_period_counter - 1) * online_retraining_period_size:, :],\n",
    "                                               train_size=number_of_rows_to_model,\n",
    "                                               test_size=online_retraining_period_size, shuffle=False)\n",
    "            y_train, y_test = train_test_split(y[(retraining_period_counter - 1) * online_retraining_period_size:, :],\n",
    "                                               train_size=number_of_rows_to_model,\n",
    "                                               test_size=online_retraining_period_size, shuffle=False)\n",
    "\n",
    "            y_train = np.asanyarray(y_train)\n",
    "            y_test = np.asanyarray(y_test)\n",
    "\n",
    "            # =====================================================================================================\n",
    "            # IMPORTANT: The code below modifies the dummy word mappings to be forcing a false positive to be counted.\n",
    "            if max_test_accuracy < 1:\n",
    "                print(\"Overwritting Ignored Words...\")\n",
    "                print(dummy_word_index)\n",
    "                if convert_output_to_binary:\n",
    "                    y_test = np.array([[0 for tmp2 in tmp1] if all(\n",
    "                        tmp1 == convert_to_binary(data=[dummy_word_index], bit_size=bit_size)[0]) else tmp1 for tmp1 in\n",
    "                                       y_test])\n",
    "                else:\n",
    "                    y_test = np.array(\n",
    "                        [[0 for tmp2 in tmp1] if argmax(tmp1) == dummy_word_index else tmp1 for tmp1 in y_test])\n",
    "                print(\"Overwritting Ignored Words Completted\")\n",
    "            # =====================================================================================================\n",
    "\n",
    "        # plot the online learning/retraining graph only at the end.\n",
    "        if len(overall_online_learning_accuracy) > 1:\n",
    "            set_plot_size(20, 8)\n",
    "            _ = plt.figure()\n",
    "            _ = plt.plot(range(1, len(overall_online_learning_accuracy) + 1), overall_online_learning_accuracy,\n",
    "                         linestyle='-', marker='^', markersize=8, linewidth=2)\n",
    "\n",
    "            for index, val in enumerate(overall_retrain_tracker):\n",
    "                if val == 1 and index > 0:\n",
    "                    # we don't flag as retraining the beginning of the testing phase\n",
    "                    _ = plt.annotate('retrained', fontsize=22, xy=(index + 1, overall_online_learning_accuracy[index]),\n",
    "                                     xytext=(index + 1.15, overall_online_learning_accuracy[index] + 0.15),\n",
    "                                     arrowprops=dict(facecolor='black', arrowstyle=\"->\"))\n",
    "\n",
    "            _ = plt.title(\"Online Testing Accuracy Over Time\\nFor The %s App\" % (app_name))\n",
    "            _ = plt.xlabel(\"Program Execution\")\n",
    "            _ = plt.ylabel(\"Accuracy\")\n",
    "            # _ = plt.legend(['Accuracy'], loc='upper left')\n",
    "            _ = plt.ylim(0, 1.2)\n",
    "            _ = plt.xlim(0.5, len(overall_online_learning_accuracy) + 0.5)\n",
    "            _ = plt.grid(True)\n",
    "            _ = plt.savefig(NOTEBOOK_PLOTS_DIRECTORY + \"online_accuracy_%s.eps\" % (scenario_name), bbox_inches='tight')\n",
    "            _ = plt.show(block=False)\n",
    "\n",
    "        # TODO: fix to return average of all\n",
    "        np.savetxt('%s/accuracy_%s.txt' % (NOTEBOOK_REPORT_DIRECTORY, scenario_name),\n",
    "                   np.array([overall_online_learning_accuracy]), delimiter=',', fmt='%10.5f')\n",
    "        np.savetxt('%s/online_retraining_tracker_%s.txt' % (NOTEBOOK_REPORT_DIRECTORY, scenario_name),\n",
    "                   np.array([overall_retrain_tracker]), delimiter=',', fmt='%10.5f')\n",
    "\n",
    "        misc_stats['execution_time'] = time.time() - start_time\n",
    "        misc_stats['vocab_size_raw'] = vocab_size_raw\n",
    "        misc_stats['final_vocab_size'] = final_vocab_size\n",
    "        misc_stats['params'] = model.count_params()\n",
    "        misc_stats['max_test_accuracy'] = max_test_accuracy\n",
    "\n",
    "        return train_history.history['accuracy'][-1], np.array(\n",
    "            overall_online_learning_accuracy).mean(), misc_stats  # test_history[1]\n",
    "\n",
    "        # print \"Train Accuracy %f, Test Accuracy %f\" % (train_accuracy, accuracy)\n",
    "        # return train_accuracy, accuracy, misc_stats\n",
    "\n",
    "    else:\n",
    "        # =====================================================================================================\n",
    "        # Data preparation\n",
    "        # =====================================================================================================\n",
    "        encoded_final, sequences, final_vocab_size, tokenizer, tokenizer2, max_test_accuracy, max_length, dummy_word, \\\n",
    "        dummy_word_index, dummy_index, vocab_size_raw = dataset_creator(\n",
    "            scenario)\n",
    "        # =====================================================================================================\n",
    "\n",
    "        # =====================================================================================================\n",
    "        # Neural Network Configuration\n",
    "        # =====================================================================================================\n",
    "        if convert_output_to_binary:\n",
    "            model = Sequential()\n",
    "            model.add(Embedding(final_vocab_size, embedding_size, input_length=max_length - 1))\n",
    "            if USE_GPU:\n",
    "                model.add(CuDNNLSTM(lstm_size))\n",
    "            else:\n",
    "                model.add(LSTM(lstm_size))\n",
    "            model.add(Dropout(dropout_ratio))\n",
    "            model.add(Dense(bit_size,\n",
    "                            activation=activation_fuction))  # the size of this layer should align with the size of the bit representation of the output.\n",
    "            model.compile(loss=loss_function, optimizer='adam', metrics=[\n",
    "                'accuracy'])  # top_k_categorical_accuracy is still wrong but we have it for illustration purposes.\n",
    "        else:\n",
    "            model = Sequential()\n",
    "            model.add(Embedding(final_vocab_size, embedding_size, input_length=max_length - 1))\n",
    "\n",
    "            if USE_GPU:\n",
    "                model.add(CuDNNLSTM(lstm_size))\n",
    "            else:\n",
    "                model.add(LSTM(lstm_size))\n",
    "            model.add(Dropout(dropout_ratio))\n",
    "            model.add(Dense(final_vocab_size, activation=activation_fuction))\n",
    "            model.compile(loss=loss_function, optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "        if verbosity > 0:\n",
    "            print(model.summary())\n",
    "        SVG(model_to_dot(model, show_shapes=True, show_layer_names=False).create(prog='dot', format='svg'))\n",
    "        plot_model(model, to_file=NOTEBOOK_PLOTS_DIRECTORY + 'model_for_%s.png' % scenario_name, show_shapes=True,\n",
    "                   show_layer_names=False)\n",
    "        # =====================================================================================================\n",
    "\n",
    "        # =====================================================================================================\n",
    "        # Model training/testing\n",
    "        # =====================================================================================================\n",
    "        X, y = sequences[:, :-1], sequences[:, -1]\n",
    "        # print X.shape, y.shape\n",
    "        # print \"A11\", y\n",
    "        # y = y.reshape((16, len(y)))\n",
    "\n",
    "        # print \"A7\", sequences\n",
    "        # Vectorize the output y (one hot encoding)\n",
    "        if convert_output_to_binary:\n",
    "            y = convert_to_binary(data=y, bit_size=bit_size)  # converts diffs to 16 bit representation\n",
    "        else:\n",
    "            y = to_categorical(y, num_classes=final_vocab_size)\n",
    "\n",
    "        # print y\n",
    "        # y = np.array([np.array(tmp_y) for tmp_y in y])\n",
    "        # y = y.reshape((y.shape[0], 16))\n",
    "        # print X.shape, y.shape\n",
    "        # print \"A8\", y.reshape(1, -1)\n",
    "\n",
    "        if on_the_fly_testing:\n",
    "            # TODO: fix the portion used for y_test to account for the pruned vocabulary\n",
    "            history = model.fit(X,\n",
    "                                y,\n",
    "                                validation_split=test_ratio,\n",
    "                                epochs=lstm_epochs,\n",
    "                                batch_size=lstm_batch_size,\n",
    "                                verbose=verbosity,\n",
    "                                shuffle=False)\n",
    "\n",
    "            save_obj(directory=NOTEBOOK_PICKLES_DIRECTORY, obj=model, name=\"%s_on_the_fly_testing\" % (scenario_name))\n",
    "            plot_on_the_fly_model_performance(history, app_name=app_name, scenario_name=scenario_name)\n",
    "\n",
    "            # TODO: fix max accuracy multiplier to be done automatically\n",
    "            np.savetxt('%s/accuracy_%s.txt' % (NOTEBOOK_REPORT_DIRECTORY, scenario_name),\n",
    "                       np.array([history.history['val_acc'][-1] * max_test_accuracy]), delimiter=',', fmt='%10.5f')\n",
    "            return history.history['accuracy'][-1] * max_test_accuracy, history.history['val_acc'][\n",
    "                -1] * max_test_accuracy, misc_stats\n",
    "\n",
    "        else:\n",
    "            X_train, X_test = train_test_split(X, test_size=test_ratio, shuffle=False)\n",
    "            y_train, y_test = train_test_split(y, test_size=test_ratio, shuffle=False)\n",
    "            # print \"A2\", y_train, y_test, y\n",
    "            # print X, X_train, X_test\n",
    "            # print y, y_train, y_test\n",
    "\n",
    "            # =====================================================================================================\n",
    "            # IMPORTANT: The code below modifies the dummy word mappings to be forcing a false positive to be counted.\n",
    "            if max_test_accuracy < 1:\n",
    "                print(\"Overwritting Ignored Words...\")\n",
    "                print(dummy_word_index)\n",
    "                if convert_output_to_binary:\n",
    "                    # print \"AA2\", y_test\n",
    "                    # for el in y_test:\n",
    "                    # print \"AA3\", el\n",
    "                    # print convert_to_binary(data=[dummy_word_index], bit_size=bit_size)\n",
    "                    # break\n",
    "                    # print pd.DataFrame(y_test).describe()\n",
    "                    # y_test = np.array([[0 for tmp2 in tmp1] if all(tmp1 == convert_to_binary(data=[dummy_word_index], bit_size=bit_size)[0]) else tmp1 for tmp1 in y_test])\n",
    "                    y_test = np.array([[0 for tmp2 in tmp1] if np.array_equal(tmp1,\n",
    "                                                                              convert_to_binary(data=[dummy_word_index],\n",
    "                                                                                                bit_size=bit_size)[\n",
    "                                                                                  0]) else tmp1 for tmp1 in y_test])\n",
    "\n",
    "                else:\n",
    "                    y_test = np.array(\n",
    "                        [[0 for tmp2 in tmp1] if argmax(tmp1) == dummy_word_index else tmp1 for tmp1 in y_test])\n",
    "                print(\"Overwritting Ignored Words Completted\")\n",
    "            # =====================================================================================================\n",
    "            # print X_train, y_train\n",
    "            model_file_name = NOTEBOOK_PICKLES_DIRECTORY + \"%s_train_test_split_%s_128.h5\" % (scenario_name, unique_key)\n",
    "\n",
    "            if load_existing_pickles and os.path.isfile(model_file_name):\n",
    "                model = load_model(model_file_name)\n",
    "                train_history = None\n",
    "                train_accuracy = -1  # train_history.history['acc'][-1]\n",
    "            else:\n",
    "                train_history = model.fit(X_train,\n",
    "                                          y_train,\n",
    "                                          epochs=lstm_epochs,\n",
    "                                          verbose=verbosity,\n",
    "                                          shuffle=False,\n",
    "                                          batch_size=lstm_batch_size)\n",
    "\n",
    "                model.save(model_file_name)\n",
    "                train_accuracy = train_history.history['accuracy'][-1]\n",
    "\n",
    "            if convert_output_to_binary:\n",
    "                time_s=time.time()\n",
    "                y_pred = model.predict(X_test)\n",
    "                print(\"time:\",time.time()-time_s)\n",
    "                print(\"2X_test:\",X_test)\n",
    "                # np.savetxt('y_test1.txt', y_test, delimiter=',')\n",
    "                # np.savetxt('y_pred1.txt', y_pred, delimiter=',')\n",
    "\n",
    "                y_pred[y_pred >= 0.5] = 1\n",
    "                y_pred[y_pred < 0.5] = 0\n",
    "\n",
    "                # np.savetxt('y_test2.txt', y_test, delimiter=',')\n",
    "                # np.savetxt('y_pred2.txt', y_pred, delimiter=',')\n",
    "\n",
    "                aaaaa = np.packbits(np.array(y_test, dtype=np.bool).reshape(-1, 2, 8)[:, ::-1]).view(np.uint16)\n",
    "                bbbbb = np.packbits(np.array(y_pred, dtype=np.bool).reshape(-1, 2, 8)[:, ::-1]).view(np.uint16)\n",
    "                # print \"ANGELOS\", scenario_name\n",
    "                np.savetxt('%s/y_test_%s.txt' % (NOTEBOOK_DATA_DIRECTORY, scenario_name), aaaaa, delimiter=',',\n",
    "                           fmt='%10.5f')\n",
    "                np.savetxt('%s/y_pred_%s.txt' % (NOTEBOOK_DATA_DIRECTORY, scenario_name), bbbbb, delimiter=',',\n",
    "                           fmt='%10.5f')\n",
    "\n",
    "                #                 plt.plot(aaaaa)\n",
    "                #                 plt.show()\n",
    "                #                 plt.plot(bbbbb)\n",
    "                #                 plt.title(\"Predictions vs Actual Data\")\n",
    "                #                 plt.show()\n",
    "\n",
    "                accuracy = accuracy_score(np.array(y_test), np.array(y_pred))\n",
    "                test_history = [0, accuracy]  # for backwards compatibility\n",
    "            else:\n",
    "                test_history = model.evaluate(X_test,\n",
    "                                              y_test,\n",
    "                                              batch_size=prediction_batch_size,\n",
    "                                              verbose=verbosity)\n",
    "                accuracy = test_history[1]\n",
    "                np.savetxt('%s/y_test_%s.txt' % (NOTEBOOK_DATA_DIRECTORY, scenario_name), [-1], delimiter=',',\n",
    "                           fmt='%10.5f')  # too much data; cannot be exported for efficiency reasons\n",
    "                np.savetxt('%s/y_pred_%s.txt' % (NOTEBOOK_DATA_DIRECTORY, scenario_name), [-1], delimiter=',',\n",
    "                           fmt='%10.5f')  # too much data; cannot be exported for efficiency reasons\n",
    "\n",
    "            misc_stats['execution_time'] = time.time() - start_time\n",
    "            misc_stats['vocab_size_raw'] = vocab_size_raw\n",
    "            misc_stats['final_vocab_size'] = final_vocab_size\n",
    "            misc_stats['params'] = model.count_params()\n",
    "            misc_stats['max_test_accuracy'] = max_test_accuracy\n",
    "\n",
    "            np.savetxt('%s/accuracy_%s.txt' % (NOTEBOOK_REPORT_DIRECTORY, scenario_name), np.array([accuracy]),\n",
    "                       delimiter=',', fmt='%10.5f')\n",
    "            plot_train_test_model_performance(train_history, test_history, app_name=app_name,\n",
    "                                              scenario_name=scenario_name)\n",
    "\n",
    "            print(\"Train Accuracy %f, Test Accuracy %f\" % (train_accuracy, accuracy))\n",
    "            return train_accuracy, accuracy, misc_stats\n",
    "            # =====================================================================================================\n",
    "\n",
    "# In [] Customizations\n",
    "from tensorflow.python.ops import math_ops\n",
    "from tensorflow.python.framework import ops\n",
    "from keras.backend import epsilon\n",
    "from tensorflow.python.ops import clip_ops\n",
    "from tensorflow.python.ops import nn\n",
    "\n",
    "\n",
    "def custom_cross_entropy(target, output, from_logits=False, axis=-1):\n",
    "    target = target[:, :-4]\n",
    "    output = output[:, :-4]\n",
    "\n",
    "    if not from_logits:\n",
    "        # transform back to logits\n",
    "        epsilon_ = ops.convert_to_tensor(epsilon(), dtype=output.dtype.base_dtype)\n",
    "        output = clip_ops.clip_by_value(output, epsilon_, 1 - epsilon_)\n",
    "        output = math_ops.log(output / (1 - output))\n",
    "    return nn.sigmoid_cross_entropy_with_logits(labels=target, logits=output)\n",
    "\n",
    "# In[] Model Evaluation Scenarios\n",
    "\n",
    "#Important Notes\n",
    "\n",
    "# Swaptions app needs a higher threshold for vocabulary capping. The best tried was 15. For the Blackscholes app we tried 5 and worked fine.\n",
    "\n",
    "trace_offsets = {\n",
    "    'swaptions_1_1M.out': 100000,\n",
    "}\n",
    "\n",
    "manager = Manager()\n",
    "\n",
    "all_results = manager.dict()  # this is for sharing data across processes and also store the features data that will be used for clustering\n",
    "\n",
    "modeling_scenarios = OrderedDict()\n",
    "\n",
    "\n",
    "def lstm_modeling_worker(scenario):\n",
    "    global all_results\n",
    "    import json\n",
    "\n",
    "    print(\"Executing Scenario %s\" % scenario['scenario_name'])\n",
    "\n",
    "    report_file_name = '%s/all_stats_%s_%s.json' % (NOTEBOOK_REPORT_DIRECTORY, scenario_name, scenario['id'])\n",
    "\n",
    "    if not scenario['skip_run_if_previous_stats_found'] or not os.path.isfile(report_file_name):\n",
    "        train_history, test_history, misc_stats = run_lstm_model(scenario)\n",
    "        all_results[scenario['scenario_name']] = [scenario, train_history, test_history, misc_stats]\n",
    "        '''\n",
    "        json = json.dumps(all_results[scenario['scenario_name']], indent=4)\n",
    "\n",
    "        f = open(report_file_name, \"w\")\n",
    "        f.write(json)\n",
    "        f.close()'''\n",
    "    else:\n",
    "        print(\"Skipping run since past results found for the same configuration...\")\n",
    "    return all_results\n",
    "\n",
    "# # 50/50 Split Analysis\n",
    "for trace in TRACE_FILE_NAMES:\n",
    "    if trace in [\n",
    "        'swaptions_1_1M.out',\n",
    "                 # 'swaptions_old_1_1M.out',\n",
    "                 # 'blackscholes_old_1_1M.out',\n",
    "                 # 'fluidanimate_old_1_1M.out'\n",
    "                 ]:\n",
    "        for model_type in [\"fpga\"]:  # \"vanilla\",  \"custom_loss_fpga\"\n",
    "            for pretrain_type in [\"rerun\", \"new\"]:\n",
    "                scenario_counter = 1\n",
    "                trace_short = trace.split(\".\")[0].replace(\"_mem\", \"\").capitalize()\n",
    "                for i in range(5, 6):\n",
    "                    # we store the scenario name as key, but also add it in the scenario configuration for availability in each function\n",
    "                    modeling_scenarios['LSTM_%s_Pretrained_%s_%s_%s' % (\n",
    "                        model_type.upper(), pretrain_type, scenario_counter, trace_short)] = {\n",
    "                        # trace params\n",
    "                        'scenario_name': 'LSTM_%s_Pretrained_%s_%s_%s' % (\n",
    "                            model_type.upper(), pretrain_type, scenario_counter, trace_short),\n",
    "                        'app_name': trace.split(\".\")[0].split(\"_\")[0].capitalize(),\n",
    "                        'trace_file_name': trace,\n",
    "                        'load_existing_pickles': True,\n",
    "                        'skip_run_if_previous_stats_found': True,\n",
    "\n",
    "                        # dataset params\n",
    "                        'keep_read_access_only': False,\n",
    "                        'number_of_rows_to_model': 400000,\n",
    "                        'number_of_rows_to_skip': trace_offsets[trace],  # int(TRACE_FILE_NAME_SIZES[trace]*3.0/5.0),\n",
    "                        'pretrain_type': pretrain_type,\n",
    "\n",
    "                        'model_diffs': True,\n",
    "                        # set to True if you want instead of the actual time series to model memory location differences.\n",
    "                        'vocabulary_maximum_size': 50000 if \"vanilla\" in model_type else 0,\n",
    "                        # this is to further reduce the dictionary size\n",
    "                        'vocabulary_mimimum_word_frequency_quantile': 0.95 if not \"fpga\" in model_type else 1,\n",
    "                        \"prune_lsb\": True if \"lsb\" in model_type else False,\n",
    "                        \"prune_length\": 1,\n",
    "                        # this corresponds to how many \"letters\" to be pruned from the HEX address (1 letter = 4 bits)\n",
    "                        \"bit_size\": 16,\n",
    "\n",
    "                        # Not Used\n",
    "                        'decompose_timeseries': False,  # not used #TODO: remove\n",
    "                        'decomposition_frequency': 10,  # not used #TODO: remove\n",
    "                        'use_manual_encoding': False,\n",
    "                        # not used #TODO: remove # True applies only to non-diff time series. --TODO: remove completely.\n",
    "\n",
    "                        # model params\n",
    "                        'model_type': model_type,  # None, #'fpga',\n",
    "                        'look_back_window': 3,\n",
    "                        'lstm_epochs': 20,\n",
    "                        'lstm_batch_size': 256,\n",
    "                        'lstm_size': 8,\n",
    "                        'dropout_ratio': 0.1,\n",
    "                        'embedding_size': 10,\n",
    "                        'verbosity': 1,\n",
    "                        'test_ratio': 0.1 * float(i),  # this does not apply to online learning\n",
    "                        'prediction_batch_size': 4096,  # this has an impact only if on_the_fly_testing is disabled\n",
    "                        'loss_function': 'categorical_crossentropy' if not \"fpga\" in model_type else \"binary_crossentropy\" if model_type in [\n",
    "                            \"fpga\", \"lsb_fpga\"] else custom_cross_entropy,\n",
    "                        # 'categorical_crossentropy', 'binary_crossentropy', # custom_crossentropy,  # binary_cross_entropy is needed for multi-label classification, otherwise we need categorical_crossentropy\n",
    "                        'activation_function': \"softmax\" if not \"fpga\" in model_type else \"sigmoid\",\n",
    "                        'convert_output_to_binary': True if \"fpga\" in model_type else False,\n",
    "\n",
    "                        # run-time params\n",
    "                        'on_the_fly_testing': False,\n",
    "                        # if True, it will run testing on the whole data for each epoch (good for plotting performance). Not used if online_retraining is enabled.\n",
    "                        'plot_timeseries': False,\n",
    "\n",
    "                        'online_retraining': False,\n",
    "                        # if this is True, then we model number_of_rows_to_model samples and then generate predictions for until the accuracy becomes smaller than online_learning_accuracy_threshold, and then we retrain etc.\n",
    "                        'online_learning_accuracy_threshold': 0.6,\n",
    "                        # It is used only if online_retraining is set to True.\n",
    "                        'online_retraining_periods': 5,  # It is used only if online_retraining is set to True.\n",
    "                        'online_retraining_period_size': 10000,\n",
    "                        # How many predictions to run before measuring cummulative accuracy for the given period. It is used only if online_retraining is set to True.\n",
    "                    }\n",
    "                    scenario_counter += 1\n",
    "\n",
    "                # calculate a unique ID for each scenario based on its values\n",
    "tmp_scenarios = modeling_scenarios.copy()\n",
    "for scenario_name, scenario in tmp_scenarios.items():\n",
    "    modeling_scenarios[scenario_name]['id'] = abs(hash(frozenset(scenario.items())))\n",
    "\n",
    "print (\"USE_GPU:\",USE_GPU)\n",
    "if not USE_GPU:\n",
    "    # with ProcessPoolExecutor(max_workers=NUMBER_OF_PROCESSES) as e:\n",
    "    for scenario_name, scenario in modeling_scenarios.items():\n",
    "        # e.submit(lstm_modeling_worker, scenario)\n",
    "        lstm_modeling_worker(scenario)\n",
    "else:\n",
    "    for scenario_name, scenario in modeling_scenarios.items():\n",
    "        lstm_modeling_worker(scenario)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path=\"/home/pengmiao/Project/MEMSYS/Pem/data/output/notebooks/03_1/pickles/LSTM_FPGA_Pretrained_rerun_1_Swaptions_1_1m_train_test_split_5786126779807229184.h5\"\n",
    "model = load_model(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 0.0037114620208740234\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[9.9837780e-06, 5.7330728e-04, 2.5171041e-04, 1.0532141e-04,\n",
       "        4.8771501e-04, 2.5576353e-04, 4.8029423e-04, 3.4019351e-04,\n",
       "        3.3810735e-04, 5.1691830e-03, 1.0723293e-02, 1.4850557e-02,\n",
       "        9.2415810e-03, 3.9669037e-02, 2.5466800e-02, 9.6658200e-01]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "x_p=np.array([[1,1,1]])\n",
    "time_s=time.time()\n",
    "y_p=model.predict(x_p)\n",
    "time_e=time.time()\n",
    "print(\"time:\",time_e-time_s)\n",
    "y_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 0.0035390853881835938\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.00278109, 0.00939181, 0.00249621, 0.0012483 , 0.00189769,\n",
       "        0.00191087, 0.00484484, 0.00332645, 0.00262767, 0.06562126,\n",
       "        0.01703385, 0.04189658, 0.03534591, 0.13184848, 0.15712813,\n",
       "        0.7057959 ]], dtype=float32)"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path=\"/home/pengmiao/Project/MEMSYS/Pem/data/output/notebooks/03_1/pickles/LSTM_FPGA_Pretrained_rerun_1_Swaptions_1_1m_train_test_split_1422988847010746865_16.h5\"\n",
    "model = load_model(file_path)\n",
    "import time\n",
    "x_p=np.array([[1,1,1]])\n",
    "time_s=time.time()\n",
    "y_p=model.predict(x_p)\n",
    "time_e=time.time()\n",
    "print(\"time:\",time_e-time_s)\n",
    "y_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 0.00391077995300293\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1.51991844e-06, 3.35553288e-03, 6.92546368e-04, 8.03172588e-05,\n",
       "        1.35806203e-03, 1.78933144e-04, 2.99841166e-04, 6.27487898e-04,\n",
       "        2.63929367e-04, 1.04463398e-02, 5.86745143e-03, 1.32596195e-02,\n",
       "        7.17398524e-03, 2.37396657e-02, 2.52552927e-02, 9.82264459e-01]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#file_path=\"/home/pengmiao/Project/MEMSYS/Pem/data/output/notebooks/03_1/pickles/LSTM_FPGA_Pretrained_rerun_1_Swaptions_1_1m_train_test_split_8299409015082351217_64.h5\"\n",
    "#model = load_model(file_path)\n",
    "import time\n",
    "x_p=np.array([[1,1,1]])\n",
    "time_s=time.time()\n",
    "y_p=model.predict(x_p)\n",
    "time_e=time.time()\n",
    "print(\"time:\",time_e-time_s)\n",
    "y_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 0.004231691360473633\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1.7881393e-07, 4.9149692e-03, 5.0303936e-03, 1.6850233e-04,\n",
       "        2.9345155e-03, 9.4550848e-04, 1.2684762e-03, 1.3779104e-03,\n",
       "        1.1146069e-03, 6.1289072e-03, 9.8685622e-03, 1.3138622e-02,\n",
       "        1.0089904e-02, 1.4767617e-02, 1.2588710e-02, 9.9297088e-01]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#file_path=\"/home/pengmiao/Project/MEMSYS/Pem/data/output/notebooks/03_1/pickles/LSTM_FPGA_Pretrained_rerun_1_Swaptions_1_1m_train_test_split_2037519773339408343_128.h5\"\n",
    "#model = load_model(file_path)\n",
    "import time\n",
    "x_p=np.array([[1,1,1]])\n",
    "time_s=time.time()\n",
    "y_p=model.predict(x_p)\n",
    "time_e=time.time()\n",
    "print(\"time:\",time_e-time_s)\n",
    "y_p"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf1.n]",
   "language": "python",
   "name": "tf1.n"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

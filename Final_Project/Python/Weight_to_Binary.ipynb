{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weight to binary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "QN = 6\n",
    "QM = 11\n",
    "def real_to_Qnm(real, n, m):\n",
    "    if(real >= 0):\n",
    "        return int(np.round(real*(2**m)).astype(int))\n",
    "    else:\n",
    "        return int(2**(n+m+1) + np.round(real*(2**m)).astype(int))\n",
    "def Qnm_to_real(real, n, m):\n",
    "    real = int(real) & int(2**(n+m+1)-1)\n",
    "    if(real >= 2**(n+m)):\n",
    "        return (real-2**(n+m+1))/(2**m)\n",
    "    else:\n",
    "        return real/(2**m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/questions/4838994/float-to-binary\n",
    "#64bit IEE754\n",
    "def float_to_bin(x):\n",
    "  if x == 0:\n",
    "    return \"0\" * 64\n",
    "  w, sign = (float.hex(x), 0) if x > 0 else (float.hex(x)[1:], 1)\n",
    "  mantissa, exp = int(w[4:17], 16), int(w[18:])\n",
    "  return \"{}{:011b}{:052b}\".format(sign, exp + 1023, mantissa)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "        1, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "        1, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1,\n",
       "        1, 1, 1, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "        1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1,\n",
       "        1, 1, 1, 1],\n",
       "       [0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "        1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1,\n",
       "        1, 1, 1, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0,\n",
       "        1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1,\n",
       "        1, 1, 1, 1],\n",
       "       [1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0,\n",
       "        1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "        1, 0, 1, 0],\n",
       "       [1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        1, 0, 1, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 1, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        1, 0, 0, 0]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test=np.load(\"X_test.npy\")\n",
    "X_test=X_test[0:10]\n",
    "X_test.shape[0]\n",
    "X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-adba9c0429aa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mfin_Wz\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Input_X.dat'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mcc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mcc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcc\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_test' is not defined"
     ]
    }
   ],
   "source": [
    "fin_Wz  = open('Input_X.dat', 'w')\n",
    "cc=0\n",
    "for j in range(X_test.shape[0]) :\n",
    "    for i in range(X_test.shape[1]) :\n",
    "        cc=cc+1\n",
    "        fin_Wz.write(\"{0}\".format(int(X_test[j,i])))\n",
    "        if cc == 48:\n",
    "            fin_Wz.write(\"\\n\")\n",
    "            cc = 0\n",
    "fin_Wz.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tensorflow.python.keras.layers.embeddings.Embedding at 0x7fd50a29f630>,\n",
       " <tensorflow.python.keras.layers.recurrent.LSTM at 0x7fd50a29fc88>,\n",
       " <tensorflow.python.keras.layers.core.Dropout at 0x7fd50a29fb38>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x7fd50a261f28>]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model_file_name='my_model_dc_parsec.h5'\n",
    "model_ = load_model(model_file_name)\n",
    "model_.layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embedding: (2, 8)\n",
      "embedding: [[ 0.1511789   0.21257462  0.02249864  0.05298556  0.3013374   0.04191065\n",
      "   0.20380408  0.01847126]\n",
      " [-0.58739895 -0.8522611  -0.12063408 -0.9246319  -1.0010942  -0.925209\n",
      "  -0.6365828  -0.16443335]]\n",
      "2 8\n"
     ]
    }
   ],
   "source": [
    "print(\"embedding:\",model_.layers[0].get_weights()[0].shape)\n",
    "print(\"embedding:\",model_.layers[0].get_weights()[0])\n",
    "embedding_weight=model_.layers[0].get_weights()[0]\n",
    "embedding_INPUT_SZ=model_.layers[0].get_weights()[0].shape[0]\n",
    "embedding_HIDDEN_SZ=model_.layers[0].get_weights()[0].shape[1]\n",
    "print(embedding_INPUT_SZ,embedding_HIDDEN_SZ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "fin_Wz  = open('weight_Em_fpb.det', 'w')\n",
    "for j in range(embedding_INPUT_SZ) :\n",
    "\tfor i in range(embedding_HIDDEN_SZ) :\n",
    "\t\tfin_Wz.write(\"{0:018b}\\n\".format(int(real_to_Qnm(embedding_weight[j,i],QN,QM))))\n",
    "fin_Wz.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lstm: (3,)\n",
      "lstm_0: (8, 128)\n",
      "lstm_1: (32, 128)\n",
      "lstm_2: (128,)\n",
      "total: 12200\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(\"lstm:\",np.array(model_.layers[1].get_weights()).shape)\n",
    "print(\"lstm_0:\",model_.layers[1].get_weights()[0].shape)\n",
    "print(\"lstm_1:\",model_.layers[1].get_weights()[1].shape)\n",
    "print(\"lstm_2:\",model_.layers[1].get_weights()[2].shape)\n",
    "print(\"total: 12200\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. units:  32\n"
     ]
    }
   ],
   "source": [
    "#print(model_.layers[1].trainable_weights)\n",
    "units = int(int(model_.layers[1].trainable_weights[0].shape[1])/4)\n",
    "print(\"No. units: \", units)\n",
    "\n",
    "W = model_.layers[1].get_weights()[0]\n",
    "R = model_.layers[1].get_weights()[1]\n",
    "b = model_.layers[1].get_weights()[2]\n",
    "\n",
    "W_i = W[:, :units]\n",
    "W_f = W[:, units: units * 2]\n",
    "W_c = W[:, units * 2: units * 3]\n",
    "W_o = W[:, units * 3:]\n",
    "\n",
    "R_i = R[:, :units]\n",
    "R_f = R[:, units: units * 2]\n",
    "R_c = R[:, units * 2: units * 3]\n",
    "R_o = R[:, units * 3:]\n",
    "\n",
    "b_i = b[:units]\n",
    "b_f = b[units: units * 2]\n",
    "b_c = b[units * 2: units * 3]\n",
    "b_o = b[units * 3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 32) (32, 32) (32,)\n",
      "(8, 32) (32, 32) (32,)\n"
     ]
    }
   ],
   "source": [
    "print(W_i.shape,R_i.shape,b_i.shape)\n",
    "print(W_f.shape,R_f.shape,b_f.shape)\n",
    "# https://stackoverflow.com/questions/42861460/how-to-interpret-weights-in-a-lstm-layer-in-keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.2852685 , 1.2954607 , 1.1132425 , 1.076543  , 1.2984583 ,\n",
       "       1.137377  , 1.064606  , 1.2264651 , 1.3859788 , 1.1612115 ,\n",
       "       1.2088773 , 1.2976155 , 1.1497114 , 1.5215207 , 1.0806828 ,\n",
       "       0.9369431 , 1.036492  , 1.0942913 , 1.0145316 , 1.3832744 ,\n",
       "       0.8848595 , 1.0030036 , 1.6137878 , 1.2144096 , 0.97843343,\n",
       "       1.0646273 , 1.0207555 , 1.1481979 , 1.21238   , 1.370541  ,\n",
       "       0.7913532 , 1.0583173 ], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "fin_Wz  = open('weight_W_i_fpb.dat', 'w')\n",
    "for j in range(W_i.shape[0]) :\n",
    "\tfor i in range(W_i.shape[1]) :\n",
    "\t\tfin_Wz.write(\"{0:018b}\\n\".format(int(real_to_Qnm(W_i[j,i],QN,QM))))\n",
    "fin_Wz.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "fin_Wz  = open('weight_W_f_fpb.dat', 'w')\n",
    "for j in range(W_f.shape[0]) :\n",
    "\tfor i in range(W_f.shape[1]) :\n",
    "\t\tfin_Wz.write(\"{0:018b}\\n\".format(int(real_to_Qnm(W_f[j,i],QN,QM))))\n",
    "fin_Wz.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "fin_Wz  = open('weight_W_c_fpb.dat', 'w')\n",
    "for j in range(W_c.shape[0]) :\n",
    "\tfor i in range(W_c.shape[1]) :\n",
    "\t\tfin_Wz.write(\"{0:018b}\\n\".format(int(real_to_Qnm(W_c[j,i],QN,QM))))\n",
    "fin_Wz.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "fin_Wz  = open('weight_W_o_fpb.dat', 'w')\n",
    "for j in range(W_o.shape[0]) :\n",
    "\tfor i in range(W_o.shape[1]) :\n",
    "\t\tfin_Wz.write(\"{0:018b}\\n\".format(int(real_to_Qnm(W_o[j,i],QN,QM))))\n",
    "fin_Wz.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "fin_Wz  = open('weight_R_i_fpb.dat', 'w')\n",
    "for j in range(R_i.shape[0]) :\n",
    "\tfor i in range(R_i.shape[1]) :\n",
    "\t\tfin_Wz.write(\"{0:018b}\\n\".format(int(real_to_Qnm(R_i[j,i],QN,QM))))\n",
    "fin_Wz.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "fin_Wz  = open('weight_R_f_fpb.dat', 'w')\n",
    "for j in range(R_f.shape[0]) :\n",
    "\tfor i in range(R_f.shape[1]) :\n",
    "\t\tfin_Wz.write(\"{0:018b}\\n\".format(int(real_to_Qnm(R_f[j,i],QN,QM))))\n",
    "fin_Wz.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "fin_Wz  = open('weight_R_c_fpb.dat', 'w')\n",
    "for j in range(R_c.shape[0]) :\n",
    "\tfor i in range(R_c.shape[1]) :\n",
    "\t\tfin_Wz.write(\"{0:018b}\\n\".format(int(real_to_Qnm(R_c[j,i],QN,QM))))\n",
    "fin_Wz.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "fin_Wz  = open('weight_R_o_fpb.dat', 'w')\n",
    "for j in range(R_o.shape[0]) :\n",
    "\tfor i in range(R_o.shape[1]) :\n",
    "\t\tfin_Wz.write(\"{0:018b}\\n\".format(int(real_to_Qnm(R_o[j,i],QN,QM))))\n",
    "fin_Wz.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "fin_Wz  = open('weight_b_i_fpb.dat', 'w')\n",
    "for j in range(b_i.shape[0]) :\n",
    "\tfin_Wz.write(\"{0:018b}\\n\".format(int(real_to_Qnm(b_i[j],QN,QM))))\n",
    "fin_Wz.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "fin_Wz  = open('weight_b_f_fpb.dat', 'w')\n",
    "for j in range(b_f.shape[0]) :\n",
    "\tfin_Wz.write(\"{0:018b}\\n\".format(int(real_to_Qnm(b_f[j],QN,QM))))\n",
    "fin_Wz.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "fin_Wz  = open('weight_b_c_fpb.dat', 'w')\n",
    "for j in range(b_c.shape[0]) :\n",
    "\tfin_Wz.write(\"{0:018b}\\n\".format(int(real_to_Qnm(b_c[j],QN,QM))))\n",
    "fin_Wz.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "fin_Wz  = open('weight_b_o_fpb.dat', 'w')\n",
    "for j in range(b_o.shape[0]) :\n",
    "\tfin_Wz.write(\"{0:018b}\\n\".format(int(real_to_Qnm(b_o[j],QN,QM))))\n",
    "fin_Wz.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dense_w: (32, 16)\n",
      "dense_b: (16,)\n"
     ]
    }
   ],
   "source": [
    "print(\"dense_w:\",model_.layers[3].get_weights()[0].shape)\n",
    "print(\"dense_b:\",model_.layers[3].get_weights()[1].shape)\n",
    "dense_w=model_.layers[3].get_weights()[0]\n",
    "dense_b=model_.layers[3].get_weights()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.8013229 , -1.0441449 , -0.49105257, -0.77370507, -0.4876282 ,\n",
       "       -0.4249529 , -0.38504785, -0.34773955, -0.3683724 , -0.22437364,\n",
       "       -0.33965763, -0.3289736 , -0.12665622,  0.01863566, -0.5537919 ,\n",
       "        0.42437387], dtype=float32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dense_b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "fin_Wz  = open('weight_dense_w_fpb.dat', 'w')\n",
    "for j in range(dense_w.shape[0]) :\n",
    "\tfor i in range(dense_w.shape[1]) :\n",
    "\t\tfin_Wz.write(\"{0:018b}\\n\".format(int(real_to_Qnm(dense_w[j,i],QN,QM))))\n",
    "fin_Wz.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "fin_Wz  = open('weight_dense_b_fpb.dat', 'w')\n",
    "for j in range(dense_b.shape[0]) :\n",
    "\tfin_Wz.write(\"{0:018b}\\n\".format(int(real_to_Qnm(dense_b[j],QN,QM))))\n",
    "fin_Wz.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
